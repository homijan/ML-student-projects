{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Open a Jupyter notebook to complete the activity.\n",
    "#2. Import the TensorFlow and pandas libraries.\n",
    "#3. Load in the superconductivity.csv dataset.\n",
    "#4. Drop any rows that have null values.\n",
    "#5. Set the target values to true when values of the critical_temp column are above 77.36 and false when below. The feature dataset is the remaining columns in the dataset.\n",
    "#6. Rescale the feature dataset using a standard scaler.\n",
    "#7. Initialize a model of the Keras Sequential class.\n",
    "#8. Add an input layer, three hidden layers of sizes 32, 16, and 8, and an output layer with a sigmoid activation function of size 1 to the model.\n",
    "#9. Compile the model with an RMSprop optimizer with a learning rate equal to 0.0001 and binary cross-entropy for the loss and compute the accuracy metric.\n",
    "#10. Add a callback to write logs to TensorBoard. (optional)\n",
    "#11. Fit the model to the training data for 50 epochs and a validation split equal to 0%.\n",
    "#12. Evaluate the model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/fenago/datasets/main/superconductivity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_elements</th>\n",
       "      <th>mean_atomic_mass</th>\n",
       "      <th>wtd_mean_atomic_mass</th>\n",
       "      <th>gmean_atomic_mass</th>\n",
       "      <th>wtd_gmean_atomic_mass</th>\n",
       "      <th>entropy_atomic_mass</th>\n",
       "      <th>wtd_entropy_atomic_mass</th>\n",
       "      <th>range_atomic_mass</th>\n",
       "      <th>wtd_range_atomic_mass</th>\n",
       "      <th>std_atomic_mass</th>\n",
       "      <th>...</th>\n",
       "      <th>wtd_mean_Valence</th>\n",
       "      <th>gmean_Valence</th>\n",
       "      <th>wtd_gmean_Valence</th>\n",
       "      <th>entropy_Valence</th>\n",
       "      <th>wtd_entropy_Valence</th>\n",
       "      <th>range_Valence</th>\n",
       "      <th>wtd_range_Valence</th>\n",
       "      <th>std_Valence</th>\n",
       "      <th>wtd_std_Valence</th>\n",
       "      <th>critical_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6352</th>\n",
       "      <td>5</td>\n",
       "      <td>101.628010</td>\n",
       "      <td>55.981263</td>\n",
       "      <td>78.379583</td>\n",
       "      <td>36.455230</td>\n",
       "      <td>1.438484</td>\n",
       "      <td>1.430809</td>\n",
       "      <td>134.36060</td>\n",
       "      <td>19.032623</td>\n",
       "      <td>52.867028</td>\n",
       "      <td>...</td>\n",
       "      <td>2.092664</td>\n",
       "      <td>2.491462</td>\n",
       "      <td>2.072800</td>\n",
       "      <td>1.564957</td>\n",
       "      <td>1.277334</td>\n",
       "      <td>2</td>\n",
       "      <td>1.011583</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.339066</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14818</th>\n",
       "      <td>5</td>\n",
       "      <td>81.789084</td>\n",
       "      <td>52.617798</td>\n",
       "      <td>45.923551</td>\n",
       "      <td>30.445450</td>\n",
       "      <td>1.211225</td>\n",
       "      <td>1.183367</td>\n",
       "      <td>154.11932</td>\n",
       "      <td>22.737765</td>\n",
       "      <td>69.089853</td>\n",
       "      <td>...</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.930156</td>\n",
       "      <td>2.749459</td>\n",
       "      <td>1.586785</td>\n",
       "      <td>1.411949</td>\n",
       "      <td>2</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>0.687184</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13024</th>\n",
       "      <td>3</td>\n",
       "      <td>130.298627</td>\n",
       "      <td>116.146323</td>\n",
       "      <td>123.093539</td>\n",
       "      <td>110.063924</td>\n",
       "      <td>1.039711</td>\n",
       "      <td>0.758662</td>\n",
       "      <td>102.17762</td>\n",
       "      <td>67.107147</td>\n",
       "      <td>45.991695</td>\n",
       "      <td>...</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>5.646216</td>\n",
       "      <td>5.233176</td>\n",
       "      <td>1.095078</td>\n",
       "      <td>0.691150</td>\n",
       "      <td>1</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9073</th>\n",
       "      <td>5</td>\n",
       "      <td>88.679574</td>\n",
       "      <td>57.453544</td>\n",
       "      <td>70.154267</td>\n",
       "      <td>35.982178</td>\n",
       "      <td>1.445332</td>\n",
       "      <td>1.006610</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>36.455794</td>\n",
       "      <td>46.485352</td>\n",
       "      <td>...</td>\n",
       "      <td>2.267857</td>\n",
       "      <td>2.168944</td>\n",
       "      <td>2.229448</td>\n",
       "      <td>1.594167</td>\n",
       "      <td>1.050239</td>\n",
       "      <td>1</td>\n",
       "      <td>1.125714</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.442843</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5707</th>\n",
       "      <td>4</td>\n",
       "      <td>51.810850</td>\n",
       "      <td>42.722456</td>\n",
       "      <td>43.468565</td>\n",
       "      <td>33.871021</td>\n",
       "      <td>1.241927</td>\n",
       "      <td>1.315143</td>\n",
       "      <td>71.62060</td>\n",
       "      <td>8.838560</td>\n",
       "      <td>26.646429</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.290165</td>\n",
       "      <td>0</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       number_of_elements  mean_atomic_mass  wtd_mean_atomic_mass  \\\n",
       "6352                    5        101.628010             55.981263   \n",
       "14818                   5         81.789084             52.617798   \n",
       "13024                   3        130.298627            116.146323   \n",
       "9073                    5         88.679574             57.453544   \n",
       "5707                    4         51.810850             42.722456   \n",
       "\n",
       "       gmean_atomic_mass  wtd_gmean_atomic_mass  entropy_atomic_mass  \\\n",
       "6352           78.379583              36.455230             1.438484   \n",
       "14818          45.923551              30.445450             1.211225   \n",
       "13024         123.093539             110.063924             1.039711   \n",
       "9073           70.154267              35.982178             1.445332   \n",
       "5707           43.468565              33.871021             1.241927   \n",
       "\n",
       "       wtd_entropy_atomic_mass  range_atomic_mass  wtd_range_atomic_mass  \\\n",
       "6352                  1.430809          134.36060              19.032623   \n",
       "14818                 1.183367          154.11932              22.737765   \n",
       "13024                 0.758662          102.17762              67.107147   \n",
       "9073                  1.006610          122.90607              36.455794   \n",
       "5707                  1.315143           71.62060               8.838560   \n",
       "\n",
       "       std_atomic_mass  ...  wtd_mean_Valence  gmean_Valence  \\\n",
       "6352         52.867028  ...          2.092664       2.491462   \n",
       "14818        69.089853  ...          2.833333       2.930156   \n",
       "13024        45.991695  ...          5.250000       5.646216   \n",
       "9073         46.485352  ...          2.267857       2.168944   \n",
       "5707         26.646429  ...          2.000000       2.000000   \n",
       "\n",
       "       wtd_gmean_Valence  entropy_Valence  wtd_entropy_Valence  range_Valence  \\\n",
       "6352            2.072800         1.564957             1.277334              2   \n",
       "14818           2.749459         1.586785             1.411949              2   \n",
       "13024           5.233176         1.095078             0.691150              1   \n",
       "9073            2.229448         1.594167             1.050239              1   \n",
       "5707            2.000000         1.386294             1.290165              0   \n",
       "\n",
       "       wtd_range_Valence  std_Valence  wtd_std_Valence  critical_temp  \n",
       "6352            1.011583     0.800000         0.339066           41.0  \n",
       "14818           0.950000     0.632456         0.687184            8.2  \n",
       "13024           3.600000     0.471405         0.433013            7.9  \n",
       "9073            1.125714     0.400000         0.442843           10.4  \n",
       "5707            0.560000     0.000000         0.000000          109.0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View a sample\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear all empty values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions (x, y): ((21263, 81), (21263,))\n"
     ]
    }
   ],
   "source": [
    "# Create target (y) and features (x)\n",
    "target = df['critical_temp'].apply(lambda x: 1 if x>77.36 else 0)\n",
    "features = df.drop('critical_temp', axis=1)\n",
    "print(f'dimensions (x, y): {features.shape, target.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale input data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "feature_array = scaler.fit_transform(features)\n",
    "features = pd.DataFrame(feature_array, columns=features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NN object\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Add input layer: size coresponds to the number of x components\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(features.shape[1],), name='Input_layer'))\n",
    "\n",
    "# Add hidden layers\n",
    "model.add(tf.keras.layers.Dense(32, name='Dense_layer_1'))\n",
    "model.add(tf.keras.layers.Dense(16, name='Dense_layer_2'))\n",
    "model.add(tf.keras.layers.Dense(8, name='Dense_layer_3'))\n",
    "\n",
    "# Add output layer: size corresponds to the number of y components\n",
    "model.add(tf.keras.layers.Dense(1, name='Output_layer', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set back propagation learner/optimizer \n",
    "model.compile(tf.optimizers.RMSprop(0.0001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.6521 - accuracy: 0.6271 - val_loss: 0.3945 - val_accuracy: 0.9716\n",
      "Epoch 2/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.6199 - accuracy: 0.6575 - val_loss: 0.2709 - val_accuracy: 0.9766\n",
      "Epoch 3/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.5984 - accuracy: 0.6643 - val_loss: 0.1882 - val_accuracy: 0.9782\n",
      "Epoch 4/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.5790 - accuracy: 0.6742 - val_loss: 0.1313 - val_accuracy: 0.9786\n",
      "Epoch 5/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.5621 - accuracy: 0.6910 - val_loss: 0.0911 - val_accuracy: 0.9810\n",
      "Epoch 6/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.5480 - accuracy: 0.7005 - val_loss: 0.0698 - val_accuracy: 0.9848\n",
      "Epoch 7/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7077 - val_loss: 0.0531 - val_accuracy: 0.9834\n",
      "Epoch 8/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.5261 - accuracy: 0.7099 - val_loss: 0.0514 - val_accuracy: 0.9865\n",
      "Epoch 9/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.5181 - accuracy: 0.7139 - val_loss: 0.0427 - val_accuracy: 0.9880\n",
      "Epoch 10/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.5108 - accuracy: 0.7165 - val_loss: 0.0396 - val_accuracy: 0.9878\n",
      "Epoch 11/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.5044 - accuracy: 0.7210 - val_loss: 0.0365 - val_accuracy: 0.9874\n",
      "Epoch 12/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4994 - accuracy: 0.7217 - val_loss: 0.0362 - val_accuracy: 0.9869\n",
      "Epoch 13/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4948 - accuracy: 0.7264 - val_loss: 0.0340 - val_accuracy: 0.9875\n",
      "Epoch 14/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4914 - accuracy: 0.7303 - val_loss: 0.0329 - val_accuracy: 0.9878\n",
      "Epoch 15/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4881 - accuracy: 0.7288 - val_loss: 0.0323 - val_accuracy: 0.9885\n",
      "Epoch 16/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4858 - accuracy: 0.7327 - val_loss: 0.0337 - val_accuracy: 0.9874\n",
      "Epoch 17/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4830 - accuracy: 0.7370 - val_loss: 0.0314 - val_accuracy: 0.9876\n",
      "Epoch 18/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4814 - accuracy: 0.7361 - val_loss: 0.0316 - val_accuracy: 0.9870\n",
      "Epoch 19/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4793 - accuracy: 0.7377 - val_loss: 0.0311 - val_accuracy: 0.9873\n",
      "Epoch 20/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4777 - accuracy: 0.7400 - val_loss: 0.0307 - val_accuracy: 0.9897\n",
      "Epoch 21/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4760 - accuracy: 0.7408 - val_loss: 0.0312 - val_accuracy: 0.9873\n",
      "Epoch 22/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4748 - accuracy: 0.7415 - val_loss: 0.0303 - val_accuracy: 0.9877\n",
      "Epoch 23/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4730 - accuracy: 0.7435 - val_loss: 0.0310 - val_accuracy: 0.9875\n",
      "Epoch 24/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4725 - accuracy: 0.7454 - val_loss: 0.0305 - val_accuracy: 0.9877\n",
      "Epoch 25/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4718 - accuracy: 0.7429 - val_loss: 0.0299 - val_accuracy: 0.9882\n",
      "Epoch 26/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4707 - accuracy: 0.7473 - val_loss: 0.0302 - val_accuracy: 0.9877\n",
      "Epoch 27/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4696 - accuracy: 0.7476 - val_loss: 0.0298 - val_accuracy: 0.9876\n",
      "Epoch 28/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4680 - accuracy: 0.7470 - val_loss: 0.0297 - val_accuracy: 0.9875\n",
      "Epoch 29/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4673 - accuracy: 0.7484 - val_loss: 0.0298 - val_accuracy: 0.9897\n",
      "Epoch 30/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4659 - accuracy: 0.7467 - val_loss: 0.0297 - val_accuracy: 0.9881\n",
      "Epoch 31/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4655 - accuracy: 0.7481 - val_loss: 0.0309 - val_accuracy: 0.9876\n",
      "Epoch 32/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4650 - accuracy: 0.7501 - val_loss: 0.0304 - val_accuracy: 0.9882\n",
      "Epoch 33/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4642 - accuracy: 0.7499 - val_loss: 0.0297 - val_accuracy: 0.9881\n",
      "Epoch 34/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4629 - accuracy: 0.7511 - val_loss: 0.0297 - val_accuracy: 0.9881\n",
      "Epoch 35/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4622 - accuracy: 0.7519 - val_loss: 0.0298 - val_accuracy: 0.9880\n",
      "Epoch 36/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4618 - accuracy: 0.7539 - val_loss: 0.0296 - val_accuracy: 0.9877\n",
      "Epoch 37/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4601 - accuracy: 0.7526 - val_loss: 0.0300 - val_accuracy: 0.9879\n",
      "Epoch 38/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4599 - accuracy: 0.7533 - val_loss: 0.0298 - val_accuracy: 0.9881\n",
      "Epoch 39/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4593 - accuracy: 0.7549 - val_loss: 0.0296 - val_accuracy: 0.9881\n",
      "Epoch 40/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4591 - accuracy: 0.7544 - val_loss: 0.0297 - val_accuracy: 0.9881\n",
      "Epoch 41/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4578 - accuracy: 0.7552 - val_loss: 0.0294 - val_accuracy: 0.9880\n",
      "Epoch 42/50\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.4574 - accuracy: 0.7566 - val_loss: 0.0300 - val_accuracy: 0.9881\n",
      "Epoch 43/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4563 - accuracy: 0.7536 - val_loss: 0.0297 - val_accuracy: 0.9881\n",
      "Epoch 44/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4562 - accuracy: 0.7555 - val_loss: 0.0299 - val_accuracy: 0.9882\n",
      "Epoch 45/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4563 - accuracy: 0.7567 - val_loss: 0.0299 - val_accuracy: 0.9894\n",
      "Epoch 46/50\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.4556 - accuracy: 0.7558 - val_loss: 0.0310 - val_accuracy: 0.9884\n",
      "Epoch 47/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4540 - accuracy: 0.7593 - val_loss: 0.0296 - val_accuracy: 0.9881\n",
      "Epoch 48/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4545 - accuracy: 0.7585 - val_loss: 0.0297 - val_accuracy: 0.9892\n",
      "Epoch 49/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4531 - accuracy: 0.7579 - val_loss: 0.0296 - val_accuracy: 0.9881\n",
      "Epoch 50/50\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.4525 - accuracy: 0.7576 - val_loss: 0.0297 - val_accuracy: 0.9883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff390576040>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actual training\n",
    "model.fit(x=features.to_numpy(), y=target.to_numpy(), epochs=50, validation_split=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665/665 [==============================] - 1s 828us/step - loss: 0.2399 - accuracy: 0.8772\n",
      "loss: 0.23993106186389923, accuracy: 0.8772045373916626\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(features.to_numpy(), target.to_numpy())\n",
    "print(f'loss: {loss}, accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
