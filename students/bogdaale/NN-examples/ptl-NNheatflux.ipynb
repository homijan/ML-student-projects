{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e6ec5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/workspace/mlmfem/anaconda3/envs/ptl_env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.profiler import Profiler, AdvancedProfiler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "367f55c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5991dc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9463, 88)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Z_0</th>\n",
       "      <th>Z_1</th>\n",
       "      <th>Z_2</th>\n",
       "      <th>Z_3</th>\n",
       "      <th>Z_4</th>\n",
       "      <th>Z_5</th>\n",
       "      <th>Z_6</th>\n",
       "      <th>Z_7</th>\n",
       "      <th>Z_8</th>\n",
       "      <th>Z_9</th>\n",
       "      <th>...</th>\n",
       "      <th>n_10</th>\n",
       "      <th>n_11</th>\n",
       "      <th>n_12</th>\n",
       "      <th>n_13</th>\n",
       "      <th>n_14</th>\n",
       "      <th>n_15</th>\n",
       "      <th>n_16</th>\n",
       "      <th>Qimpact_c-1</th>\n",
       "      <th>Qimpact_c</th>\n",
       "      <th>Qimpact_c+1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.006199</th>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.387379</td>\n",
       "      <td>-0.387291</td>\n",
       "      <td>-0.387195</td>\n",
       "      <td>-0.387090</td>\n",
       "      <td>-0.386979</td>\n",
       "      <td>-0.386861</td>\n",
       "      <td>-0.386738</td>\n",
       "      <td>-1.047110</td>\n",
       "      <td>-1.042031</td>\n",
       "      <td>-1.036952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.006218</th>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.387376</td>\n",
       "      <td>-0.387288</td>\n",
       "      <td>-0.387191</td>\n",
       "      <td>-0.387087</td>\n",
       "      <td>-0.386975</td>\n",
       "      <td>-0.386858</td>\n",
       "      <td>-0.386734</td>\n",
       "      <td>-1.046952</td>\n",
       "      <td>-1.041873</td>\n",
       "      <td>-1.036793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.006237</th>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.387374</td>\n",
       "      <td>-0.387285</td>\n",
       "      <td>-0.387188</td>\n",
       "      <td>-0.387084</td>\n",
       "      <td>-0.386972</td>\n",
       "      <td>-0.386854</td>\n",
       "      <td>-0.386730</td>\n",
       "      <td>-1.046793</td>\n",
       "      <td>-1.041714</td>\n",
       "      <td>-1.036634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.006256</th>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.387371</td>\n",
       "      <td>-0.387282</td>\n",
       "      <td>-0.387185</td>\n",
       "      <td>-0.387080</td>\n",
       "      <td>-0.386968</td>\n",
       "      <td>-0.386850</td>\n",
       "      <td>-0.386726</td>\n",
       "      <td>-1.046634</td>\n",
       "      <td>-1.041555</td>\n",
       "      <td>-1.036476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.006274</th>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.387368</td>\n",
       "      <td>-0.387279</td>\n",
       "      <td>-0.387182</td>\n",
       "      <td>-0.387077</td>\n",
       "      <td>-0.386965</td>\n",
       "      <td>-0.386846</td>\n",
       "      <td>-0.386722</td>\n",
       "      <td>-1.046476</td>\n",
       "      <td>-1.041396</td>\n",
       "      <td>-1.036317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Z_0       Z_1       Z_2       Z_3       Z_4       Z_5  \\\n",
       "0.006199 -0.390936 -0.390936 -0.390936 -0.390936 -0.390936 -0.390936   \n",
       "0.006218 -0.390936 -0.390936 -0.390936 -0.390936 -0.390936 -0.390936   \n",
       "0.006237 -0.390936 -0.390936 -0.390936 -0.390936 -0.390936 -0.390936   \n",
       "0.006256 -0.390936 -0.390936 -0.390936 -0.390936 -0.390936 -0.390936   \n",
       "0.006274 -0.390936 -0.390936 -0.390936 -0.390936 -0.390936 -0.390936   \n",
       "\n",
       "               Z_6       Z_7       Z_8       Z_9  ...      n_10      n_11  \\\n",
       "0.006199 -0.390936 -0.390936 -0.390936 -0.390936  ... -0.387379 -0.387291   \n",
       "0.006218 -0.390936 -0.390936 -0.390936 -0.390936  ... -0.387376 -0.387288   \n",
       "0.006237 -0.390936 -0.390936 -0.390936 -0.390936  ... -0.387374 -0.387285   \n",
       "0.006256 -0.390936 -0.390936 -0.390936 -0.390936  ... -0.387371 -0.387282   \n",
       "0.006274 -0.390936 -0.390936 -0.390936 -0.390936  ... -0.387368 -0.387279   \n",
       "\n",
       "              n_12      n_13      n_14      n_15      n_16  Qimpact_c-1  \\\n",
       "0.006199 -0.387195 -0.387090 -0.386979 -0.386861 -0.386738    -1.047110   \n",
       "0.006218 -0.387191 -0.387087 -0.386975 -0.386858 -0.386734    -1.046952   \n",
       "0.006237 -0.387188 -0.387084 -0.386972 -0.386854 -0.386730    -1.046793   \n",
       "0.006256 -0.387185 -0.387080 -0.386968 -0.386850 -0.386726    -1.046634   \n",
       "0.006274 -0.387182 -0.387077 -0.386965 -0.386846 -0.386722    -1.046476   \n",
       "\n",
       "          Qimpact_c  Qimpact_c+1  \n",
       "0.006199  -1.042031    -1.036952  \n",
       "0.006218  -1.041873    -1.036793  \n",
       "0.006237  -1.041714    -1.036634  \n",
       "0.006256  -1.041555    -1.036476  \n",
       "0.006274  -1.041396    -1.036317  \n",
       "\n",
       "[5 rows x 88 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_Qdata = pd.read_csv(f'{path}/scaled_QdataKn32width1e-02cm.csv', header=0, index_col=0)  #qdata with Knudsen\n",
    "print(scaled_Qdata.shape)\n",
    "scaled_Qdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "840a5025",
   "metadata": {},
   "outputs": [],
   "source": [
    "validationsize=1000 #how many samples will be used as traindata\n",
    "testsize=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e86d3a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size:  (7463, 88) \n",
      "Testing dataset size:  (9463, 88) \n",
      "Validation dataset size:  (1000, 88)\n"
     ]
    }
   ],
   "source": [
    "shuffled_Qdata=scaled_Qdata.sample(n=scaled_Qdata.shape[0])\n",
    "\n",
    "validation_data=shuffled_Qdata.iloc[:validationsize]\n",
    "test_data=scaled_Qdata\n",
    "train_data=shuffled_Qdata.iloc[validationsize+testsize:]\n",
    "\n",
    "print('Training dataset size: ', train_data.shape, '\\nTesting dataset size: ',test_data.shape,'\\nValidation dataset size: ', validation_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3105ebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "threePoint = False\n",
    "if (threePoint):\n",
    "    target_fields = ['Qimpact_c-1','Qimpact_c','Qimpact_c+1']\n",
    "else:\n",
    "    target_fields = ['Qimpact_c']\n",
    "drop_fields = ['Qimpact_c-1','Qimpact_c','Qimpact_c+1']\n",
    "\n",
    "train_features, train_targets = train_data.drop(drop_fields, axis=1), train_data[target_fields]\n",
    "test_features, test_targets = test_data.drop(drop_fields, axis=1), test_data[target_fields]\n",
    "validation_features, validation_targets = validation_data.drop(drop_fields, axis=1), validation_data[target_fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24b0cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_rate = 0.1\n",
    "mse_loss = nn.MSELoss(reduction = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6767ca2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ce9ee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression(pl.LightningModule):\n",
    "    \n",
    "### The Model ### \n",
    "\n",
    "    # Question: what will your model architecture look like?\n",
    "    # Initialize the layers\n",
    "    # Here we have one input layer (size 56 #3N as we have 56 #3N features), one hidden layer (size 10), \n",
    "    # and one output layer (size 1 as we are predicting a single value)\n",
    "    def __init__(self):\n",
    "        super(Regression, self).__init__()\n",
    "        N1 = 30\n",
    "        N2 = 10\n",
    "        self.fc1 = nn.Linear(train_features.shape[1], N1)\n",
    "        self.fc2 = nn.Linear(N1, N2)\n",
    "        if (threePoint):\n",
    "            self.fc3 = nn.Linear(N2, 3)\n",
    "        else:\n",
    "            self.fc3 = nn.Linear(N2, 1)            \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "### Data loader ### \n",
    "    def train_dataloader(self):\n",
    "        train_dataset = TensorDataset(torch.tensor(train_features.values).float(), torch.tensor(train_targets[target_fields].values).float())\n",
    "        train_loader = DataLoader(dataset = train_dataset, batch_size = 128)\n",
    "        return train_loader\n",
    "        \n",
    "    def val_dataloader(self):\n",
    "        validation_dataset = TensorDataset(torch.tensor(validation_features.values).float(),\\\n",
    "                                           torch.tensor(validation_targets[target_fields].values).float())\n",
    "        validation_loader = DataLoader(dataset = validation_dataset, batch_size = 128)\n",
    "        return validation_loader\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        test_dataset = TensorDataset(torch.tensor(test_features.values).float(), torch.tensor(test_targets[target_fields].values).float())\n",
    "        test_loader = DataLoader(dataset = test_dataset, batch_size = 128)\n",
    "        return test_loader\n",
    "\n",
    "### The Optimizer ### \n",
    "    def configure_optimizers(self):\n",
    "        return optim.SGD(self.parameters(), lr=l_rate)\n",
    "\n",
    "### Training ### \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = mse_loss(logits, y)\n",
    "        # Add logging\n",
    "        logs = {'loss': loss}\n",
    "        return {'loss': loss, 'log': logs}\n",
    "\n",
    "### Validation ### \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = mse_loss(logits, y)\n",
    "        return {'val_loss': loss}\n",
    "\n",
    "    # Define validation epoch end\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {'val_loss': avg_loss}\n",
    "        return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}\n",
    "\n",
    "### Testing ###     \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = mse_loss(logits, y)\n",
    "        correct = torch.sum(logits == y.data)\n",
    "        \n",
    "        predictions_pred.append(logits)\n",
    "        predictions_actual.append(y.data)\n",
    "        return {'test_loss': loss, 'test_correct': correct, 'logits': logits}\n",
    "    \n",
    "    # Define test end\n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        logs = {'test_loss': avg_loss}      \n",
    "        return {'avg_test_loss': avg_loss, 'log': logs, 'progress_bar': logs }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23f5500e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name | Type   | Params\n",
      "--------------------------------\n",
      "0 | fc1  | Linear | 2.6 K \n",
      "1 | fc2  | Linear | 310   \n",
      "2 | fc3  | Linear | 11    \n",
      "--------------------------------\n",
      "2.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.9 K     Total params\n",
      "0.012     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/workspace/mlmfem/anaconda3/envs/ptl_env/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/usr/workspace/mlmfem/anaconda3/envs/ptl_env/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  88%|████████████████████████▋   | 59/67 [00:00<00:00, 154.61it/s, loss=0.157, v_num=2]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████   | 60/67 [00:00<00:00, 153.34it/s, loss=0.157, v_num=2]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████▍  | 61/67 [00:00<00:00, 153.98it/s, loss=0.157, v_num=2]\u001b[A\n",
      "Epoch 0:  93%|█████████████████████████▉  | 62/67 [00:00<00:00, 154.64it/s, loss=0.157, v_num=2]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████▎ | 63/67 [00:00<00:00, 155.35it/s, loss=0.157, v_num=2]\u001b[A\n",
      "Epoch 0:  96%|██████████████████████████▋ | 64/67 [00:00<00:00, 156.02it/s, loss=0.157, v_num=2]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████▏| 65/67 [00:00<00:00, 156.68it/s, loss=0.157, v_num=2]\u001b[A\n",
      "Epoch 0:  99%|███████████████████████████▌| 66/67 [00:00<00:00, 157.31it/s, loss=0.157, v_num=2]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████| 67/67 [00:00<00:00, 157.40it/s, loss=0.157, v_num=2]\u001b[A\n",
      "Epoch 1:  88%|███████████████████████▊   | 59/67 [00:00<00:00, 153.51it/s, loss=0.0579, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  90%|████████████████████████▏  | 60/67 [00:00<00:00, 152.32it/s, loss=0.0579, v_num=2]\u001b[A\n",
      "Epoch 1:  91%|████████████████████████▌  | 61/67 [00:00<00:00, 153.07it/s, loss=0.0579, v_num=2]\u001b[A\n",
      "Epoch 1:  93%|████████████████████████▉  | 62/67 [00:00<00:00, 153.80it/s, loss=0.0579, v_num=2]\u001b[A\n",
      "Epoch 1:  94%|█████████████████████████▍ | 63/67 [00:00<00:00, 154.50it/s, loss=0.0579, v_num=2]\u001b[A\n",
      "Epoch 1:  96%|█████████████████████████▊ | 64/67 [00:00<00:00, 155.22it/s, loss=0.0579, v_num=2]\u001b[A\n",
      "Epoch 1:  97%|██████████████████████████▏| 65/67 [00:00<00:00, 155.87it/s, loss=0.0579, v_num=2]\u001b[A\n",
      "Epoch 1:  99%|██████████████████████████▌| 66/67 [00:00<00:00, 156.51it/s, loss=0.0579, v_num=2]\u001b[A\n",
      "Epoch 1: 100%|███████████████████████████| 67/67 [00:00<00:00, 156.62it/s, loss=0.0579, v_num=2]\u001b[A\n",
      "Epoch 2:  88%|███████████████████████▊   | 59/67 [00:00<00:00, 160.65it/s, loss=0.0378, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  90%|████████████████████████▏  | 60/67 [00:00<00:00, 159.25it/s, loss=0.0378, v_num=2]\u001b[A\n",
      "Epoch 2:  91%|████████████████████████▌  | 61/67 [00:00<00:00, 160.01it/s, loss=0.0378, v_num=2]\u001b[A\n",
      "Epoch 2:  93%|████████████████████████▉  | 62/67 [00:00<00:00, 160.68it/s, loss=0.0378, v_num=2]\u001b[A\n",
      "Epoch 2:  94%|█████████████████████████▍ | 63/67 [00:00<00:00, 161.38it/s, loss=0.0378, v_num=2]\u001b[A\n",
      "Epoch 2:  96%|█████████████████████████▊ | 64/67 [00:00<00:00, 162.04it/s, loss=0.0378, v_num=2]\u001b[A\n",
      "Epoch 2:  97%|██████████████████████████▏| 65/67 [00:00<00:00, 162.71it/s, loss=0.0378, v_num=2]\u001b[A\n",
      "Epoch 2:  99%|██████████████████████████▌| 66/67 [00:00<00:00, 163.34it/s, loss=0.0378, v_num=2]\u001b[A\n",
      "Epoch 2: 100%|███████████████████████████| 67/67 [00:00<00:00, 163.37it/s, loss=0.0378, v_num=2]\u001b[A\n",
      "Epoch 3:  88%|███████████████████████▊   | 59/67 [00:00<00:00, 161.82it/s, loss=0.0253, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  90%|████████████████████████▏  | 60/67 [00:00<00:00, 160.41it/s, loss=0.0253, v_num=2]\u001b[A\n",
      "Epoch 3:  91%|████████████████████████▌  | 61/67 [00:00<00:00, 161.10it/s, loss=0.0253, v_num=2]\u001b[A\n",
      "Epoch 3:  93%|████████████████████████▉  | 62/67 [00:00<00:00, 161.78it/s, loss=0.0253, v_num=2]\u001b[A\n",
      "Epoch 3:  94%|█████████████████████████▍ | 63/67 [00:00<00:00, 162.47it/s, loss=0.0253, v_num=2]\u001b[A\n",
      "Epoch 3:  96%|█████████████████████████▊ | 64/67 [00:00<00:00, 163.17it/s, loss=0.0253, v_num=2]\u001b[A\n",
      "Epoch 3:  97%|██████████████████████████▏| 65/67 [00:00<00:00, 163.82it/s, loss=0.0253, v_num=2]\u001b[A\n",
      "Epoch 3:  99%|██████████████████████████▌| 66/67 [00:00<00:00, 164.45it/s, loss=0.0253, v_num=2]\u001b[A\n",
      "Epoch 3: 100%|███████████████████████████| 67/67 [00:00<00:00, 164.48it/s, loss=0.0253, v_num=2]\u001b[A\n",
      "Epoch 4:  88%|███████████████████████▊   | 59/67 [00:00<00:00, 159.04it/s, loss=0.0182, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  90%|████████████████████████▏  | 60/67 [00:00<00:00, 157.64it/s, loss=0.0182, v_num=2]\u001b[A\n",
      "Epoch 4:  91%|████████████████████████▌  | 61/67 [00:00<00:00, 158.42it/s, loss=0.0182, v_num=2]\u001b[A\n",
      "Epoch 4:  93%|████████████████████████▉  | 62/67 [00:00<00:00, 159.14it/s, loss=0.0182, v_num=2]\u001b[A\n",
      "Epoch 4:  94%|█████████████████████████▍ | 63/67 [00:00<00:00, 159.87it/s, loss=0.0182, v_num=2]\u001b[A\n",
      "Epoch 4:  96%|█████████████████████████▊ | 64/67 [00:00<00:00, 160.61it/s, loss=0.0182, v_num=2]\u001b[A\n",
      "Epoch 4:  97%|██████████████████████████▏| 65/67 [00:00<00:00, 161.29it/s, loss=0.0182, v_num=2]\u001b[A\n",
      "Epoch 4:  99%|██████████████████████████▌| 66/67 [00:00<00:00, 161.98it/s, loss=0.0182, v_num=2]\u001b[A\n",
      "Epoch 4: 100%|███████████████████████████| 67/67 [00:00<00:00, 162.04it/s, loss=0.0182, v_num=2]\u001b[A\n",
      "Epoch 5:  88%|███████████████████████▊   | 59/67 [00:00<00:00, 164.02it/s, loss=0.0153, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  90%|████████████████████████▏  | 60/67 [00:00<00:00, 162.64it/s, loss=0.0153, v_num=2]\u001b[A\n",
      "Epoch 5:  91%|████████████████████████▌  | 61/67 [00:00<00:00, 163.41it/s, loss=0.0153, v_num=2]\u001b[A\n",
      "Epoch 5:  93%|████████████████████████▉  | 62/67 [00:00<00:00, 164.15it/s, loss=0.0153, v_num=2]\u001b[A\n",
      "Epoch 5:  94%|█████████████████████████▍ | 63/67 [00:00<00:00, 164.86it/s, loss=0.0153, v_num=2]\u001b[A\n",
      "Epoch 5:  96%|█████████████████████████▊ | 64/67 [00:00<00:00, 165.55it/s, loss=0.0153, v_num=2]\u001b[A\n",
      "Epoch 5:  97%|██████████████████████████▏| 65/67 [00:00<00:00, 166.22it/s, loss=0.0153, v_num=2]\u001b[A\n",
      "Epoch 5:  99%|██████████████████████████▌| 66/67 [00:00<00:00, 166.78it/s, loss=0.0153, v_num=2]\u001b[A\n",
      "Epoch 5: 100%|███████████████████████████| 67/67 [00:00<00:00, 166.83it/s, loss=0.0153, v_num=2]\u001b[A\n",
      "Epoch 6:  88%|███████████████████████▊   | 59/67 [00:00<00:00, 162.83it/s, loss=0.0126, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:  90%|████████████████████████▏  | 60/67 [00:00<00:00, 161.48it/s, loss=0.0126, v_num=2]\u001b[A\n",
      "Epoch 6:  91%|████████████████████████▌  | 61/67 [00:00<00:00, 162.24it/s, loss=0.0126, v_num=2]\u001b[A\n",
      "Epoch 6:  93%|████████████████████████▉  | 62/67 [00:00<00:00, 162.97it/s, loss=0.0126, v_num=2]\u001b[A\n",
      "Epoch 6:  94%|█████████████████████████▍ | 63/67 [00:00<00:00, 163.78it/s, loss=0.0126, v_num=2]\u001b[A\n",
      "Epoch 6:  96%|█████████████████████████▊ | 64/67 [00:00<00:00, 164.44it/s, loss=0.0126, v_num=2]\u001b[A\n",
      "Epoch 6:  97%|██████████████████████████▏| 65/67 [00:00<00:00, 165.10it/s, loss=0.0126, v_num=2]\u001b[A\n",
      "Epoch 6:  99%|██████████████████████████▌| 66/67 [00:00<00:00, 165.81it/s, loss=0.0126, v_num=2]\u001b[A\n",
      "Epoch 6: 100%|███████████████████████████| 67/67 [00:00<00:00, 165.92it/s, loss=0.0126, v_num=2]\u001b[A\n",
      "Epoch 7:  88%|███████████████████████▊   | 59/67 [00:00<00:00, 162.75it/s, loss=0.0107, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:  90%|████████████████████████▏  | 60/67 [00:00<00:00, 161.52it/s, loss=0.0107, v_num=2]\u001b[A\n",
      "Epoch 7:  91%|████████████████████████▌  | 61/67 [00:00<00:00, 162.50it/s, loss=0.0107, v_num=2]\u001b[A\n",
      "Epoch 7:  93%|████████████████████████▉  | 62/67 [00:00<00:00, 163.49it/s, loss=0.0107, v_num=2]\u001b[A\n",
      "Epoch 7:  94%|█████████████████████████▍ | 63/67 [00:00<00:00, 164.45it/s, loss=0.0107, v_num=2]\u001b[A\n",
      "Epoch 7:  96%|█████████████████████████▊ | 64/67 [00:00<00:00, 165.41it/s, loss=0.0107, v_num=2]\u001b[A\n",
      "Epoch 7:  97%|██████████████████████████▏| 65/67 [00:00<00:00, 166.29it/s, loss=0.0107, v_num=2]\u001b[A\n",
      "Epoch 7:  99%|██████████████████████████▌| 66/67 [00:00<00:00, 167.21it/s, loss=0.0107, v_num=2]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████████| 67/67 [00:00<00:00, 167.51it/s, loss=0.0107, v_num=2]\u001b[A\n",
      "Epoch 8:  88%|██████████████████████▉   | 59/67 [00:00<00:00, 165.57it/s, loss=0.00941, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  90%|███████████████████████▎  | 60/67 [00:00<00:00, 164.15it/s, loss=0.00941, v_num=2]\u001b[A\n",
      "Epoch 8:  91%|███████████████████████▋  | 61/67 [00:00<00:00, 164.88it/s, loss=0.00941, v_num=2]\u001b[A\n",
      "Epoch 8:  93%|████████████████████████  | 62/67 [00:00<00:00, 165.60it/s, loss=0.00941, v_num=2]\u001b[A\n",
      "Epoch 8:  94%|████████████████████████▍ | 63/67 [00:00<00:00, 166.32it/s, loss=0.00941, v_num=2]\u001b[A\n",
      "Epoch 8:  96%|████████████████████████▊ | 64/67 [00:00<00:00, 167.05it/s, loss=0.00941, v_num=2]\u001b[A\n",
      "Epoch 8:  97%|█████████████████████████▏| 65/67 [00:00<00:00, 167.72it/s, loss=0.00941, v_num=2]\u001b[A\n",
      "Epoch 8:  99%|█████████████████████████▌| 66/67 [00:00<00:00, 168.36it/s, loss=0.00941, v_num=2]\u001b[A\n",
      "Epoch 8: 100%|██████████████████████████| 67/67 [00:00<00:00, 168.40it/s, loss=0.00941, v_num=2]\u001b[A\n",
      "Epoch 9:  88%|██████████████████████▉   | 59/67 [00:00<00:00, 160.68it/s, loss=0.00829, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:  90%|███████████████████████▎  | 60/67 [00:00<00:00, 159.30it/s, loss=0.00829, v_num=2]\u001b[A\n",
      "Epoch 9:  91%|███████████████████████▋  | 61/67 [00:00<00:00, 160.08it/s, loss=0.00829, v_num=2]\u001b[A\n",
      "Epoch 9:  93%|████████████████████████  | 62/67 [00:00<00:00, 160.79it/s, loss=0.00829, v_num=2]\u001b[A\n",
      "Epoch 9:  94%|████████████████████████▍ | 63/67 [00:00<00:00, 161.54it/s, loss=0.00829, v_num=2]\u001b[A\n",
      "Epoch 9:  96%|████████████████████████▊ | 64/67 [00:00<00:00, 162.24it/s, loss=0.00829, v_num=2]\u001b[A\n",
      "Epoch 9:  97%|█████████████████████████▏| 65/67 [00:00<00:00, 162.91it/s, loss=0.00829, v_num=2]\u001b[A\n",
      "Epoch 9:  99%|█████████████████████████▌| 66/67 [00:00<00:00, 163.60it/s, loss=0.00829, v_num=2]\u001b[A\n",
      "Epoch 9: 100%|██████████████████████████| 67/67 [00:00<00:00, 163.66it/s, loss=0.00829, v_num=2]\u001b[A\n",
      "Epoch 10:  88%|██████████████████████   | 59/67 [00:00<00:00, 163.00it/s, loss=0.00723, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:  90%|██████████████████████▍  | 60/67 [00:00<00:00, 161.62it/s, loss=0.00723, v_num=2]\u001b[A\n",
      "Epoch 10:  91%|██████████████████████▊  | 61/67 [00:00<00:00, 162.32it/s, loss=0.00723, v_num=2]\u001b[A\n",
      "Epoch 10:  93%|███████████████████████▏ | 62/67 [00:00<00:00, 163.05it/s, loss=0.00723, v_num=2]\u001b[A\n",
      "Epoch 10:  94%|███████████████████████▌ | 63/67 [00:00<00:00, 163.76it/s, loss=0.00723, v_num=2]\u001b[A\n",
      "Epoch 10:  96%|███████████████████████▉ | 64/67 [00:00<00:00, 164.42it/s, loss=0.00723, v_num=2]\u001b[A\n",
      "Epoch 10:  97%|████████████████████████▎| 65/67 [00:00<00:00, 165.04it/s, loss=0.00723, v_num=2]\u001b[A\n",
      "Epoch 10:  99%|████████████████████████▋| 66/67 [00:00<00:00, 165.71it/s, loss=0.00723, v_num=2]\u001b[A\n",
      "Epoch 10: 100%|█████████████████████████| 67/67 [00:00<00:00, 165.82it/s, loss=0.00723, v_num=2]\u001b[A\n",
      "Epoch 11:  88%|██████████████████████   | 59/67 [00:00<00:00, 162.07it/s, loss=0.00628, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11:  90%|██████████████████████▍  | 60/67 [00:00<00:00, 160.63it/s, loss=0.00628, v_num=2]\u001b[A\n",
      "Epoch 11:  91%|██████████████████████▊  | 61/67 [00:00<00:00, 161.38it/s, loss=0.00628, v_num=2]\u001b[A\n",
      "Epoch 11:  93%|███████████████████████▏ | 62/67 [00:00<00:00, 162.02it/s, loss=0.00628, v_num=2]\u001b[A\n",
      "Epoch 11:  94%|███████████████████████▌ | 63/67 [00:00<00:00, 162.79it/s, loss=0.00628, v_num=2]\u001b[A\n",
      "Epoch 11:  96%|███████████████████████▉ | 64/67 [00:00<00:00, 163.57it/s, loss=0.00628, v_num=2]\u001b[A\n",
      "Epoch 11:  97%|████████████████████████▎| 65/67 [00:00<00:00, 164.34it/s, loss=0.00628, v_num=2]\u001b[A\n",
      "Epoch 11:  99%|████████████████████████▋| 66/67 [00:00<00:00, 165.08it/s, loss=0.00628, v_num=2]\u001b[A\n",
      "Epoch 11: 100%|█████████████████████████| 67/67 [00:00<00:00, 165.24it/s, loss=0.00628, v_num=2]\u001b[A\n",
      "Epoch 12:  88%|██████████████████████   | 59/67 [00:00<00:00, 166.34it/s, loss=0.00569, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12:  90%|██████████████████████▍  | 60/67 [00:00<00:00, 164.80it/s, loss=0.00569, v_num=2]\u001b[A\n",
      "Epoch 12:  91%|██████████████████████▊  | 61/67 [00:00<00:00, 165.54it/s, loss=0.00569, v_num=2]\u001b[A\n",
      "Epoch 12:  93%|███████████████████████▏ | 62/67 [00:00<00:00, 166.20it/s, loss=0.00569, v_num=2]\u001b[A\n",
      "Epoch 12:  94%|███████████████████████▌ | 63/67 [00:00<00:00, 166.91it/s, loss=0.00569, v_num=2]\u001b[A\n",
      "Epoch 12:  96%|███████████████████████▉ | 64/67 [00:00<00:00, 167.59it/s, loss=0.00569, v_num=2]\u001b[A\n",
      "Epoch 12:  97%|████████████████████████▎| 65/67 [00:00<00:00, 168.25it/s, loss=0.00569, v_num=2]\u001b[A\n",
      "Epoch 12:  99%|████████████████████████▋| 66/67 [00:00<00:00, 169.09it/s, loss=0.00569, v_num=2]\u001b[A\n",
      "Epoch 12: 100%|█████████████████████████| 67/67 [00:00<00:00, 169.33it/s, loss=0.00569, v_num=2]\u001b[A\n",
      "Epoch 13:  88%|██████████████████████   | 59/67 [00:00<00:00, 159.73it/s, loss=0.00524, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13:  90%|██████████████████████▍  | 60/67 [00:00<00:00, 158.34it/s, loss=0.00524, v_num=2]\u001b[A\n",
      "Epoch 13:  91%|██████████████████████▊  | 61/67 [00:00<00:00, 159.28it/s, loss=0.00524, v_num=2]\u001b[A\n",
      "Epoch 13:  93%|███████████████████████▏ | 62/67 [00:00<00:00, 160.19it/s, loss=0.00524, v_num=2]\u001b[A\n",
      "Epoch 13:  94%|███████████████████████▌ | 63/67 [00:00<00:00, 161.12it/s, loss=0.00524, v_num=2]\u001b[A\n",
      "Epoch 13:  96%|███████████████████████▉ | 64/67 [00:00<00:00, 162.02it/s, loss=0.00524, v_num=2]\u001b[A\n",
      "Epoch 13:  97%|████████████████████████▎| 65/67 [00:00<00:00, 162.87it/s, loss=0.00524, v_num=2]\u001b[A\n",
      "Epoch 13:  99%|████████████████████████▋| 66/67 [00:00<00:00, 163.74it/s, loss=0.00524, v_num=2]\u001b[A\n",
      "Epoch 13: 100%|█████████████████████████| 67/67 [00:00<00:00, 163.99it/s, loss=0.00524, v_num=2]\u001b[A\n",
      "Epoch 14:  88%|██████████████████████   | 59/67 [00:00<00:00, 161.82it/s, loss=0.00487, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 14:  90%|██████████████████████▍  | 60/67 [00:00<00:00, 160.45it/s, loss=0.00487, v_num=2]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:  91%|██████████████████████▊  | 61/67 [00:00<00:00, 161.40it/s, loss=0.00487, v_num=2]\u001b[A\n",
      "Epoch 14:  93%|███████████████████████▏ | 62/67 [00:00<00:00, 162.32it/s, loss=0.00487, v_num=2]\u001b[A\n",
      "Epoch 14:  94%|███████████████████████▌ | 63/67 [00:00<00:00, 163.24it/s, loss=0.00487, v_num=2]\u001b[A\n",
      "Epoch 14:  96%|███████████████████████▉ | 64/67 [00:00<00:00, 164.13it/s, loss=0.00487, v_num=2]\u001b[A\n",
      "Epoch 14:  97%|████████████████████████▎| 65/67 [00:00<00:00, 165.02it/s, loss=0.00487, v_num=2]\u001b[A\n",
      "Epoch 14:  99%|████████████████████████▋| 66/67 [00:00<00:00, 165.86it/s, loss=0.00487, v_num=2]\u001b[A\n",
      "Epoch 14: 100%|█████████████████████████| 67/67 [00:00<00:00, 166.14it/s, loss=0.00487, v_num=2]\u001b[A\n",
      "Epoch 15:  88%|██████████████████████   | 59/67 [00:00<00:00, 162.63it/s, loss=0.00462, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 15:  90%|██████████████████████▍  | 60/67 [00:00<00:00, 161.16it/s, loss=0.00462, v_num=2]\u001b[A\n",
      "Epoch 15:  91%|██████████████████████▊  | 61/67 [00:00<00:00, 161.86it/s, loss=0.00462, v_num=2]\u001b[A\n",
      "Epoch 15:  93%|███████████████████████▏ | 62/67 [00:00<00:00, 162.53it/s, loss=0.00462, v_num=2]\u001b[A\n",
      "Epoch 15:  94%|███████████████████████▌ | 63/67 [00:00<00:00, 163.17it/s, loss=0.00462, v_num=2]\u001b[A\n",
      "Epoch 15:  96%|███████████████████████▉ | 64/67 [00:00<00:00, 163.87it/s, loss=0.00462, v_num=2]\u001b[A\n",
      "Epoch 15:  97%|████████████████████████▎| 65/67 [00:00<00:00, 164.52it/s, loss=0.00462, v_num=2]\u001b[A\n",
      "Epoch 15:  99%|████████████████████████▋| 66/67 [00:00<00:00, 165.15it/s, loss=0.00462, v_num=2]\u001b[A\n",
      "Epoch 15: 100%|█████████████████████████| 67/67 [00:00<00:00, 165.18it/s, loss=0.00462, v_num=2]\u001b[A\n",
      "Epoch 16:  88%|██████████████████████   | 59/67 [00:00<00:00, 160.03it/s, loss=0.00448, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 16:  90%|██████████████████████▍  | 60/67 [00:00<00:00, 158.71it/s, loss=0.00448, v_num=2]\u001b[A\n",
      "Epoch 16:  91%|██████████████████████▊  | 61/67 [00:00<00:00, 159.66it/s, loss=0.00448, v_num=2]\u001b[A\n",
      "Epoch 16:  93%|███████████████████████▏ | 62/67 [00:00<00:00, 160.63it/s, loss=0.00448, v_num=2]\u001b[A\n",
      "Epoch 16:  94%|███████████████████████▌ | 63/67 [00:00<00:00, 161.54it/s, loss=0.00448, v_num=2]\u001b[A\n",
      "Epoch 16:  96%|███████████████████████▉ | 64/67 [00:00<00:00, 162.47it/s, loss=0.00448, v_num=2]\u001b[A\n",
      "Epoch 16:  97%|████████████████████████▎| 65/67 [00:00<00:00, 163.40it/s, loss=0.00448, v_num=2]\u001b[A\n",
      "Epoch 16:  99%|████████████████████████▋| 66/67 [00:00<00:00, 164.29it/s, loss=0.00448, v_num=2]\u001b[A\n",
      "Epoch 16: 100%|█████████████████████████| 67/67 [00:00<00:00, 164.59it/s, loss=0.00448, v_num=2]\u001b[A\n",
      "Epoch 17:  88%|██████████████████████▉   | 59/67 [00:00<00:00, 163.20it/s, loss=0.0042, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 17:  90%|███████████████████████▎  | 60/67 [00:00<00:00, 161.79it/s, loss=0.0042, v_num=2]\u001b[A\n",
      "Epoch 17:  91%|███████████████████████▋  | 61/67 [00:00<00:00, 162.50it/s, loss=0.0042, v_num=2]\u001b[A\n",
      "Epoch 17:  93%|████████████████████████  | 62/67 [00:00<00:00, 163.43it/s, loss=0.0042, v_num=2]\u001b[A\n",
      "Epoch 17:  94%|████████████████████████▍ | 63/67 [00:00<00:00, 164.40it/s, loss=0.0042, v_num=2]\u001b[A\n",
      "Epoch 17:  96%|████████████████████████▊ | 64/67 [00:00<00:00, 165.31it/s, loss=0.0042, v_num=2]\u001b[A\n",
      "Epoch 17:  97%|█████████████████████████▏| 65/67 [00:00<00:00, 166.21it/s, loss=0.0042, v_num=2]\u001b[A\n",
      "Epoch 17:  99%|█████████████████████████▌| 66/67 [00:00<00:00, 167.08it/s, loss=0.0042, v_num=2]\u001b[A\n",
      "Epoch 17: 100%|██████████████████████████| 67/67 [00:00<00:00, 167.37it/s, loss=0.0042, v_num=2]\u001b[A\n",
      "Epoch 18:  88%|██████████████████████   | 59/67 [00:00<00:00, 162.24it/s, loss=0.00391, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 18:  90%|██████████████████████▍  | 60/67 [00:00<00:00, 160.89it/s, loss=0.00391, v_num=2]\u001b[A\n",
      "Epoch 18:  91%|██████████████████████▊  | 61/67 [00:00<00:00, 161.69it/s, loss=0.00391, v_num=2]\u001b[A\n",
      "Epoch 18:  93%|███████████████████████▏ | 62/67 [00:00<00:00, 162.48it/s, loss=0.00391, v_num=2]\u001b[A\n",
      "Epoch 18:  94%|███████████████████████▌ | 63/67 [00:00<00:00, 163.28it/s, loss=0.00391, v_num=2]\u001b[A\n",
      "Epoch 18:  96%|███████████████████████▉ | 64/67 [00:00<00:00, 164.04it/s, loss=0.00391, v_num=2]\u001b[A\n",
      "Epoch 18:  97%|████████████████████████▎| 65/67 [00:00<00:00, 164.82it/s, loss=0.00391, v_num=2]\u001b[A\n",
      "Epoch 18:  99%|████████████████████████▋| 66/67 [00:00<00:00, 165.58it/s, loss=0.00391, v_num=2]\u001b[A\n",
      "Epoch 18: 100%|█████████████████████████| 67/67 [00:00<00:00, 165.74it/s, loss=0.00391, v_num=2]\u001b[A\n",
      "Epoch 19:  88%|███████████████████████▊   | 59/67 [00:00<00:00, 162.86it/s, loss=0.002, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 19:  90%|████████████████████████▏  | 60/67 [00:00<00:00, 161.53it/s, loss=0.002, v_num=2]\u001b[A\n",
      "Epoch 19:  91%|████████████████████████▌  | 61/67 [00:00<00:00, 162.57it/s, loss=0.002, v_num=2]\u001b[A\n",
      "Epoch 19:  93%|████████████████████████▉  | 62/67 [00:00<00:00, 163.61it/s, loss=0.002, v_num=2]\u001b[A\n",
      "Epoch 19:  94%|█████████████████████████▍ | 63/67 [00:00<00:00, 164.62it/s, loss=0.002, v_num=2]\u001b[A\n",
      "Epoch 19:  96%|█████████████████████████▊ | 64/67 [00:00<00:00, 165.58it/s, loss=0.002, v_num=2]\u001b[A\n",
      "Epoch 19:  97%|██████████████████████████▏| 65/67 [00:00<00:00, 166.56it/s, loss=0.002, v_num=2]\u001b[A\n",
      "Epoch 19:  99%|██████████████████████████▌| 66/67 [00:00<00:00, 167.47it/s, loss=0.002, v_num=2]\u001b[A\n",
      "Epoch 19: 100%|███████████████████████████| 67/67 [00:00<00:00, 167.85it/s, loss=0.002, v_num=2]\u001b[A\n",
      "Epoch 20:  88%|██████████████████████   | 59/67 [00:00<00:00, 164.40it/s, loss=0.00266, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 20:  90%|██████████████████████▍  | 60/67 [00:00<00:00, 162.96it/s, loss=0.00266, v_num=2]\u001b[A\n",
      "Epoch 20:  91%|██████████████████████▊  | 61/67 [00:00<00:00, 163.77it/s, loss=0.00266, v_num=2]\u001b[A\n",
      "Epoch 20:  93%|███████████████████████▏ | 62/67 [00:00<00:00, 164.55it/s, loss=0.00266, v_num=2]\u001b[A\n",
      "Epoch 20:  94%|███████████████████████▌ | 63/67 [00:00<00:00, 165.34it/s, loss=0.00266, v_num=2]\u001b[A\n",
      "Epoch 20:  96%|███████████████████████▉ | 64/67 [00:00<00:00, 166.14it/s, loss=0.00266, v_num=2]\u001b[A\n",
      "Epoch 20:  97%|████████████████████████▎| 65/67 [00:00<00:00, 166.88it/s, loss=0.00266, v_num=2]\u001b[A\n",
      "Epoch 20:  99%|████████████████████████▋| 66/67 [00:00<00:00, 167.62it/s, loss=0.00266, v_num=2]\u001b[A\n",
      "Epoch 20: 100%|█████████████████████████| 67/67 [00:00<00:00, 167.75it/s, loss=0.00266, v_num=2]\u001b[A\n",
      "Epoch 21:  88%|██████████████████████   | 59/67 [00:00<00:00, 162.26it/s, loss=0.00173, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 21:  90%|██████████████████████▍  | 60/67 [00:00<00:00, 160.75it/s, loss=0.00173, v_num=2]\u001b[A\n",
      "Epoch 21:  91%|██████████████████████▊  | 61/67 [00:00<00:00, 161.55it/s, loss=0.00173, v_num=2]\u001b[A\n",
      "Epoch 21:  93%|███████████████████████▏ | 62/67 [00:00<00:00, 162.32it/s, loss=0.00173, v_num=2]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  94%|███████████████████████▌ | 63/67 [00:00<00:00, 163.07it/s, loss=0.00173, v_num=2]\u001b[A\n",
      "Epoch 21:  96%|███████████████████████▉ | 64/67 [00:00<00:00, 163.86it/s, loss=0.00173, v_num=2]\u001b[A\n",
      "Epoch 21:  97%|████████████████████████▎| 65/67 [00:00<00:00, 164.61it/s, loss=0.00173, v_num=2]\u001b[A\n",
      "Epoch 21:  99%|████████████████████████▋| 66/67 [00:00<00:00, 165.31it/s, loss=0.00173, v_num=2]\u001b[A\n",
      "Epoch 21: 100%|█████████████████████████| 67/67 [00:00<00:00, 165.46it/s, loss=0.00173, v_num=2]\u001b[A\n",
      "Epoch 22:  88%|██████████████████████   | 59/67 [00:00<00:00, 163.72it/s, loss=0.00255, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 22:  90%|██████████████████████▍  | 60/67 [00:00<00:00, 162.28it/s, loss=0.00255, v_num=2]\u001b[A\n",
      "Epoch 22:  91%|██████████████████████▊  | 61/67 [00:00<00:00, 163.04it/s, loss=0.00255, v_num=2]\u001b[A\n",
      "Epoch 22:  93%|███████████████████████▏ | 62/67 [00:00<00:00, 163.75it/s, loss=0.00255, v_num=2]\u001b[A\n",
      "Epoch 22:  94%|███████████████████████▌ | 63/67 [00:00<00:00, 164.45it/s, loss=0.00255, v_num=2]\u001b[A\n",
      "Epoch 22:  96%|███████████████████████▉ | 64/67 [00:00<00:00, 165.15it/s, loss=0.00255, v_num=2]\u001b[A\n",
      "Epoch 22:  97%|████████████████████████▎| 65/67 [00:00<00:00, 166.05it/s, loss=0.00255, v_num=2]\u001b[A\n",
      "Epoch 22:  99%|████████████████████████▋| 66/67 [00:00<00:00, 166.88it/s, loss=0.00255, v_num=2]\u001b[A\n",
      "Epoch 22: 100%|█████████████████████████| 67/67 [00:00<00:00, 167.21it/s, loss=0.00255, v_num=2]\u001b[A\n",
      "Epoch 23:  88%|██████████████████████▉   | 59/67 [00:00<00:00, 163.04it/s, loss=0.0012, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 23:  90%|███████████████████████▎  | 60/67 [00:00<00:00, 161.71it/s, loss=0.0012, v_num=2]\u001b[A\n",
      "Epoch 23:  91%|███████████████████████▋  | 61/67 [00:00<00:00, 162.50it/s, loss=0.0012, v_num=2]\u001b[A\n",
      "Epoch 23:  93%|████████████████████████  | 62/67 [00:00<00:00, 163.27it/s, loss=0.0012, v_num=2]\u001b[A\n",
      "Epoch 23:  94%|████████████████████████▍ | 63/67 [00:00<00:00, 164.05it/s, loss=0.0012, v_num=2]\u001b[A\n",
      "Epoch 23:  96%|████████████████████████▊ | 64/67 [00:00<00:00, 164.79it/s, loss=0.0012, v_num=2]\u001b[A\n",
      "Epoch 23:  97%|█████████████████████████▏| 65/67 [00:00<00:00, 165.53it/s, loss=0.0012, v_num=2]\u001b[A\n",
      "Epoch 23:  99%|█████████████████████████▌| 66/67 [00:00<00:00, 166.26it/s, loss=0.0012, v_num=2]\u001b[A\n",
      "Epoch 23: 100%|██████████████████████████| 67/67 [00:00<00:00, 166.34it/s, loss=0.0012, v_num=2]\u001b[A\n",
      "Epoch 24:  88%|██████████████████████   | 59/67 [00:00<00:00, 165.36it/s, loss=0.00194, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 24:  90%|██████████████████████▍  | 60/67 [00:00<00:00, 163.89it/s, loss=0.00194, v_num=2]\u001b[A\n",
      "Epoch 24:  91%|██████████████████████▊  | 61/67 [00:00<00:00, 164.63it/s, loss=0.00194, v_num=2]\u001b[A\n",
      "Epoch 24:  93%|███████████████████████▏ | 62/67 [00:00<00:00, 165.34it/s, loss=0.00194, v_num=2]\u001b[A\n",
      "Epoch 24:  94%|███████████████████████▌ | 63/67 [00:00<00:00, 166.06it/s, loss=0.00194, v_num=2]\u001b[A\n",
      "Epoch 24:  96%|███████████████████████▉ | 64/67 [00:00<00:00, 166.76it/s, loss=0.00194, v_num=2]\u001b[A\n",
      "Epoch 24:  97%|████████████████████████▎| 65/67 [00:00<00:00, 167.40it/s, loss=0.00194, v_num=2]\u001b[A\n",
      "Epoch 24:  99%|████████████████████████▋| 66/67 [00:00<00:00, 168.12it/s, loss=0.00194, v_num=2]\u001b[A\n",
      "Epoch 24: 100%|█████████████████████████| 67/67 [00:00<00:00, 168.21it/s, loss=0.00194, v_num=2]\u001b[A\n",
      "Epoch 25:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 165.87it/s, loss=0.000911, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 25:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 164.35it/s, loss=0.000911, v_num=2]\u001b[A\n",
      "Epoch 25:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 165.06it/s, loss=0.000911, v_num=2]\u001b[A\n",
      "Epoch 25:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 165.76it/s, loss=0.000911, v_num=2]\u001b[A\n",
      "Epoch 25:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 166.44it/s, loss=0.000911, v_num=2]\u001b[A\n",
      "Epoch 25:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 167.09it/s, loss=0.000911, v_num=2]\u001b[A\n",
      "Epoch 25:  97%|███████████████████████▎| 65/67 [00:00<00:00, 167.73it/s, loss=0.000911, v_num=2]\u001b[A\n",
      "Epoch 25:  99%|███████████████████████▋| 66/67 [00:00<00:00, 168.36it/s, loss=0.000911, v_num=2]\u001b[A\n",
      "Epoch 25: 100%|████████████████████████| 67/67 [00:00<00:00, 168.35it/s, loss=0.000911, v_num=2]\u001b[A\n",
      "Epoch 26:  88%|██████████████████████   | 59/67 [00:00<00:00, 161.95it/s, loss=0.00111, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 26:  90%|██████████████████████▍  | 60/67 [00:00<00:00, 160.56it/s, loss=0.00111, v_num=2]\u001b[A\n",
      "Epoch 26:  91%|██████████████████████▊  | 61/67 [00:00<00:00, 161.29it/s, loss=0.00111, v_num=2]\u001b[A\n",
      "Epoch 26:  93%|███████████████████████▏ | 62/67 [00:00<00:00, 162.02it/s, loss=0.00111, v_num=2]\u001b[A\n",
      "Epoch 26:  94%|███████████████████████▌ | 63/67 [00:00<00:00, 162.73it/s, loss=0.00111, v_num=2]\u001b[A\n",
      "Epoch 26:  96%|███████████████████████▉ | 64/67 [00:00<00:00, 163.40it/s, loss=0.00111, v_num=2]\u001b[A\n",
      "Epoch 26:  97%|████████████████████████▎| 65/67 [00:00<00:00, 164.08it/s, loss=0.00111, v_num=2]\u001b[A\n",
      "Epoch 26:  99%|████████████████████████▋| 66/67 [00:00<00:00, 164.71it/s, loss=0.00111, v_num=2]\u001b[A\n",
      "Epoch 26: 100%|█████████████████████████| 67/67 [00:00<00:00, 164.75it/s, loss=0.00111, v_num=2]\u001b[A\n",
      "Epoch 27:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 162.23it/s, loss=0.000834, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 27:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 160.87it/s, loss=0.000834, v_num=2]\u001b[A\n",
      "Epoch 27:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 161.58it/s, loss=0.000834, v_num=2]\u001b[A\n",
      "Epoch 27:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 162.31it/s, loss=0.000834, v_num=2]\u001b[A\n",
      "Epoch 27:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 163.03it/s, loss=0.000834, v_num=2]\u001b[A\n",
      "Epoch 27:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 163.79it/s, loss=0.000834, v_num=2]\u001b[A\n",
      "Epoch 27:  97%|███████████████████████▎| 65/67 [00:00<00:00, 164.48it/s, loss=0.000834, v_num=2]\u001b[A\n",
      "Epoch 27:  99%|███████████████████████▋| 66/67 [00:00<00:00, 165.17it/s, loss=0.000834, v_num=2]\u001b[A\n",
      "Epoch 27: 100%|████████████████████████| 67/67 [00:00<00:00, 165.23it/s, loss=0.000834, v_num=2]\u001b[A\n",
      "Epoch 28:  88%|██████████████████████   | 59/67 [00:00<00:00, 161.89it/s, loss=0.00154, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 28:  90%|██████████████████████▍  | 60/67 [00:00<00:00, 160.42it/s, loss=0.00154, v_num=2]\u001b[A\n",
      "Epoch 28:  91%|██████████████████████▊  | 61/67 [00:00<00:00, 161.13it/s, loss=0.00154, v_num=2]\u001b[A\n",
      "Epoch 28:  93%|███████████████████████▏ | 62/67 [00:00<00:00, 161.82it/s, loss=0.00154, v_num=2]\u001b[A\n",
      "Epoch 28:  94%|███████████████████████▌ | 63/67 [00:00<00:00, 162.44it/s, loss=0.00154, v_num=2]\u001b[A\n",
      "Epoch 28:  96%|███████████████████████▉ | 64/67 [00:00<00:00, 163.13it/s, loss=0.00154, v_num=2]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28:  97%|████████████████████████▎| 65/67 [00:00<00:00, 163.75it/s, loss=0.00154, v_num=2]\u001b[A\n",
      "Epoch 28:  99%|████████████████████████▋| 66/67 [00:00<00:00, 164.37it/s, loss=0.00154, v_num=2]\u001b[A\n",
      "Epoch 28: 100%|█████████████████████████| 67/67 [00:00<00:00, 164.36it/s, loss=0.00154, v_num=2]\u001b[A\n",
      "Epoch 29:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 166.35it/s, loss=0.000646, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 29:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 165.28it/s, loss=0.000646, v_num=2]\u001b[A\n",
      "Epoch 29:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 166.39it/s, loss=0.000646, v_num=2]\u001b[A\n",
      "Epoch 29:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 167.53it/s, loss=0.000646, v_num=2]\u001b[A\n",
      "Epoch 29:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 168.64it/s, loss=0.000646, v_num=2]\u001b[A\n",
      "Epoch 29:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 169.75it/s, loss=0.000646, v_num=2]\u001b[A\n",
      "Epoch 29:  97%|███████████████████████▎| 65/67 [00:00<00:00, 170.81it/s, loss=0.000646, v_num=2]\u001b[A\n",
      "Epoch 29:  99%|███████████████████████▋| 66/67 [00:00<00:00, 171.87it/s, loss=0.000646, v_num=2]\u001b[A\n",
      "Epoch 29: 100%|████████████████████████| 67/67 [00:00<00:00, 172.12it/s, loss=0.000646, v_num=2]\u001b[A\n",
      "Epoch 30:  88%|██████████████████████▉   | 59/67 [00:00<00:00, 172.72it/s, loss=0.0011, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 30:  90%|███████████████████████▎  | 60/67 [00:00<00:00, 171.43it/s, loss=0.0011, v_num=2]\u001b[A\n",
      "Epoch 30:  91%|███████████████████████▋  | 61/67 [00:00<00:00, 172.32it/s, loss=0.0011, v_num=2]\u001b[A\n",
      "Epoch 30:  93%|████████████████████████  | 62/67 [00:00<00:00, 173.01it/s, loss=0.0011, v_num=2]\u001b[A\n",
      "Epoch 30:  94%|████████████████████████▍ | 63/67 [00:00<00:00, 173.96it/s, loss=0.0011, v_num=2]\u001b[A\n",
      "Epoch 30:  96%|████████████████████████▊ | 64/67 [00:00<00:00, 174.80it/s, loss=0.0011, v_num=2]\u001b[A\n",
      "Epoch 30:  97%|█████████████████████████▏| 65/67 [00:00<00:00, 175.38it/s, loss=0.0011, v_num=2]\u001b[A\n",
      "Epoch 30:  99%|█████████████████████████▌| 66/67 [00:00<00:00, 176.24it/s, loss=0.0011, v_num=2]\u001b[A\n",
      "Epoch 30: 100%|██████████████████████████| 67/67 [00:00<00:00, 176.38it/s, loss=0.0011, v_num=2]\u001b[A\n",
      "Epoch 31:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 174.07it/s, loss=0.000588, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 31:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 172.74it/s, loss=0.000588, v_num=2]\u001b[A\n",
      "Epoch 31:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 173.49it/s, loss=0.000588, v_num=2]\u001b[A\n",
      "Epoch 31:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 174.27it/s, loss=0.000588, v_num=2]\u001b[A\n",
      "Epoch 31:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 175.05it/s, loss=0.000588, v_num=2]\u001b[A\n",
      "Epoch 31:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 175.80it/s, loss=0.000588, v_num=2]\u001b[A\n",
      "Epoch 31:  97%|███████████████████████▎| 65/67 [00:00<00:00, 176.39it/s, loss=0.000588, v_num=2]\u001b[A\n",
      "Epoch 31:  99%|███████████████████████▋| 66/67 [00:00<00:00, 177.13it/s, loss=0.000588, v_num=2]\u001b[A\n",
      "Epoch 31: 100%|████████████████████████| 67/67 [00:00<00:00, 177.42it/s, loss=0.000588, v_num=2]\u001b[A\n",
      "Epoch 32:  88%|██████████████████████   | 59/67 [00:00<00:00, 168.43it/s, loss=0.00112, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 32:  90%|██████████████████████▍  | 60/67 [00:00<00:00, 167.33it/s, loss=0.00112, v_num=2]\u001b[A\n",
      "Epoch 32:  91%|██████████████████████▊  | 61/67 [00:00<00:00, 168.29it/s, loss=0.00112, v_num=2]\u001b[A\n",
      "Epoch 32:  93%|███████████████████████▏ | 62/67 [00:00<00:00, 169.13it/s, loss=0.00112, v_num=2]\u001b[A\n",
      "Epoch 32:  94%|███████████████████████▌ | 63/67 [00:00<00:00, 169.95it/s, loss=0.00112, v_num=2]\u001b[A\n",
      "Epoch 32:  96%|███████████████████████▉ | 64/67 [00:00<00:00, 170.83it/s, loss=0.00112, v_num=2]\u001b[A\n",
      "Epoch 32:  97%|████████████████████████▎| 65/67 [00:00<00:00, 171.67it/s, loss=0.00112, v_num=2]\u001b[A\n",
      "Epoch 32:  99%|████████████████████████▋| 66/67 [00:00<00:00, 172.46it/s, loss=0.00112, v_num=2]\u001b[A\n",
      "Epoch 32: 100%|█████████████████████████| 67/67 [00:00<00:00, 172.73it/s, loss=0.00112, v_num=2]\u001b[A\n",
      "Epoch 33:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 170.97it/s, loss=0.000518, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 33:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 169.90it/s, loss=0.000518, v_num=2]\u001b[A\n",
      "Epoch 33:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 170.85it/s, loss=0.000518, v_num=2]\u001b[A\n",
      "Epoch 33:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 171.80it/s, loss=0.000518, v_num=2]\u001b[A\n",
      "Epoch 33:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 172.73it/s, loss=0.000518, v_num=2]\u001b[A\n",
      "Epoch 33:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 173.64it/s, loss=0.000518, v_num=2]\u001b[A\n",
      "Epoch 33:  97%|███████████████████████▎| 65/67 [00:00<00:00, 174.53it/s, loss=0.000518, v_num=2]\u001b[A\n",
      "Epoch 33:  99%|███████████████████████▋| 66/67 [00:00<00:00, 175.39it/s, loss=0.000518, v_num=2]\u001b[A\n",
      "Epoch 33: 100%|████████████████████████| 67/67 [00:00<00:00, 175.64it/s, loss=0.000518, v_num=2]\u001b[A\n",
      "Epoch 34:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 173.20it/s, loss=0.000911, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 34:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 172.00it/s, loss=0.000911, v_num=2]\u001b[A\n",
      "Epoch 34:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 172.92it/s, loss=0.000911, v_num=2]\u001b[A\n",
      "Epoch 34:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 173.85it/s, loss=0.000911, v_num=2]\u001b[A\n",
      "Epoch 34:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 174.94it/s, loss=0.000911, v_num=2]\u001b[A\n",
      "Epoch 34:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 176.05it/s, loss=0.000911, v_num=2]\u001b[A\n",
      "Epoch 34:  97%|███████████████████████▎| 65/67 [00:00<00:00, 177.12it/s, loss=0.000911, v_num=2]\u001b[A\n",
      "Epoch 34:  99%|███████████████████████▋| 66/67 [00:00<00:00, 178.21it/s, loss=0.000911, v_num=2]\u001b[A\n",
      "Epoch 34: 100%|████████████████████████| 67/67 [00:00<00:00, 178.64it/s, loss=0.000911, v_num=2]\u001b[A\n",
      "Epoch 35:  88%|██████████████████████   | 59/67 [00:00<00:00, 172.16it/s, loss=0.00048, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 35:  90%|██████████████████████▍  | 60/67 [00:00<00:00, 171.06it/s, loss=0.00048, v_num=2]\u001b[A\n",
      "Epoch 35:  91%|██████████████████████▊  | 61/67 [00:00<00:00, 171.87it/s, loss=0.00048, v_num=2]\u001b[A\n",
      "Epoch 35:  93%|███████████████████████▏ | 62/67 [00:00<00:00, 172.86it/s, loss=0.00048, v_num=2]\u001b[A\n",
      "Epoch 35:  94%|███████████████████████▌ | 63/67 [00:00<00:00, 173.71it/s, loss=0.00048, v_num=2]\u001b[A\n",
      "Epoch 35:  96%|███████████████████████▉ | 64/67 [00:00<00:00, 174.45it/s, loss=0.00048, v_num=2]\u001b[A\n",
      "Epoch 35:  97%|████████████████████████▎| 65/67 [00:00<00:00, 175.15it/s, loss=0.00048, v_num=2]\u001b[A\n",
      "Epoch 35:  99%|████████████████████████▋| 66/67 [00:00<00:00, 176.07it/s, loss=0.00048, v_num=2]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|█████████████████████████| 67/67 [00:00<00:00, 176.30it/s, loss=0.00048, v_num=2]\u001b[A\n",
      "Epoch 36:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 171.30it/s, loss=0.000804, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 36:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 170.21it/s, loss=0.000804, v_num=2]\u001b[A\n",
      "Epoch 36:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 171.36it/s, loss=0.000804, v_num=2]\u001b[A\n",
      "Epoch 36:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 172.51it/s, loss=0.000804, v_num=2]\u001b[A\n",
      "Epoch 36:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 173.65it/s, loss=0.000804, v_num=2]\u001b[A\n",
      "Epoch 36:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 174.75it/s, loss=0.000804, v_num=2]\u001b[A\n",
      "Epoch 36:  97%|███████████████████████▎| 65/67 [00:00<00:00, 175.85it/s, loss=0.000804, v_num=2]\u001b[A\n",
      "Epoch 36:  99%|███████████████████████▋| 66/67 [00:00<00:00, 176.90it/s, loss=0.000804, v_num=2]\u001b[A\n",
      "Epoch 36: 100%|████████████████████████| 67/67 [00:00<00:00, 177.38it/s, loss=0.000804, v_num=2]\u001b[A\n",
      "Epoch 37:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 170.51it/s, loss=0.000416, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 37:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 169.07it/s, loss=0.000416, v_num=2]\u001b[A\n",
      "Epoch 37:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 170.12it/s, loss=0.000416, v_num=2]\u001b[A\n",
      "Epoch 37:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 171.17it/s, loss=0.000416, v_num=2]\u001b[A\n",
      "Epoch 37:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 172.20it/s, loss=0.000416, v_num=2]\u001b[A\n",
      "Epoch 37:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 173.21it/s, loss=0.000416, v_num=2]\u001b[A\n",
      "Epoch 37:  97%|███████████████████████▎| 65/67 [00:00<00:00, 174.19it/s, loss=0.000416, v_num=2]\u001b[A\n",
      "Epoch 37:  99%|███████████████████████▋| 66/67 [00:00<00:00, 175.17it/s, loss=0.000416, v_num=2]\u001b[A\n",
      "Epoch 37: 100%|████████████████████████| 67/67 [00:00<00:00, 175.50it/s, loss=0.000416, v_num=2]\u001b[A\n",
      "Epoch 38:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 171.16it/s, loss=0.000709, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 38:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 169.98it/s, loss=0.000709, v_num=2]\u001b[A\n",
      "Epoch 38:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 170.84it/s, loss=0.000709, v_num=2]\u001b[A\n",
      "Epoch 38:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 171.47it/s, loss=0.000709, v_num=2]\u001b[A\n",
      "Epoch 38:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 172.32it/s, loss=0.000709, v_num=2]\u001b[A\n",
      "Epoch 38:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 173.30it/s, loss=0.000709, v_num=2]\u001b[A\n",
      "Epoch 38:  97%|███████████████████████▎| 65/67 [00:00<00:00, 174.15it/s, loss=0.000709, v_num=2]\u001b[A\n",
      "Epoch 38:  99%|███████████████████████▋| 66/67 [00:00<00:00, 175.22it/s, loss=0.000709, v_num=2]\u001b[A\n",
      "Epoch 38: 100%|████████████████████████| 67/67 [00:00<00:00, 175.72it/s, loss=0.000709, v_num=2]\u001b[A\n",
      "Epoch 39:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 170.34it/s, loss=0.000388, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 39:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 169.17it/s, loss=0.000388, v_num=2]\u001b[A\n",
      "Epoch 39:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 170.23it/s, loss=0.000388, v_num=2]\u001b[A\n",
      "Epoch 39:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 171.26it/s, loss=0.000388, v_num=2]\u001b[A\n",
      "Epoch 39:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 172.10it/s, loss=0.000388, v_num=2]\u001b[A\n",
      "Epoch 39:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 173.12it/s, loss=0.000388, v_num=2]\u001b[A\n",
      "Epoch 39:  97%|███████████████████████▎| 65/67 [00:00<00:00, 174.09it/s, loss=0.000388, v_num=2]\u001b[A\n",
      "Epoch 39:  99%|███████████████████████▋| 66/67 [00:00<00:00, 175.06it/s, loss=0.000388, v_num=2]\u001b[A\n",
      "Epoch 39: 100%|████████████████████████| 67/67 [00:00<00:00, 175.41it/s, loss=0.000388, v_num=2]\u001b[A\n",
      "Epoch 40:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 170.02it/s, loss=0.000614, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 40:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 168.88it/s, loss=0.000614, v_num=2]\u001b[A\n",
      "Epoch 40:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 169.70it/s, loss=0.000614, v_num=2]\u001b[A\n",
      "Epoch 40:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 170.52it/s, loss=0.000614, v_num=2]\u001b[A\n",
      "Epoch 40:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 171.30it/s, loss=0.000614, v_num=2]\u001b[A\n",
      "Epoch 40:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 171.85it/s, loss=0.000614, v_num=2]\u001b[A\n",
      "Epoch 40:  97%|███████████████████████▎| 65/67 [00:00<00:00, 172.52it/s, loss=0.000614, v_num=2]\u001b[A\n",
      "Epoch 40:  99%|███████████████████████▋| 66/67 [00:00<00:00, 173.39it/s, loss=0.000614, v_num=2]\u001b[A\n",
      "Epoch 40: 100%|████████████████████████| 67/67 [00:00<00:00, 173.51it/s, loss=0.000614, v_num=2]\u001b[A\n",
      "Epoch 41:  88%|██████████████████████   | 59/67 [00:00<00:00, 173.98it/s, loss=0.00036, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 41:  90%|██████████████████████▍  | 60/67 [00:00<00:00, 172.88it/s, loss=0.00036, v_num=2]\u001b[A\n",
      "Epoch 41:  91%|██████████████████████▊  | 61/67 [00:00<00:00, 174.06it/s, loss=0.00036, v_num=2]\u001b[A\n",
      "Epoch 41:  93%|███████████████████████▏ | 62/67 [00:00<00:00, 175.18it/s, loss=0.00036, v_num=2]\u001b[A\n",
      "Epoch 41:  94%|███████████████████████▌ | 63/67 [00:00<00:00, 176.30it/s, loss=0.00036, v_num=2]\u001b[A\n",
      "Epoch 41:  96%|███████████████████████▉ | 64/67 [00:00<00:00, 177.39it/s, loss=0.00036, v_num=2]\u001b[A\n",
      "Epoch 41:  97%|████████████████████████▎| 65/67 [00:00<00:00, 178.41it/s, loss=0.00036, v_num=2]\u001b[A\n",
      "Epoch 41:  99%|████████████████████████▋| 66/67 [00:00<00:00, 179.35it/s, loss=0.00036, v_num=2]\u001b[A\n",
      "Epoch 41: 100%|█████████████████████████| 67/67 [00:00<00:00, 179.62it/s, loss=0.00036, v_num=2]\u001b[A\n",
      "Epoch 42:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 173.64it/s, loss=0.000559, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 42:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 172.46it/s, loss=0.000559, v_num=2]\u001b[A\n",
      "Epoch 42:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 173.30it/s, loss=0.000559, v_num=2]\u001b[A\n",
      "Epoch 42:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 174.08it/s, loss=0.000559, v_num=2]\u001b[A\n",
      "Epoch 42:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 174.93it/s, loss=0.000559, v_num=2]\u001b[A\n",
      "Epoch 42:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 175.69it/s, loss=0.000559, v_num=2]\u001b[A\n",
      "Epoch 42:  97%|███████████████████████▎| 65/67 [00:00<00:00, 176.47it/s, loss=0.000559, v_num=2]\u001b[A\n",
      "Epoch 42:  99%|███████████████████████▋| 66/67 [00:00<00:00, 177.23it/s, loss=0.000559, v_num=2]\u001b[A\n",
      "Epoch 42: 100%|████████████████████████| 67/67 [00:00<00:00, 177.31it/s, loss=0.000559, v_num=2]\u001b[A\n",
      "Epoch 43:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 166.69it/s, loss=0.000339, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 43:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 165.71it/s, loss=0.000339, v_num=2]\u001b[A\n",
      "Epoch 43:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 166.70it/s, loss=0.000339, v_num=2]\u001b[A\n",
      "Epoch 43:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 167.74it/s, loss=0.000339, v_num=2]\u001b[A\n",
      "Epoch 43:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 168.78it/s, loss=0.000339, v_num=2]\u001b[A\n",
      "Epoch 43:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 169.79it/s, loss=0.000339, v_num=2]\u001b[A\n",
      "Epoch 43:  97%|███████████████████████▎| 65/67 [00:00<00:00, 170.80it/s, loss=0.000339, v_num=2]\u001b[A\n",
      "Epoch 43:  99%|███████████████████████▋| 66/67 [00:00<00:00, 171.79it/s, loss=0.000339, v_num=2]\u001b[A\n",
      "Epoch 43: 100%|████████████████████████| 67/67 [00:00<00:00, 171.87it/s, loss=0.000339, v_num=2]\u001b[A\n",
      "Epoch 44:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 172.65it/s, loss=0.000511, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 44:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 171.59it/s, loss=0.000511, v_num=2]\u001b[A\n",
      "Epoch 44:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 172.55it/s, loss=0.000511, v_num=2]\u001b[A\n",
      "Epoch 44:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 173.46it/s, loss=0.000511, v_num=2]\u001b[A\n",
      "Epoch 44:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 174.30it/s, loss=0.000511, v_num=2]\u001b[A\n",
      "Epoch 44:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 175.15it/s, loss=0.000511, v_num=2]\u001b[A\n",
      "Epoch 44:  97%|███████████████████████▎| 65/67 [00:00<00:00, 175.98it/s, loss=0.000511, v_num=2]\u001b[A\n",
      "Epoch 44:  99%|███████████████████████▋| 66/67 [00:00<00:00, 176.82it/s, loss=0.000511, v_num=2]\u001b[A\n",
      "Epoch 44: 100%|████████████████████████| 67/67 [00:00<00:00, 177.05it/s, loss=0.000511, v_num=2]\u001b[A\n",
      "Epoch 45:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 171.56it/s, loss=0.000323, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 45:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 170.32it/s, loss=0.000323, v_num=2]\u001b[A\n",
      "Epoch 45:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 171.17it/s, loss=0.000323, v_num=2]\u001b[A\n",
      "Epoch 45:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 172.01it/s, loss=0.000323, v_num=2]\u001b[A\n",
      "Epoch 45:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 172.61it/s, loss=0.000323, v_num=2]\u001b[A\n",
      "Epoch 45:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 173.60it/s, loss=0.000323, v_num=2]\u001b[A\n",
      "Epoch 45:  97%|███████████████████████▎| 65/67 [00:00<00:00, 174.50it/s, loss=0.000323, v_num=2]\u001b[A\n",
      "Epoch 45:  99%|███████████████████████▋| 66/67 [00:00<00:00, 175.37it/s, loss=0.000323, v_num=2]\u001b[A\n",
      "Epoch 45: 100%|████████████████████████| 67/67 [00:00<00:00, 174.97it/s, loss=0.000323, v_num=2]\u001b[A\n",
      "Epoch 46:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 169.91it/s, loss=0.000473, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 46:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 168.62it/s, loss=0.000473, v_num=2]\u001b[A\n",
      "Epoch 46:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 169.43it/s, loss=0.000473, v_num=2]\u001b[A\n",
      "Epoch 46:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 170.24it/s, loss=0.000473, v_num=2]\u001b[A\n",
      "Epoch 46:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 171.05it/s, loss=0.000473, v_num=2]\u001b[A\n",
      "Epoch 46:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 171.82it/s, loss=0.000473, v_num=2]\u001b[A\n",
      "Epoch 46:  97%|███████████████████████▎| 65/67 [00:00<00:00, 172.57it/s, loss=0.000473, v_num=2]\u001b[A\n",
      "Epoch 46:  99%|███████████████████████▋| 66/67 [00:00<00:00, 173.30it/s, loss=0.000473, v_num=2]\u001b[A\n",
      "Epoch 46: 100%|████████████████████████| 67/67 [00:00<00:00, 173.39it/s, loss=0.000473, v_num=2]\u001b[A\n",
      "Epoch 47:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 167.96it/s, loss=0.000294, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 47:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 166.85it/s, loss=0.000294, v_num=2]\u001b[A\n",
      "Epoch 47:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 167.93it/s, loss=0.000294, v_num=2]\u001b[A\n",
      "Epoch 47:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 168.94it/s, loss=0.000294, v_num=2]\u001b[A\n",
      "Epoch 47:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 169.97it/s, loss=0.000294, v_num=2]\u001b[A\n",
      "Epoch 47:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 170.98it/s, loss=0.000294, v_num=2]\u001b[A\n",
      "Epoch 47:  97%|███████████████████████▎| 65/67 [00:00<00:00, 171.95it/s, loss=0.000294, v_num=2]\u001b[A\n",
      "Epoch 47:  99%|███████████████████████▋| 66/67 [00:00<00:00, 172.91it/s, loss=0.000294, v_num=2]\u001b[A\n",
      "Epoch 47: 100%|████████████████████████| 67/67 [00:00<00:00, 173.29it/s, loss=0.000294, v_num=2]\u001b[A\n",
      "Epoch 48:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 172.15it/s, loss=0.000446, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 48:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 170.83it/s, loss=0.000446, v_num=2]\u001b[A\n",
      "Epoch 48:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 171.65it/s, loss=0.000446, v_num=2]\u001b[A\n",
      "Epoch 48:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 172.49it/s, loss=0.000446, v_num=2]\u001b[A\n",
      "Epoch 48:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 173.33it/s, loss=0.000446, v_num=2]\u001b[A\n",
      "Epoch 48:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 174.13it/s, loss=0.000446, v_num=2]\u001b[A\n",
      "Epoch 48:  97%|███████████████████████▎| 65/67 [00:00<00:00, 174.93it/s, loss=0.000446, v_num=2]\u001b[A\n",
      "Epoch 48:  99%|███████████████████████▋| 66/67 [00:00<00:00, 175.66it/s, loss=0.000446, v_num=2]\u001b[A\n",
      "Epoch 48: 100%|████████████████████████| 67/67 [00:00<00:00, 175.74it/s, loss=0.000446, v_num=2]\u001b[A\n",
      "Epoch 49:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 171.89it/s, loss=0.000296, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 49:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 170.60it/s, loss=0.000296, v_num=2]\u001b[A\n",
      "Epoch 49:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 171.44it/s, loss=0.000296, v_num=2]\u001b[A\n",
      "Epoch 49:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 172.26it/s, loss=0.000296, v_num=2]\u001b[A\n",
      "Epoch 49:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 173.07it/s, loss=0.000296, v_num=2]\u001b[A\n",
      "Epoch 49:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 173.86it/s, loss=0.000296, v_num=2]\u001b[A\n",
      "Epoch 49:  97%|███████████████████████▎| 65/67 [00:00<00:00, 174.64it/s, loss=0.000296, v_num=2]\u001b[A\n",
      "Epoch 49:  99%|███████████████████████▋| 66/67 [00:00<00:00, 175.41it/s, loss=0.000296, v_num=2]\u001b[A\n",
      "Epoch 49: 100%|████████████████████████| 67/67 [00:00<00:00, 175.56it/s, loss=0.000296, v_num=2]\u001b[A\n",
      "Epoch 50:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 171.20it/s, loss=0.000414, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 169.90it/s, loss=0.000414, v_num=2]\u001b[A\n",
      "Epoch 50:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 170.71it/s, loss=0.000414, v_num=2]\u001b[A\n",
      "Epoch 50:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 171.51it/s, loss=0.000414, v_num=2]\u001b[A\n",
      "Epoch 50:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 172.27it/s, loss=0.000414, v_num=2]\u001b[A\n",
      "Epoch 50:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 173.04it/s, loss=0.000414, v_num=2]\u001b[A\n",
      "Epoch 50:  97%|███████████████████████▎| 65/67 [00:00<00:00, 173.80it/s, loss=0.000414, v_num=2]\u001b[A\n",
      "Epoch 50:  99%|███████████████████████▋| 66/67 [00:00<00:00, 174.54it/s, loss=0.000414, v_num=2]\u001b[A\n",
      "Epoch 50: 100%|████████████████████████| 67/67 [00:00<00:00, 174.66it/s, loss=0.000414, v_num=2]\u001b[A\n",
      "Epoch 51:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 166.56it/s, loss=0.000263, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 51:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 165.30it/s, loss=0.000263, v_num=2]\u001b[A\n",
      "Epoch 51:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 166.16it/s, loss=0.000263, v_num=2]\u001b[A\n",
      "Epoch 51:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 167.04it/s, loss=0.000263, v_num=2]\u001b[A\n",
      "Epoch 51:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 167.83it/s, loss=0.000263, v_num=2]\u001b[A\n",
      "Epoch 51:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 168.60it/s, loss=0.000263, v_num=2]\u001b[A\n",
      "Epoch 51:  97%|███████████████████████▎| 65/67 [00:00<00:00, 169.65it/s, loss=0.000263, v_num=2]\u001b[A\n",
      "Epoch 51:  99%|███████████████████████▋| 66/67 [00:00<00:00, 170.67it/s, loss=0.000263, v_num=2]\u001b[A\n",
      "Epoch 51: 100%|████████████████████████| 67/67 [00:00<00:00, 171.14it/s, loss=0.000263, v_num=2]\u001b[A\n",
      "Epoch 52:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 170.75it/s, loss=0.000394, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 52:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 169.62it/s, loss=0.000394, v_num=2]\u001b[A\n",
      "Epoch 52:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 170.70it/s, loss=0.000394, v_num=2]\u001b[A\n",
      "Epoch 52:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 171.76it/s, loss=0.000394, v_num=2]\u001b[A\n",
      "Epoch 52:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 172.80it/s, loss=0.000394, v_num=2]\u001b[A\n",
      "Epoch 52:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 173.79it/s, loss=0.000394, v_num=2]\u001b[A\n",
      "Epoch 52:  97%|███████████████████████▎| 65/67 [00:00<00:00, 174.70it/s, loss=0.000394, v_num=2]\u001b[A\n",
      "Epoch 52:  99%|███████████████████████▋| 66/67 [00:00<00:00, 175.67it/s, loss=0.000394, v_num=2]\u001b[A\n",
      "Epoch 52: 100%|████████████████████████| 67/67 [00:00<00:00, 175.95it/s, loss=0.000394, v_num=2]\u001b[A\n",
      "Epoch 53:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 173.38it/s, loss=0.000245, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 53:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 172.18it/s, loss=0.000245, v_num=2]\u001b[A\n",
      "Epoch 53:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 173.01it/s, loss=0.000245, v_num=2]\u001b[A\n",
      "Epoch 53:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 173.85it/s, loss=0.000245, v_num=2]\u001b[A\n",
      "Epoch 53:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 174.70it/s, loss=0.000245, v_num=2]\u001b[A\n",
      "Epoch 53:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 175.49it/s, loss=0.000245, v_num=2]\u001b[A\n",
      "Epoch 53:  97%|███████████████████████▎| 65/67 [00:00<00:00, 176.24it/s, loss=0.000245, v_num=2]\u001b[A\n",
      "Epoch 53:  99%|███████████████████████▋| 66/67 [00:00<00:00, 176.98it/s, loss=0.000245, v_num=2]\u001b[A\n",
      "Epoch 53: 100%|████████████████████████| 67/67 [00:00<00:00, 177.09it/s, loss=0.000245, v_num=2]\u001b[A\n",
      "Epoch 54:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 171.32it/s, loss=0.000367, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 54:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 170.11it/s, loss=0.000367, v_num=2]\u001b[A\n",
      "Epoch 54:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 170.98it/s, loss=0.000367, v_num=2]\u001b[A\n",
      "Epoch 54:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 171.84it/s, loss=0.000367, v_num=2]\u001b[A\n",
      "Epoch 54:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 172.69it/s, loss=0.000367, v_num=2]\u001b[A\n",
      "Epoch 54:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 173.46it/s, loss=0.000367, v_num=2]\u001b[A\n",
      "Epoch 54:  97%|███████████████████████▎| 65/67 [00:00<00:00, 174.26it/s, loss=0.000367, v_num=2]\u001b[A\n",
      "Epoch 54:  99%|███████████████████████▋| 66/67 [00:00<00:00, 175.00it/s, loss=0.000367, v_num=2]\u001b[A\n",
      "Epoch 54: 100%|████████████████████████| 67/67 [00:00<00:00, 175.16it/s, loss=0.000367, v_num=2]\u001b[A\n",
      "Epoch 55:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 171.11it/s, loss=0.000223, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 55:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 169.84it/s, loss=0.000223, v_num=2]\u001b[A\n",
      "Epoch 55:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 170.67it/s, loss=0.000223, v_num=2]\u001b[A\n",
      "Epoch 55:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 171.45it/s, loss=0.000223, v_num=2]\u001b[A\n",
      "Epoch 55:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 172.49it/s, loss=0.000223, v_num=2]\u001b[A\n",
      "Epoch 55:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 173.48it/s, loss=0.000223, v_num=2]\u001b[A\n",
      "Epoch 55:  97%|███████████████████████▎| 65/67 [00:00<00:00, 174.49it/s, loss=0.000223, v_num=2]\u001b[A\n",
      "Epoch 55:  99%|███████████████████████▋| 66/67 [00:00<00:00, 175.45it/s, loss=0.000223, v_num=2]\u001b[A\n",
      "Epoch 55: 100%|████████████████████████| 67/67 [00:00<00:00, 175.80it/s, loss=0.000223, v_num=2]\u001b[A\n",
      "Epoch 56:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 167.92it/s, loss=0.000346, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 56:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 166.70it/s, loss=0.000346, v_num=2]\u001b[A\n",
      "Epoch 56:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 167.70it/s, loss=0.000346, v_num=2]\u001b[A\n",
      "Epoch 56:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 168.68it/s, loss=0.000346, v_num=2]\u001b[A\n",
      "Epoch 56:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 169.69it/s, loss=0.000346, v_num=2]\u001b[A\n",
      "Epoch 56:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 170.68it/s, loss=0.000346, v_num=2]\u001b[A\n",
      "Epoch 56:  97%|███████████████████████▎| 65/67 [00:00<00:00, 171.65it/s, loss=0.000346, v_num=2]\u001b[A\n",
      "Epoch 56:  99%|███████████████████████▋| 66/67 [00:00<00:00, 172.59it/s, loss=0.000346, v_num=2]\u001b[A\n",
      "Epoch 56: 100%|████████████████████████| 67/67 [00:00<00:00, 172.95it/s, loss=0.000346, v_num=2]\u001b[A\n",
      "Epoch 57:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 171.77it/s, loss=0.000204, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 57:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 170.69it/s, loss=0.000204, v_num=2]\u001b[A\n",
      "Epoch 57:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 171.65it/s, loss=0.000204, v_num=2]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 172.54it/s, loss=0.000204, v_num=2]\u001b[A\n",
      "Epoch 57:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 173.47it/s, loss=0.000204, v_num=2]\u001b[A\n",
      "Epoch 57:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 174.34it/s, loss=0.000204, v_num=2]\u001b[A\n",
      "Epoch 57:  97%|███████████████████████▎| 65/67 [00:00<00:00, 175.23it/s, loss=0.000204, v_num=2]\u001b[A\n",
      "Epoch 57:  99%|███████████████████████▋| 66/67 [00:00<00:00, 176.10it/s, loss=0.000204, v_num=2]\u001b[A\n",
      "Epoch 57: 100%|████████████████████████| 67/67 [00:00<00:00, 176.33it/s, loss=0.000204, v_num=2]\u001b[A\n",
      "Epoch 58:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 172.18it/s, loss=0.000324, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 58:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 170.97it/s, loss=0.000324, v_num=2]\u001b[A\n",
      "Epoch 58:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 171.78it/s, loss=0.000324, v_num=2]\u001b[A\n",
      "Epoch 58:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 172.61it/s, loss=0.000324, v_num=2]\u001b[A\n",
      "Epoch 58:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 173.44it/s, loss=0.000324, v_num=2]\u001b[A\n",
      "Epoch 58:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 174.22it/s, loss=0.000324, v_num=2]\u001b[A\n",
      "Epoch 58:  97%|███████████████████████▎| 65/67 [00:00<00:00, 174.97it/s, loss=0.000324, v_num=2]\u001b[A\n",
      "Epoch 58:  99%|███████████████████████▋| 66/67 [00:00<00:00, 175.77it/s, loss=0.000324, v_num=2]\u001b[A\n",
      "Epoch 58: 100%|████████████████████████| 67/67 [00:00<00:00, 175.83it/s, loss=0.000324, v_num=2]\u001b[A\n",
      "Epoch 59:  88%|██████████████████████   | 59/67 [00:00<00:00, 171.67it/s, loss=0.00019, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 59:  90%|██████████████████████▍  | 60/67 [00:00<00:00, 170.50it/s, loss=0.00019, v_num=2]\u001b[A\n",
      "Epoch 59:  91%|██████████████████████▊  | 61/67 [00:00<00:00, 171.34it/s, loss=0.00019, v_num=2]\u001b[A\n",
      "Epoch 59:  93%|███████████████████████▏ | 62/67 [00:00<00:00, 172.20it/s, loss=0.00019, v_num=2]\u001b[A\n",
      "Epoch 59:  94%|███████████████████████▌ | 63/67 [00:00<00:00, 173.27it/s, loss=0.00019, v_num=2]\u001b[A\n",
      "Epoch 59:  96%|███████████████████████▉ | 64/67 [00:00<00:00, 174.28it/s, loss=0.00019, v_num=2]\u001b[A\n",
      "Epoch 59:  97%|████████████████████████▎| 65/67 [00:00<00:00, 175.32it/s, loss=0.00019, v_num=2]\u001b[A\n",
      "Epoch 59:  99%|████████████████████████▋| 66/67 [00:00<00:00, 176.30it/s, loss=0.00019, v_num=2]\u001b[A\n",
      "Epoch 59: 100%|█████████████████████████| 67/67 [00:00<00:00, 176.72it/s, loss=0.00019, v_num=2]\u001b[A\n",
      "Epoch 60:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 173.90it/s, loss=0.000307, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 60:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 172.74it/s, loss=0.000307, v_num=2]\u001b[A\n",
      "Epoch 60:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 173.64it/s, loss=0.000307, v_num=2]\u001b[A\n",
      "Epoch 60:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 174.55it/s, loss=0.000307, v_num=2]\u001b[A\n",
      "Epoch 60:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 175.44it/s, loss=0.000307, v_num=2]\u001b[A\n",
      "Epoch 60:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 176.34it/s, loss=0.000307, v_num=2]\u001b[A\n",
      "Epoch 60:  97%|███████████████████████▎| 65/67 [00:00<00:00, 177.19it/s, loss=0.000307, v_num=2]\u001b[A\n",
      "Epoch 60:  99%|███████████████████████▋| 66/67 [00:00<00:00, 178.07it/s, loss=0.000307, v_num=2]\u001b[A\n",
      "Epoch 60: 100%|████████████████████████| 67/67 [00:00<00:00, 178.28it/s, loss=0.000307, v_num=2]\u001b[A\n",
      "Epoch 61:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 161.32it/s, loss=0.000178, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 61:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 159.62it/s, loss=0.000178, v_num=2]\u001b[A\n",
      "Epoch 61:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 160.31it/s, loss=0.000178, v_num=2]\u001b[A\n",
      "Epoch 61:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 161.28it/s, loss=0.000178, v_num=2]\u001b[A\n",
      "Epoch 61:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 162.19it/s, loss=0.000178, v_num=2]\u001b[A\n",
      "Epoch 61:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 163.06it/s, loss=0.000178, v_num=2]\u001b[A\n",
      "Epoch 61:  97%|███████████████████████▎| 65/67 [00:00<00:00, 163.95it/s, loss=0.000178, v_num=2]\u001b[A\n",
      "Epoch 61:  99%|███████████████████████▋| 66/67 [00:00<00:00, 164.82it/s, loss=0.000178, v_num=2]\u001b[A\n",
      "Epoch 61: 100%|████████████████████████| 67/67 [00:00<00:00, 165.10it/s, loss=0.000178, v_num=2]\u001b[A\n",
      "Epoch 62:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 164.37it/s, loss=0.000292, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 62:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 162.91it/s, loss=0.000292, v_num=2]\u001b[A\n",
      "Epoch 62:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 163.66it/s, loss=0.000292, v_num=2]\u001b[A\n",
      "Epoch 62:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 164.43it/s, loss=0.000292, v_num=2]\u001b[A\n",
      "Epoch 62:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 165.17it/s, loss=0.000292, v_num=2]\u001b[A\n",
      "Epoch 62:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 165.91it/s, loss=0.000292, v_num=2]\u001b[A\n",
      "Epoch 62:  97%|███████████████████████▎| 65/67 [00:00<00:00, 166.61it/s, loss=0.000292, v_num=2]\u001b[A\n",
      "Epoch 62:  99%|███████████████████████▋| 66/67 [00:00<00:00, 167.26it/s, loss=0.000292, v_num=2]\u001b[A\n",
      "Epoch 62: 100%|████████████████████████| 67/67 [00:00<00:00, 167.33it/s, loss=0.000292, v_num=2]\u001b[A\n",
      "Epoch 63:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 166.20it/s, loss=0.000167, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 63:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 164.80it/s, loss=0.000167, v_num=2]\u001b[A\n",
      "Epoch 63:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 165.62it/s, loss=0.000167, v_num=2]\u001b[A\n",
      "Epoch 63:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 166.35it/s, loss=0.000167, v_num=2]\u001b[A\n",
      "Epoch 63:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 167.08it/s, loss=0.000167, v_num=2]\u001b[A\n",
      "Epoch 63:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 167.83it/s, loss=0.000167, v_num=2]\u001b[A\n",
      "Epoch 63:  97%|███████████████████████▎| 65/67 [00:00<00:00, 168.58it/s, loss=0.000167, v_num=2]\u001b[A\n",
      "Epoch 63:  99%|███████████████████████▋| 66/67 [00:00<00:00, 169.28it/s, loss=0.000167, v_num=2]\u001b[A\n",
      "Epoch 63: 100%|████████████████████████| 67/67 [00:00<00:00, 169.38it/s, loss=0.000167, v_num=2]\u001b[A\n",
      "Epoch 64:  88%|██████████████████████   | 59/67 [00:00<00:00, 167.66it/s, loss=0.00028, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 64:  90%|██████████████████████▍  | 60/67 [00:00<00:00, 166.66it/s, loss=0.00028, v_num=2]\u001b[A\n",
      "Epoch 64:  91%|██████████████████████▊  | 61/67 [00:00<00:00, 167.58it/s, loss=0.00028, v_num=2]\u001b[A\n",
      "Epoch 64:  93%|███████████████████████▏ | 62/67 [00:00<00:00, 168.44it/s, loss=0.00028, v_num=2]\u001b[A\n",
      "Epoch 64:  94%|███████████████████████▌ | 63/67 [00:00<00:00, 169.31it/s, loss=0.00028, v_num=2]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64:  96%|███████████████████████▉ | 64/67 [00:00<00:00, 170.15it/s, loss=0.00028, v_num=2]\u001b[A\n",
      "Epoch 64:  97%|████████████████████████▎| 65/67 [00:00<00:00, 171.07it/s, loss=0.00028, v_num=2]\u001b[A\n",
      "Epoch 64:  99%|████████████████████████▋| 66/67 [00:00<00:00, 172.14it/s, loss=0.00028, v_num=2]\u001b[A\n",
      "Epoch 64: 100%|█████████████████████████| 67/67 [00:00<00:00, 172.66it/s, loss=0.00028, v_num=2]\u001b[A\n",
      "Epoch 65:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 171.86it/s, loss=0.000159, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 65:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 170.78it/s, loss=0.000159, v_num=2]\u001b[A\n",
      "Epoch 65:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 171.89it/s, loss=0.000159, v_num=2]\u001b[A\n",
      "Epoch 65:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 172.99it/s, loss=0.000159, v_num=2]\u001b[A\n",
      "Epoch 65:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 174.06it/s, loss=0.000159, v_num=2]\u001b[A\n",
      "Epoch 65:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 175.11it/s, loss=0.000159, v_num=2]\u001b[A\n",
      "Epoch 65:  97%|███████████████████████▎| 65/67 [00:00<00:00, 176.13it/s, loss=0.000159, v_num=2]\u001b[A\n",
      "Epoch 65:  99%|███████████████████████▋| 66/67 [00:00<00:00, 177.13it/s, loss=0.000159, v_num=2]\u001b[A\n",
      "Epoch 65: 100%|████████████████████████| 67/67 [00:00<00:00, 177.55it/s, loss=0.000159, v_num=2]\u001b[A\n",
      "Epoch 66:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 171.33it/s, loss=0.000275, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 66:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 170.19it/s, loss=0.000275, v_num=2]\u001b[A\n",
      "Epoch 66:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 171.03it/s, loss=0.000275, v_num=2]\u001b[A\n",
      "Epoch 66:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 171.91it/s, loss=0.000275, v_num=2]\u001b[A\n",
      "Epoch 66:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 172.77it/s, loss=0.000275, v_num=2]\u001b[A\n",
      "Epoch 66:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 173.58it/s, loss=0.000275, v_num=2]\u001b[A\n",
      "Epoch 66:  97%|███████████████████████▎| 65/67 [00:00<00:00, 174.38it/s, loss=0.000275, v_num=2]\u001b[A\n",
      "Epoch 66:  99%|███████████████████████▋| 66/67 [00:00<00:00, 175.17it/s, loss=0.000275, v_num=2]\u001b[A\n",
      "Epoch 66: 100%|████████████████████████| 67/67 [00:00<00:00, 175.29it/s, loss=0.000275, v_num=2]\u001b[A\n",
      "Epoch 67:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 171.13it/s, loss=0.000153, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 67:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 170.08it/s, loss=0.000153, v_num=2]\u001b[A\n",
      "Epoch 67:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 171.01it/s, loss=0.000153, v_num=2]\u001b[A\n",
      "Epoch 67:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 171.91it/s, loss=0.000153, v_num=2]\u001b[A\n",
      "Epoch 67:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 172.81it/s, loss=0.000153, v_num=2]\u001b[A\n",
      "Epoch 67:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 173.71it/s, loss=0.000153, v_num=2]\u001b[A\n",
      "Epoch 67:  97%|███████████████████████▎| 65/67 [00:00<00:00, 174.57it/s, loss=0.000153, v_num=2]\u001b[A\n",
      "Epoch 67:  99%|███████████████████████▋| 66/67 [00:00<00:00, 175.43it/s, loss=0.000153, v_num=2]\u001b[A\n",
      "Epoch 67: 100%|████████████████████████| 67/67 [00:00<00:00, 175.68it/s, loss=0.000153, v_num=2]\u001b[A\n",
      "Epoch 68:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 171.56it/s, loss=0.000265, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 68:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 170.44it/s, loss=0.000265, v_num=2]\u001b[A\n",
      "Epoch 68:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 171.26it/s, loss=0.000265, v_num=2]\u001b[A\n",
      "Epoch 68:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 172.14it/s, loss=0.000265, v_num=2]\u001b[A\n",
      "Epoch 68:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 172.97it/s, loss=0.000265, v_num=2]\u001b[A\n",
      "Epoch 68:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 173.77it/s, loss=0.000265, v_num=2]\u001b[A\n",
      "Epoch 68:  97%|███████████████████████▎| 65/67 [00:00<00:00, 174.60it/s, loss=0.000265, v_num=2]\u001b[A\n",
      "Epoch 68:  99%|███████████████████████▋| 66/67 [00:00<00:00, 175.37it/s, loss=0.000265, v_num=2]\u001b[A\n",
      "Epoch 68: 100%|████████████████████████| 67/67 [00:00<00:00, 175.51it/s, loss=0.000265, v_num=2]\u001b[A\n",
      "Epoch 69:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 169.36it/s, loss=0.000144, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 69:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 168.22it/s, loss=0.000144, v_num=2]\u001b[A\n",
      "Epoch 69:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 169.06it/s, loss=0.000144, v_num=2]\u001b[A\n",
      "Epoch 69:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 169.91it/s, loss=0.000144, v_num=2]\u001b[A\n",
      "Epoch 69:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 170.80it/s, loss=0.000144, v_num=2]\u001b[A\n",
      "Epoch 69:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 171.62it/s, loss=0.000144, v_num=2]\u001b[A\n",
      "Epoch 69:  97%|███████████████████████▎| 65/67 [00:00<00:00, 172.42it/s, loss=0.000144, v_num=2]\u001b[A\n",
      "Epoch 69:  99%|███████████████████████▋| 66/67 [00:00<00:00, 173.23it/s, loss=0.000144, v_num=2]\u001b[A\n",
      "Epoch 69: 100%|████████████████████████| 67/67 [00:00<00:00, 173.40it/s, loss=0.000144, v_num=2]\u001b[A\n",
      "Epoch 70:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 168.53it/s, loss=0.000255, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 70:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 167.28it/s, loss=0.000255, v_num=2]\u001b[A\n",
      "Epoch 70:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 168.09it/s, loss=0.000255, v_num=2]\u001b[A\n",
      "Epoch 70:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 168.83it/s, loss=0.000255, v_num=2]\u001b[A\n",
      "Epoch 70:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 169.62it/s, loss=0.000255, v_num=2]\u001b[A\n",
      "Epoch 70:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 170.33it/s, loss=0.000255, v_num=2]\u001b[A\n",
      "Epoch 70:  97%|███████████████████████▎| 65/67 [00:00<00:00, 171.04it/s, loss=0.000255, v_num=2]\u001b[A\n",
      "Epoch 70:  99%|███████████████████████▋| 66/67 [00:00<00:00, 171.79it/s, loss=0.000255, v_num=2]\u001b[A\n",
      "Epoch 70: 100%|████████████████████████| 67/67 [00:00<00:00, 171.80it/s, loss=0.000255, v_num=2]\u001b[A\n",
      "Epoch 71:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 170.65it/s, loss=0.000135, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 71:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 169.45it/s, loss=0.000135, v_num=2]\u001b[A\n",
      "Epoch 71:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 170.23it/s, loss=0.000135, v_num=2]\u001b[A\n",
      "Epoch 71:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 170.90it/s, loss=0.000135, v_num=2]\u001b[A\n",
      "Epoch 71:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 171.74it/s, loss=0.000135, v_num=2]\u001b[A\n",
      "Epoch 71:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 172.57it/s, loss=0.000135, v_num=2]\u001b[A\n",
      "Epoch 71:  97%|███████████████████████▎| 65/67 [00:00<00:00, 173.32it/s, loss=0.000135, v_num=2]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71:  99%|███████████████████████▋| 66/67 [00:00<00:00, 174.11it/s, loss=0.000135, v_num=2]\u001b[A\n",
      "Epoch 71: 100%|████████████████████████| 67/67 [00:00<00:00, 174.27it/s, loss=0.000135, v_num=2]\u001b[A\n",
      "Epoch 72:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 172.38it/s, loss=0.000247, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 72:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 171.09it/s, loss=0.000247, v_num=2]\u001b[A\n",
      "Epoch 72:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 171.96it/s, loss=0.000247, v_num=2]\u001b[A\n",
      "Epoch 72:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 172.79it/s, loss=0.000247, v_num=2]\u001b[A\n",
      "Epoch 72:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 173.62it/s, loss=0.000247, v_num=2]\u001b[A\n",
      "Epoch 72:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 174.44it/s, loss=0.000247, v_num=2]\u001b[A\n",
      "Epoch 72:  97%|███████████████████████▎| 65/67 [00:00<00:00, 175.28it/s, loss=0.000247, v_num=2]\u001b[A\n",
      "Epoch 72:  99%|███████████████████████▋| 66/67 [00:00<00:00, 176.05it/s, loss=0.000247, v_num=2]\u001b[A\n",
      "Epoch 72: 100%|████████████████████████| 67/67 [00:00<00:00, 176.23it/s, loss=0.000247, v_num=2]\u001b[A\n",
      "Epoch 73:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 170.68it/s, loss=0.000128, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 73:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 169.46it/s, loss=0.000128, v_num=2]\u001b[A\n",
      "Epoch 73:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 170.25it/s, loss=0.000128, v_num=2]\u001b[A\n",
      "Epoch 73:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 171.12it/s, loss=0.000128, v_num=2]\u001b[A\n",
      "Epoch 73:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 172.11it/s, loss=0.000128, v_num=2]\u001b[A\n",
      "Epoch 73:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 173.12it/s, loss=0.000128, v_num=2]\u001b[A\n",
      "Epoch 73:  97%|███████████████████████▎| 65/67 [00:00<00:00, 174.10it/s, loss=0.000128, v_num=2]\u001b[A\n",
      "Epoch 73:  99%|███████████████████████▋| 66/67 [00:00<00:00, 175.05it/s, loss=0.000128, v_num=2]\u001b[A\n",
      "Epoch 73: 100%|████████████████████████| 67/67 [00:00<00:00, 175.37it/s, loss=0.000128, v_num=2]\u001b[A\n",
      "Epoch 74:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 170.22it/s, loss=0.000238, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 74:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 169.11it/s, loss=0.000238, v_num=2]\u001b[A\n",
      "Epoch 74:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 170.19it/s, loss=0.000238, v_num=2]\u001b[A\n",
      "Epoch 74:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 171.26it/s, loss=0.000238, v_num=2]\u001b[A\n",
      "Epoch 74:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 172.31it/s, loss=0.000238, v_num=2]\u001b[A\n",
      "Epoch 74:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 173.29it/s, loss=0.000238, v_num=2]\u001b[A\n",
      "Epoch 74:  97%|███████████████████████▎| 65/67 [00:00<00:00, 174.25it/s, loss=0.000238, v_num=2]\u001b[A\n",
      "Epoch 74:  99%|███████████████████████▋| 66/67 [00:00<00:00, 175.22it/s, loss=0.000238, v_num=2]\u001b[A\n",
      "Epoch 74: 100%|████████████████████████| 67/67 [00:00<00:00, 175.62it/s, loss=0.000238, v_num=2]\u001b[A\n",
      "Epoch 75:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 171.59it/s, loss=0.000122, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 75:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 170.41it/s, loss=0.000122, v_num=2]\u001b[A\n",
      "Epoch 75:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 171.50it/s, loss=0.000122, v_num=2]\u001b[A\n",
      "Epoch 75:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 172.49it/s, loss=0.000122, v_num=2]\u001b[A\n",
      "Epoch 75:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 173.28it/s, loss=0.000122, v_num=2]\u001b[A\n",
      "Epoch 75:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 174.07it/s, loss=0.000122, v_num=2]\u001b[A\n",
      "Epoch 75:  97%|███████████████████████▎| 65/67 [00:00<00:00, 174.85it/s, loss=0.000122, v_num=2]\u001b[A\n",
      "Epoch 75:  99%|███████████████████████▋| 66/67 [00:00<00:00, 175.59it/s, loss=0.000122, v_num=2]\u001b[A\n",
      "Epoch 75: 100%|████████████████████████| 67/67 [00:00<00:00, 175.73it/s, loss=0.000122, v_num=2]\u001b[A\n",
      "Epoch 76:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 168.68it/s, loss=0.000232, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 76:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 167.54it/s, loss=0.000232, v_num=2]\u001b[A\n",
      "Epoch 76:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 168.59it/s, loss=0.000232, v_num=2]\u001b[A\n",
      "Epoch 76:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 169.65it/s, loss=0.000232, v_num=2]\u001b[A\n",
      "Epoch 76:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 170.69it/s, loss=0.000232, v_num=2]\u001b[A\n",
      "Epoch 76:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 171.69it/s, loss=0.000232, v_num=2]\u001b[A\n",
      "Epoch 76:  97%|███████████████████████▎| 65/67 [00:00<00:00, 172.70it/s, loss=0.000232, v_num=2]\u001b[A\n",
      "Epoch 76:  99%|███████████████████████▋| 66/67 [00:00<00:00, 173.69it/s, loss=0.000232, v_num=2]\u001b[A\n",
      "Epoch 76: 100%|████████████████████████| 67/67 [00:00<00:00, 174.06it/s, loss=0.000232, v_num=2]\u001b[A\n",
      "Epoch 77:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 170.54it/s, loss=0.000117, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 77:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 169.36it/s, loss=0.000117, v_num=2]\u001b[A\n",
      "Epoch 77:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 170.17it/s, loss=0.000117, v_num=2]\u001b[A\n",
      "Epoch 77:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 171.11it/s, loss=0.000117, v_num=2]\u001b[A\n",
      "Epoch 77:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 172.00it/s, loss=0.000117, v_num=2]\u001b[A\n",
      "Epoch 77:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 172.86it/s, loss=0.000117, v_num=2]\u001b[A\n",
      "Epoch 77:  97%|███████████████████████▎| 65/67 [00:00<00:00, 173.73it/s, loss=0.000117, v_num=2]\u001b[A\n",
      "Epoch 77:  99%|███████████████████████▋| 66/67 [00:00<00:00, 174.59it/s, loss=0.000117, v_num=2]\u001b[A\n",
      "Epoch 77: 100%|████████████████████████| 67/67 [00:00<00:00, 174.86it/s, loss=0.000117, v_num=2]\u001b[A\n",
      "Epoch 78:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 171.14it/s, loss=0.000222, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 78:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 169.90it/s, loss=0.000222, v_num=2]\u001b[A\n",
      "Epoch 78:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 170.76it/s, loss=0.000222, v_num=2]\u001b[A\n",
      "Epoch 78:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 171.61it/s, loss=0.000222, v_num=2]\u001b[A\n",
      "Epoch 78:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 172.44it/s, loss=0.000222, v_num=2]\u001b[A\n",
      "Epoch 78:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 173.33it/s, loss=0.000222, v_num=2]\u001b[A\n",
      "Epoch 78:  97%|███████████████████████▎| 65/67 [00:00<00:00, 174.09it/s, loss=0.000222, v_num=2]\u001b[A\n",
      "Epoch 78:  99%|███████████████████████▋| 66/67 [00:00<00:00, 174.86it/s, loss=0.000222, v_num=2]\u001b[A\n",
      "Epoch 78: 100%|████████████████████████| 67/67 [00:00<00:00, 174.98it/s, loss=0.000222, v_num=2]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 170.47it/s, loss=0.000112, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 79:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 169.44it/s, loss=0.000112, v_num=2]\u001b[A\n",
      "Epoch 79:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 170.38it/s, loss=0.000112, v_num=2]\u001b[A\n",
      "Epoch 79:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 171.31it/s, loss=0.000112, v_num=2]\u001b[A\n",
      "Epoch 79:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 172.23it/s, loss=0.000112, v_num=2]\u001b[A\n",
      "Epoch 79:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 173.12it/s, loss=0.000112, v_num=2]\u001b[A\n",
      "Epoch 79:  97%|███████████████████████▎| 65/67 [00:00<00:00, 173.99it/s, loss=0.000112, v_num=2]\u001b[A\n",
      "Epoch 79:  99%|███████████████████████▋| 66/67 [00:00<00:00, 174.86it/s, loss=0.000112, v_num=2]\u001b[A\n",
      "Epoch 79: 100%|████████████████████████| 67/67 [00:00<00:00, 175.10it/s, loss=0.000112, v_num=2]\u001b[A\n",
      "Epoch 80:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 173.94it/s, loss=0.000217, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 80:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 172.70it/s, loss=0.000217, v_num=2]\u001b[A\n",
      "Epoch 80:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 173.53it/s, loss=0.000217, v_num=2]\u001b[A\n",
      "Epoch 80:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 174.58it/s, loss=0.000217, v_num=2]\u001b[A\n",
      "Epoch 80:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 175.60it/s, loss=0.000217, v_num=2]\u001b[A\n",
      "Epoch 80:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 176.64it/s, loss=0.000217, v_num=2]\u001b[A\n",
      "Epoch 80:  97%|███████████████████████▎| 65/67 [00:00<00:00, 177.64it/s, loss=0.000217, v_num=2]\u001b[A\n",
      "Epoch 80:  99%|███████████████████████▋| 66/67 [00:00<00:00, 178.60it/s, loss=0.000217, v_num=2]\u001b[A\n",
      "Epoch 80: 100%|████████████████████████| 67/67 [00:00<00:00, 178.96it/s, loss=0.000217, v_num=2]\u001b[A\n",
      "Epoch 81:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 172.02it/s, loss=0.000108, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 81:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 170.88it/s, loss=0.000108, v_num=2]\u001b[A\n",
      "Epoch 81:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 171.82it/s, loss=0.000108, v_num=2]\u001b[A\n",
      "Epoch 81:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 172.63it/s, loss=0.000108, v_num=2]\u001b[A\n",
      "Epoch 81:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 173.58it/s, loss=0.000108, v_num=2]\u001b[A\n",
      "Epoch 81:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 174.43it/s, loss=0.000108, v_num=2]\u001b[A\n",
      "Epoch 81:  97%|███████████████████████▎| 65/67 [00:00<00:00, 175.30it/s, loss=0.000108, v_num=2]\u001b[A\n",
      "Epoch 81:  99%|███████████████████████▋| 66/67 [00:00<00:00, 176.11it/s, loss=0.000108, v_num=2]\u001b[A\n",
      "Epoch 81: 100%|████████████████████████| 67/67 [00:00<00:00, 176.30it/s, loss=0.000108, v_num=2]\u001b[A\n",
      "Epoch 82:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 172.02it/s, loss=0.000211, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 82:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 170.98it/s, loss=0.000211, v_num=2]\u001b[A\n",
      "Epoch 82:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 171.91it/s, loss=0.000211, v_num=2]\u001b[A\n",
      "Epoch 82:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 172.86it/s, loss=0.000211, v_num=2]\u001b[A\n",
      "Epoch 82:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 173.76it/s, loss=0.000211, v_num=2]\u001b[A\n",
      "Epoch 82:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 174.55it/s, loss=0.000211, v_num=2]\u001b[A\n",
      "Epoch 82:  97%|███████████████████████▎| 65/67 [00:00<00:00, 175.40it/s, loss=0.000211, v_num=2]\u001b[A\n",
      "Epoch 82:  99%|███████████████████████▋| 66/67 [00:00<00:00, 176.13it/s, loss=0.000211, v_num=2]\u001b[A\n",
      "Epoch 82: 100%|████████████████████████| 67/67 [00:00<00:00, 176.31it/s, loss=0.000211, v_num=2]\u001b[A\n",
      "Epoch 83:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 171.21it/s, loss=0.000105, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 83:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 169.99it/s, loss=0.000105, v_num=2]\u001b[A\n",
      "Epoch 83:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 170.86it/s, loss=0.000105, v_num=2]\u001b[A\n",
      "Epoch 83:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 171.71it/s, loss=0.000105, v_num=2]\u001b[A\n",
      "Epoch 83:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 172.54it/s, loss=0.000105, v_num=2]\u001b[A\n",
      "Epoch 83:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 173.35it/s, loss=0.000105, v_num=2]\u001b[A\n",
      "Epoch 83:  97%|███████████████████████▎| 65/67 [00:00<00:00, 174.16it/s, loss=0.000105, v_num=2]\u001b[A\n",
      "Epoch 83:  99%|███████████████████████▋| 66/67 [00:00<00:00, 174.89it/s, loss=0.000105, v_num=2]\u001b[A\n",
      "Epoch 83: 100%|████████████████████████| 67/67 [00:00<00:00, 175.01it/s, loss=0.000105, v_num=2]\u001b[A\n",
      "Epoch 84:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 171.28it/s, loss=0.000206, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 84:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 170.11it/s, loss=0.000206, v_num=2]\u001b[A\n",
      "Epoch 84:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 170.96it/s, loss=0.000206, v_num=2]\u001b[A\n",
      "Epoch 84:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 171.81it/s, loss=0.000206, v_num=2]\u001b[A\n",
      "Epoch 84:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 172.61it/s, loss=0.000206, v_num=2]\u001b[A\n",
      "Epoch 84:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 173.47it/s, loss=0.000206, v_num=2]\u001b[A\n",
      "Epoch 84:  97%|███████████████████████▎| 65/67 [00:00<00:00, 174.25it/s, loss=0.000206, v_num=2]\u001b[A\n",
      "Epoch 84:  99%|███████████████████████▋| 66/67 [00:00<00:00, 175.06it/s, loss=0.000206, v_num=2]\u001b[A\n",
      "Epoch 84: 100%|████████████████████████| 67/67 [00:00<00:00, 175.23it/s, loss=0.000206, v_num=2]\u001b[A\n",
      "Epoch 85:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 169.53it/s, loss=9.91e-05, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 85:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 168.37it/s, loss=9.91e-05, v_num=2]\u001b[A\n",
      "Epoch 85:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 169.25it/s, loss=9.91e-05, v_num=2]\u001b[A\n",
      "Epoch 85:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 170.11it/s, loss=9.91e-05, v_num=2]\u001b[A\n",
      "Epoch 85:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 170.95it/s, loss=9.91e-05, v_num=2]\u001b[A\n",
      "Epoch 85:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 171.84it/s, loss=9.91e-05, v_num=2]\u001b[A\n",
      "Epoch 85:  97%|███████████████████████▎| 65/67 [00:00<00:00, 172.85it/s, loss=9.91e-05, v_num=2]\u001b[A\n",
      "Epoch 85:  99%|███████████████████████▋| 66/67 [00:00<00:00, 173.86it/s, loss=9.91e-05, v_num=2]\u001b[A\n",
      "Epoch 85: 100%|████████████████████████| 67/67 [00:00<00:00, 174.28it/s, loss=9.91e-05, v_num=2]\u001b[A\n",
      "Epoch 86:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 170.22it/s, loss=0.000194, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 86:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 169.07it/s, loss=0.000194, v_num=2]\u001b[A\n",
      "Epoch 86:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 169.95it/s, loss=0.000194, v_num=2]\u001b[A\n",
      "Epoch 86:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 170.81it/s, loss=0.000194, v_num=2]\u001b[A\n",
      "Epoch 86:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 171.66it/s, loss=0.000194, v_num=2]\u001b[A\n",
      "Epoch 86:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 172.49it/s, loss=0.000194, v_num=2]\u001b[A\n",
      "Epoch 86:  97%|███████████████████████▎| 65/67 [00:00<00:00, 173.25it/s, loss=0.000194, v_num=2]\u001b[A\n",
      "Epoch 86:  99%|███████████████████████▋| 66/67 [00:00<00:00, 174.06it/s, loss=0.000194, v_num=2]\u001b[A\n",
      "Epoch 86: 100%|████████████████████████| 67/67 [00:00<00:00, 174.20it/s, loss=0.000194, v_num=2]\u001b[A\n",
      "Epoch 87:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 168.57it/s, loss=9.46e-05, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 87:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 167.57it/s, loss=9.46e-05, v_num=2]\u001b[A\n",
      "Epoch 87:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 168.70it/s, loss=9.46e-05, v_num=2]\u001b[A\n",
      "Epoch 87:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 169.77it/s, loss=9.46e-05, v_num=2]\u001b[A\n",
      "Epoch 87:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 170.80it/s, loss=9.46e-05, v_num=2]\u001b[A\n",
      "Epoch 87:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 171.84it/s, loss=9.46e-05, v_num=2]\u001b[A\n",
      "Epoch 87:  97%|███████████████████████▎| 65/67 [00:00<00:00, 172.87it/s, loss=9.46e-05, v_num=2]\u001b[A\n",
      "Epoch 87:  99%|███████████████████████▋| 66/67 [00:00<00:00, 173.87it/s, loss=9.46e-05, v_num=2]\u001b[A\n",
      "Epoch 87: 100%|████████████████████████| 67/67 [00:00<00:00, 174.28it/s, loss=9.46e-05, v_num=2]\u001b[A\n",
      "Epoch 88:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 171.48it/s, loss=0.000187, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 88:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 170.32it/s, loss=0.000187, v_num=2]\u001b[A\n",
      "Epoch 88:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 171.20it/s, loss=0.000187, v_num=2]\u001b[A\n",
      "Epoch 88:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 172.25it/s, loss=0.000187, v_num=2]\u001b[A\n",
      "Epoch 88:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 173.30it/s, loss=0.000187, v_num=2]\u001b[A\n",
      "Epoch 88:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 174.32it/s, loss=0.000187, v_num=2]\u001b[A\n",
      "Epoch 88:  97%|███████████████████████▎| 65/67 [00:00<00:00, 175.30it/s, loss=0.000187, v_num=2]\u001b[A\n",
      "Epoch 88:  99%|███████████████████████▋| 66/67 [00:00<00:00, 176.31it/s, loss=0.000187, v_num=2]\u001b[A\n",
      "Epoch 88: 100%|████████████████████████| 67/67 [00:00<00:00, 176.69it/s, loss=0.000187, v_num=2]\u001b[A\n",
      "Epoch 89:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 170.75it/s, loss=9.08e-05, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 89:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 169.56it/s, loss=9.08e-05, v_num=2]\u001b[A\n",
      "Epoch 89:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 170.41it/s, loss=9.08e-05, v_num=2]\u001b[A\n",
      "Epoch 89:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 171.26it/s, loss=9.08e-05, v_num=2]\u001b[A\n",
      "Epoch 89:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 172.05it/s, loss=9.08e-05, v_num=2]\u001b[A\n",
      "Epoch 89:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 172.84it/s, loss=9.08e-05, v_num=2]\u001b[A\n",
      "Epoch 89:  97%|███████████████████████▎| 65/67 [00:00<00:00, 173.64it/s, loss=9.08e-05, v_num=2]\u001b[A\n",
      "Epoch 89:  99%|███████████████████████▋| 66/67 [00:00<00:00, 174.43it/s, loss=9.08e-05, v_num=2]\u001b[A\n",
      "Epoch 89: 100%|████████████████████████| 67/67 [00:00<00:00, 174.56it/s, loss=9.08e-05, v_num=2]\u001b[A\n",
      "Epoch 90:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 169.57it/s, loss=0.000182, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 90:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 168.54it/s, loss=0.000182, v_num=2]\u001b[A\n",
      "Epoch 90:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 169.50it/s, loss=0.000182, v_num=2]\u001b[A\n",
      "Epoch 90:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 170.45it/s, loss=0.000182, v_num=2]\u001b[A\n",
      "Epoch 90:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 171.36it/s, loss=0.000182, v_num=2]\u001b[A\n",
      "Epoch 90:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 172.27it/s, loss=0.000182, v_num=2]\u001b[A\n",
      "Epoch 90:  97%|███████████████████████▎| 65/67 [00:00<00:00, 173.10it/s, loss=0.000182, v_num=2]\u001b[A\n",
      "Epoch 90:  99%|███████████████████████▋| 66/67 [00:00<00:00, 173.97it/s, loss=0.000182, v_num=2]\u001b[A\n",
      "Epoch 90: 100%|████████████████████████| 67/67 [00:00<00:00, 174.22it/s, loss=0.000182, v_num=2]\u001b[A\n",
      "Epoch 91:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 172.06it/s, loss=8.77e-05, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 91:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 170.78it/s, loss=8.77e-05, v_num=2]\u001b[A\n",
      "Epoch 91:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 171.61it/s, loss=8.77e-05, v_num=2]\u001b[A\n",
      "Epoch 91:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 172.48it/s, loss=8.77e-05, v_num=2]\u001b[A\n",
      "Epoch 91:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 173.24it/s, loss=8.77e-05, v_num=2]\u001b[A\n",
      "Epoch 91:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 174.03it/s, loss=8.77e-05, v_num=2]\u001b[A\n",
      "Epoch 91:  97%|███████████████████████▎| 65/67 [00:00<00:00, 174.84it/s, loss=8.77e-05, v_num=2]\u001b[A\n",
      "Epoch 91:  99%|███████████████████████▋| 66/67 [00:00<00:00, 175.59it/s, loss=8.77e-05, v_num=2]\u001b[A\n",
      "Epoch 91: 100%|████████████████████████| 67/67 [00:00<00:00, 175.71it/s, loss=8.77e-05, v_num=2]\u001b[A\n",
      "Epoch 92:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 170.20it/s, loss=0.000176, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 92:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 168.96it/s, loss=0.000176, v_num=2]\u001b[A\n",
      "Epoch 92:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 170.03it/s, loss=0.000176, v_num=2]\u001b[A\n",
      "Epoch 92:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 171.07it/s, loss=0.000176, v_num=2]\u001b[A\n",
      "Epoch 92:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 172.13it/s, loss=0.000176, v_num=2]\u001b[A\n",
      "Epoch 92:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 173.13it/s, loss=0.000176, v_num=2]\u001b[A\n",
      "Epoch 92:  97%|███████████████████████▎| 65/67 [00:00<00:00, 174.11it/s, loss=0.000176, v_num=2]\u001b[A\n",
      "Epoch 92:  99%|███████████████████████▋| 66/67 [00:00<00:00, 175.13it/s, loss=0.000176, v_num=2]\u001b[A\n",
      "Epoch 92: 100%|████████████████████████| 67/67 [00:00<00:00, 175.48it/s, loss=0.000176, v_num=2]\u001b[A\n",
      "Epoch 93:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 169.79it/s, loss=8.45e-05, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 93:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 168.68it/s, loss=8.45e-05, v_num=2]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 169.76it/s, loss=8.45e-05, v_num=2]\u001b[A\n",
      "Epoch 93:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 170.82it/s, loss=8.45e-05, v_num=2]\u001b[A\n",
      "Epoch 93:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 171.84it/s, loss=8.45e-05, v_num=2]\u001b[A\n",
      "Epoch 93:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 172.83it/s, loss=8.45e-05, v_num=2]\u001b[A\n",
      "Epoch 93:  97%|███████████████████████▎| 65/67 [00:00<00:00, 173.81it/s, loss=8.45e-05, v_num=2]\u001b[A\n",
      "Epoch 93:  99%|███████████████████████▋| 66/67 [00:00<00:00, 174.76it/s, loss=8.45e-05, v_num=2]\u001b[A\n",
      "Epoch 93: 100%|████████████████████████| 67/67 [00:00<00:00, 175.12it/s, loss=8.45e-05, v_num=2]\u001b[A\n",
      "Epoch 94:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 169.82it/s, loss=0.000172, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 94:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 168.65it/s, loss=0.000172, v_num=2]\u001b[A\n",
      "Epoch 94:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 169.69it/s, loss=0.000172, v_num=2]\u001b[A\n",
      "Epoch 94:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 170.73it/s, loss=0.000172, v_num=2]\u001b[A\n",
      "Epoch 94:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 171.79it/s, loss=0.000172, v_num=2]\u001b[A\n",
      "Epoch 94:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 172.83it/s, loss=0.000172, v_num=2]\u001b[A\n",
      "Epoch 94:  97%|███████████████████████▎| 65/67 [00:00<00:00, 173.83it/s, loss=0.000172, v_num=2]\u001b[A\n",
      "Epoch 94:  99%|███████████████████████▋| 66/67 [00:00<00:00, 174.83it/s, loss=0.000172, v_num=2]\u001b[A\n",
      "Epoch 94: 100%|████████████████████████| 67/67 [00:00<00:00, 175.20it/s, loss=0.000172, v_num=2]\u001b[A\n",
      "Epoch 95:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 168.56it/s, loss=8.21e-05, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 95:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 167.41it/s, loss=8.21e-05, v_num=2]\u001b[A\n",
      "Epoch 95:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 168.24it/s, loss=8.21e-05, v_num=2]\u001b[A\n",
      "Epoch 95:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 169.14it/s, loss=8.21e-05, v_num=2]\u001b[A\n",
      "Epoch 95:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 170.20it/s, loss=8.21e-05, v_num=2]\u001b[A\n",
      "Epoch 95:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 171.24it/s, loss=8.21e-05, v_num=2]\u001b[A\n",
      "Epoch 95:  97%|███████████████████████▎| 65/67 [00:00<00:00, 172.27it/s, loss=8.21e-05, v_num=2]\u001b[A\n",
      "Epoch 95:  99%|███████████████████████▋| 66/67 [00:00<00:00, 173.26it/s, loss=8.21e-05, v_num=2]\u001b[A\n",
      "Epoch 95: 100%|████████████████████████| 67/67 [00:00<00:00, 173.66it/s, loss=8.21e-05, v_num=2]\u001b[A\n",
      "Epoch 96:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 169.87it/s, loss=0.000167, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 96:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 168.68it/s, loss=0.000167, v_num=2]\u001b[A\n",
      "Epoch 96:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 169.54it/s, loss=0.000167, v_num=2]\u001b[A\n",
      "Epoch 96:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 170.40it/s, loss=0.000167, v_num=2]\u001b[A\n",
      "Epoch 96:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 171.20it/s, loss=0.000167, v_num=2]\u001b[A\n",
      "Epoch 96:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 172.01it/s, loss=0.000167, v_num=2]\u001b[A\n",
      "Epoch 96:  97%|███████████████████████▎| 65/67 [00:00<00:00, 172.88it/s, loss=0.000167, v_num=2]\u001b[A\n",
      "Epoch 96:  99%|███████████████████████▋| 66/67 [00:00<00:00, 173.89it/s, loss=0.000167, v_num=2]\u001b[A\n",
      "Epoch 96: 100%|████████████████████████| 67/67 [00:00<00:00, 174.26it/s, loss=0.000167, v_num=2]\u001b[A\n",
      "Epoch 97:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 172.16it/s, loss=7.99e-05, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 97:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 170.90it/s, loss=7.99e-05, v_num=2]\u001b[A\n",
      "Epoch 97:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 171.73it/s, loss=7.99e-05, v_num=2]\u001b[A\n",
      "Epoch 97:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 172.64it/s, loss=7.99e-05, v_num=2]\u001b[A\n",
      "Epoch 97:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 173.66it/s, loss=7.99e-05, v_num=2]\u001b[A\n",
      "Epoch 97:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 174.67it/s, loss=7.99e-05, v_num=2]\u001b[A\n",
      "Epoch 97:  97%|███████████████████████▎| 65/67 [00:00<00:00, 175.66it/s, loss=7.99e-05, v_num=2]\u001b[A\n",
      "Epoch 97:  99%|███████████████████████▋| 66/67 [00:00<00:00, 176.64it/s, loss=7.99e-05, v_num=2]\u001b[A\n",
      "Epoch 97: 100%|████████████████████████| 67/67 [00:00<00:00, 176.95it/s, loss=7.99e-05, v_num=2]\u001b[A\n",
      "Epoch 98:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 169.99it/s, loss=0.000162, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 98:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 168.79it/s, loss=0.000162, v_num=2]\u001b[A\n",
      "Epoch 98:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 169.64it/s, loss=0.000162, v_num=2]\u001b[A\n",
      "Epoch 98:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 170.50it/s, loss=0.000162, v_num=2]\u001b[A\n",
      "Epoch 98:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 171.33it/s, loss=0.000162, v_num=2]\u001b[A\n",
      "Epoch 98:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 172.13it/s, loss=0.000162, v_num=2]\u001b[A\n",
      "Epoch 98:  97%|███████████████████████▎| 65/67 [00:00<00:00, 172.87it/s, loss=0.000162, v_num=2]\u001b[A\n",
      "Epoch 98:  99%|███████████████████████▋| 66/67 [00:00<00:00, 173.59it/s, loss=0.000162, v_num=2]\u001b[A\n",
      "Epoch 98: 100%|████████████████████████| 67/67 [00:00<00:00, 173.70it/s, loss=0.000162, v_num=2]\u001b[A\n",
      "Epoch 99:  88%|█████████████████████▏  | 59/67 [00:00<00:00, 172.11it/s, loss=7.78e-05, v_num=2]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                         | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 99:  90%|█████████████████████▍  | 60/67 [00:00<00:00, 171.04it/s, loss=7.78e-05, v_num=2]\u001b[A\n",
      "Epoch 99:  91%|█████████████████████▊  | 61/67 [00:00<00:00, 171.96it/s, loss=7.78e-05, v_num=2]\u001b[A\n",
      "Epoch 99:  93%|██████████████████████▏ | 62/67 [00:00<00:00, 172.88it/s, loss=7.78e-05, v_num=2]\u001b[A\n",
      "Epoch 99:  94%|██████████████████████▌ | 63/67 [00:00<00:00, 173.82it/s, loss=7.78e-05, v_num=2]\u001b[A\n",
      "Epoch 99:  96%|██████████████████████▉ | 64/67 [00:00<00:00, 174.68it/s, loss=7.78e-05, v_num=2]\u001b[A\n",
      "Epoch 99:  97%|███████████████████████▎| 65/67 [00:00<00:00, 175.54it/s, loss=7.78e-05, v_num=2]\u001b[A\n",
      "Epoch 99:  99%|███████████████████████▋| 66/67 [00:00<00:00, 176.36it/s, loss=7.78e-05, v_num=2]\u001b[A\n",
      "Epoch 99: 100%|████████████████████████| 67/67 [00:00<00:00, 176.60it/s, loss=7.78e-05, v_num=2]\u001b[A\n",
      "Epoch 99: 100%|████████████████████████| 67/67 [00:00<00:00, 175.58it/s, loss=7.78e-05, v_num=2]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|████████████████████████| 67/67 [00:00<00:00, 174.19it/s, loss=7.78e-05, v_num=2]\n"
     ]
    }
   ],
   "source": [
    "model = Regression()\n",
    "trainer = Trainer(max_epochs = 100)  # Option to check if it's working at all: fast_dev_run=True \n",
    "                                    # Option to implement early stopping: early_stop_callback=True\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b886f9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/workspace/mlmfem/anaconda3/envs/ptl_env/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:134: UserWarning: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "  rank_zero_warn(\n",
      "Restoring states from the checkpoint path at /home/holec1/ML-student-projects/students/bogdaale/NN-examples/lightning_logs/version_2/checkpoints/epoch=99-step=5900.ckpt\n",
      "Loaded model weights from checkpoint at /home/holec1/ML-student-projects/students/bogdaale/NN-examples/lightning_logs/version_2/checkpoints/epoch=99-step=5900.ckpt\n",
      "/usr/workspace/mlmfem/anaconda3/envs/ptl_env/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████| 74/74 [00:00<00:00, 407.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[-1.0226],\n",
       "         [-1.0224],\n",
       "         [-1.0221],\n",
       "         [-1.0219],\n",
       "         [-1.0216],\n",
       "         [-1.0214],\n",
       "         [-1.0212],\n",
       "         [-1.0210],\n",
       "         [-1.0208],\n",
       "         [-1.0206],\n",
       "         [-1.0205],\n",
       "         [-1.0204],\n",
       "         [-1.0203],\n",
       "         [-1.0202],\n",
       "         [-1.0201],\n",
       "         [-1.0200],\n",
       "         [-1.0200],\n",
       "         [-1.0199],\n",
       "         [-1.0198],\n",
       "         [-1.0198],\n",
       "         [-1.0197],\n",
       "         [-1.0196],\n",
       "         [-1.0195],\n",
       "         [-1.0194],\n",
       "         [-1.0193],\n",
       "         [-1.0192],\n",
       "         [-1.0191],\n",
       "         [-1.0190],\n",
       "         [-1.0189],\n",
       "         [-1.0188],\n",
       "         [-1.0187],\n",
       "         [-1.0186],\n",
       "         [-1.0185],\n",
       "         [-1.0184],\n",
       "         [-1.0183],\n",
       "         [-1.0182],\n",
       "         [-1.0181],\n",
       "         [-1.0180],\n",
       "         [-1.0179],\n",
       "         [-1.0178],\n",
       "         [-1.0177],\n",
       "         [-1.0176],\n",
       "         [-1.0175],\n",
       "         [-1.0174],\n",
       "         [-1.0173],\n",
       "         [-1.0172],\n",
       "         [-1.0171],\n",
       "         [-1.0170],\n",
       "         [-1.0169],\n",
       "         [-1.0168],\n",
       "         [-1.0168],\n",
       "         [-1.0167],\n",
       "         [-1.0166],\n",
       "         [-1.0165],\n",
       "         [-1.0164],\n",
       "         [-1.0163],\n",
       "         [-1.0162],\n",
       "         [-1.0161],\n",
       "         [-1.0160],\n",
       "         [-1.0159],\n",
       "         [-1.0158],\n",
       "         [-1.0157],\n",
       "         [-1.0156],\n",
       "         [-1.0155],\n",
       "         [-1.0154],\n",
       "         [-1.0153],\n",
       "         [-1.0152],\n",
       "         [-1.0151],\n",
       "         [-1.0150],\n",
       "         [-1.0149],\n",
       "         [-1.0149],\n",
       "         [-1.0148],\n",
       "         [-1.0147],\n",
       "         [-1.0146],\n",
       "         [-1.0145],\n",
       "         [-1.0144],\n",
       "         [-1.0143],\n",
       "         [-1.0142],\n",
       "         [-1.0141],\n",
       "         [-1.0140],\n",
       "         [-1.0139],\n",
       "         [-1.0138],\n",
       "         [-1.0137],\n",
       "         [-1.0136],\n",
       "         [-1.0135],\n",
       "         [-1.0134],\n",
       "         [-1.0133],\n",
       "         [-1.0132],\n",
       "         [-1.0131],\n",
       "         [-1.0131],\n",
       "         [-1.0130],\n",
       "         [-1.0129],\n",
       "         [-1.0128],\n",
       "         [-1.0127],\n",
       "         [-1.0126],\n",
       "         [-1.0125],\n",
       "         [-1.0124],\n",
       "         [-1.0123],\n",
       "         [-1.0122],\n",
       "         [-1.0121],\n",
       "         [-1.0120],\n",
       "         [-1.0119],\n",
       "         [-1.0118],\n",
       "         [-1.0117],\n",
       "         [-1.0116],\n",
       "         [-1.0115],\n",
       "         [-1.0114],\n",
       "         [-1.0113],\n",
       "         [-1.0113],\n",
       "         [-1.0112],\n",
       "         [-1.0111],\n",
       "         [-1.0110],\n",
       "         [-1.0109],\n",
       "         [-1.0108],\n",
       "         [-1.0107],\n",
       "         [-1.0106],\n",
       "         [-1.0105],\n",
       "         [-1.0104],\n",
       "         [-1.0103],\n",
       "         [-1.0102],\n",
       "         [-1.0101],\n",
       "         [-1.0100],\n",
       "         [-1.0099],\n",
       "         [-1.0098],\n",
       "         [-1.0097],\n",
       "         [-1.0096],\n",
       "         [-1.0095],\n",
       "         [-1.0094]]),\n",
       " tensor([[-1.0094],\n",
       "         [-1.0093],\n",
       "         [-1.0092],\n",
       "         [-1.0091],\n",
       "         [-1.0090],\n",
       "         [-1.0089],\n",
       "         [-1.0088],\n",
       "         [-1.0087],\n",
       "         [-1.0086],\n",
       "         [-1.0085],\n",
       "         [-1.0084],\n",
       "         [-1.0083],\n",
       "         [-1.0082],\n",
       "         [-1.0081],\n",
       "         [-1.0080],\n",
       "         [-1.0079],\n",
       "         [-1.0078],\n",
       "         [-1.0077],\n",
       "         [-1.0076],\n",
       "         [-1.0075],\n",
       "         [-1.0074],\n",
       "         [-1.0073],\n",
       "         [-1.0072],\n",
       "         [-1.0071],\n",
       "         [-1.0071],\n",
       "         [-1.0070],\n",
       "         [-1.0069],\n",
       "         [-1.0068],\n",
       "         [-1.0067],\n",
       "         [-1.0066],\n",
       "         [-1.0065],\n",
       "         [-1.0064],\n",
       "         [-1.0063],\n",
       "         [-1.0062],\n",
       "         [-1.0061],\n",
       "         [-1.0060],\n",
       "         [-1.0059],\n",
       "         [-1.0058],\n",
       "         [-1.0057],\n",
       "         [-1.0056],\n",
       "         [-1.0055],\n",
       "         [-1.0054],\n",
       "         [-1.0053],\n",
       "         [-1.0052],\n",
       "         [-1.0051],\n",
       "         [-1.0050],\n",
       "         [-1.0049],\n",
       "         [-1.0048],\n",
       "         [-1.0047],\n",
       "         [-1.0046],\n",
       "         [-1.0045],\n",
       "         [-1.0044],\n",
       "         [-1.0043],\n",
       "         [-1.0042],\n",
       "         [-1.0041],\n",
       "         [-1.0040],\n",
       "         [-1.0039],\n",
       "         [-1.0038],\n",
       "         [-1.0037],\n",
       "         [-1.0036],\n",
       "         [-1.0035],\n",
       "         [-1.0034],\n",
       "         [-1.0033],\n",
       "         [-1.0032],\n",
       "         [-1.0031],\n",
       "         [-1.0030],\n",
       "         [-1.0029],\n",
       "         [-1.0028],\n",
       "         [-1.0027],\n",
       "         [-1.0026],\n",
       "         [-1.0025],\n",
       "         [-1.0024],\n",
       "         [-1.0023],\n",
       "         [-1.0022],\n",
       "         [-1.0021],\n",
       "         [-1.0020],\n",
       "         [-1.0019],\n",
       "         [-1.0018],\n",
       "         [-1.0017],\n",
       "         [-1.0016],\n",
       "         [-1.0015],\n",
       "         [-1.0014],\n",
       "         [-1.0013],\n",
       "         [-1.0012],\n",
       "         [-1.0011],\n",
       "         [-1.0010],\n",
       "         [-1.0009],\n",
       "         [-1.0008],\n",
       "         [-1.0007],\n",
       "         [-1.0006],\n",
       "         [-1.0005],\n",
       "         [-1.0004],\n",
       "         [-1.0003],\n",
       "         [-1.0002],\n",
       "         [-1.0001],\n",
       "         [-1.0000],\n",
       "         [-0.9999],\n",
       "         [-0.9998],\n",
       "         [-0.9997],\n",
       "         [-0.9996],\n",
       "         [-0.9995],\n",
       "         [-0.9994],\n",
       "         [-0.9993],\n",
       "         [-0.9992],\n",
       "         [-0.9991],\n",
       "         [-0.9990],\n",
       "         [-0.9989],\n",
       "         [-0.9988],\n",
       "         [-0.9986],\n",
       "         [-0.9985],\n",
       "         [-0.9984],\n",
       "         [-0.9983],\n",
       "         [-0.9982],\n",
       "         [-0.9981],\n",
       "         [-0.9980],\n",
       "         [-0.9979],\n",
       "         [-0.9978],\n",
       "         [-0.9977],\n",
       "         [-0.9976],\n",
       "         [-0.9975],\n",
       "         [-0.9974],\n",
       "         [-0.9973],\n",
       "         [-0.9972],\n",
       "         [-0.9971],\n",
       "         [-0.9970],\n",
       "         [-0.9968],\n",
       "         [-0.9967],\n",
       "         [-0.9966]]),\n",
       " tensor([[-0.9965],\n",
       "         [-0.9964],\n",
       "         [-0.9963],\n",
       "         [-0.9962],\n",
       "         [-0.9961],\n",
       "         [-0.9960],\n",
       "         [-0.9959],\n",
       "         [-0.9958],\n",
       "         [-0.9957],\n",
       "         [-0.9955],\n",
       "         [-0.9954],\n",
       "         [-0.9953],\n",
       "         [-0.9952],\n",
       "         [-0.9951],\n",
       "         [-0.9950],\n",
       "         [-0.9949],\n",
       "         [-0.9948],\n",
       "         [-0.9947],\n",
       "         [-0.9945],\n",
       "         [-0.9944],\n",
       "         [-0.9943],\n",
       "         [-0.9942],\n",
       "         [-0.9941],\n",
       "         [-0.9940],\n",
       "         [-0.9939],\n",
       "         [-0.9938],\n",
       "         [-0.9937],\n",
       "         [-0.9935],\n",
       "         [-0.9934],\n",
       "         [-0.9933],\n",
       "         [-0.9932],\n",
       "         [-0.9931],\n",
       "         [-0.9930],\n",
       "         [-0.9929],\n",
       "         [-0.9928],\n",
       "         [-0.9926],\n",
       "         [-0.9925],\n",
       "         [-0.9924],\n",
       "         [-0.9923],\n",
       "         [-0.9922],\n",
       "         [-0.9921],\n",
       "         [-0.9919],\n",
       "         [-0.9918],\n",
       "         [-0.9917],\n",
       "         [-0.9916],\n",
       "         [-0.9915],\n",
       "         [-0.9914],\n",
       "         [-0.9913],\n",
       "         [-0.9911],\n",
       "         [-0.9910],\n",
       "         [-0.9909],\n",
       "         [-0.9908],\n",
       "         [-0.9907],\n",
       "         [-0.9906],\n",
       "         [-0.9904],\n",
       "         [-0.9903],\n",
       "         [-0.9902],\n",
       "         [-0.9901],\n",
       "         [-0.9900],\n",
       "         [-0.9898],\n",
       "         [-0.9897],\n",
       "         [-0.9896],\n",
       "         [-0.9895],\n",
       "         [-0.9894],\n",
       "         [-0.9892],\n",
       "         [-0.9891],\n",
       "         [-0.9890],\n",
       "         [-0.9889],\n",
       "         [-0.9888],\n",
       "         [-0.9886],\n",
       "         [-0.9885],\n",
       "         [-0.9884],\n",
       "         [-0.9883],\n",
       "         [-0.9882],\n",
       "         [-0.9880],\n",
       "         [-0.9879],\n",
       "         [-0.9878],\n",
       "         [-0.9877],\n",
       "         [-0.9876],\n",
       "         [-0.9874],\n",
       "         [-0.9873],\n",
       "         [-0.9872],\n",
       "         [-0.9871],\n",
       "         [-0.9869],\n",
       "         [-0.9868],\n",
       "         [-0.9867],\n",
       "         [-0.9866],\n",
       "         [-0.9864],\n",
       "         [-0.9863],\n",
       "         [-0.9862],\n",
       "         [-0.9861],\n",
       "         [-0.9859],\n",
       "         [-0.9858],\n",
       "         [-0.9857],\n",
       "         [-0.9856],\n",
       "         [-0.9854],\n",
       "         [-0.9853],\n",
       "         [-0.9852],\n",
       "         [-0.9851],\n",
       "         [-0.9849],\n",
       "         [-0.9848],\n",
       "         [-0.9847],\n",
       "         [-0.9846],\n",
       "         [-0.9844],\n",
       "         [-0.9843],\n",
       "         [-0.9842],\n",
       "         [-0.9840],\n",
       "         [-0.9839],\n",
       "         [-0.9838],\n",
       "         [-0.9837],\n",
       "         [-0.9835],\n",
       "         [-0.9834],\n",
       "         [-0.9833],\n",
       "         [-0.9831],\n",
       "         [-0.9830],\n",
       "         [-0.9829],\n",
       "         [-0.9827],\n",
       "         [-0.9826],\n",
       "         [-0.9825],\n",
       "         [-0.9824],\n",
       "         [-0.9822],\n",
       "         [-0.9821],\n",
       "         [-0.9820],\n",
       "         [-0.9818],\n",
       "         [-0.9817],\n",
       "         [-0.9816],\n",
       "         [-0.9814],\n",
       "         [-0.9813]]),\n",
       " tensor([[-0.9812],\n",
       "         [-0.9810],\n",
       "         [-0.9809],\n",
       "         [-0.9808],\n",
       "         [-0.9806],\n",
       "         [-0.9805],\n",
       "         [-0.9804],\n",
       "         [-0.9802],\n",
       "         [-0.9801],\n",
       "         [-0.9800],\n",
       "         [-0.9798],\n",
       "         [-0.9797],\n",
       "         [-0.9796],\n",
       "         [-0.9794],\n",
       "         [-0.9793],\n",
       "         [-0.9791],\n",
       "         [-0.9790],\n",
       "         [-0.9789],\n",
       "         [-0.9787],\n",
       "         [-0.9786],\n",
       "         [-0.9785],\n",
       "         [-0.9783],\n",
       "         [-0.9782],\n",
       "         [-0.9781],\n",
       "         [-0.9779],\n",
       "         [-0.9778],\n",
       "         [-0.9776],\n",
       "         [-0.9775],\n",
       "         [-0.9774],\n",
       "         [-0.9772],\n",
       "         [-0.9771],\n",
       "         [-0.9769],\n",
       "         [-0.9768],\n",
       "         [-0.9767],\n",
       "         [-0.9765],\n",
       "         [-0.9764],\n",
       "         [-0.9762],\n",
       "         [-0.9761],\n",
       "         [-0.9760],\n",
       "         [-0.9758],\n",
       "         [-0.9757],\n",
       "         [-0.9755],\n",
       "         [-0.9754],\n",
       "         [-0.9753],\n",
       "         [-0.9751],\n",
       "         [-0.9750],\n",
       "         [-0.9748],\n",
       "         [-0.9747],\n",
       "         [-0.9745],\n",
       "         [-0.9744],\n",
       "         [-0.9743],\n",
       "         [-0.9741],\n",
       "         [-0.9740],\n",
       "         [-0.9738],\n",
       "         [-0.9737],\n",
       "         [-0.9735],\n",
       "         [-0.9734],\n",
       "         [-0.9733],\n",
       "         [-0.9731],\n",
       "         [-0.9730],\n",
       "         [-0.9728],\n",
       "         [-0.9727],\n",
       "         [-0.9725],\n",
       "         [-0.9724],\n",
       "         [-0.9722],\n",
       "         [-0.9721],\n",
       "         [-0.9719],\n",
       "         [-0.9718],\n",
       "         [-0.9717],\n",
       "         [-0.9715],\n",
       "         [-0.9714],\n",
       "         [-0.9712],\n",
       "         [-0.9711],\n",
       "         [-0.9709],\n",
       "         [-0.9708],\n",
       "         [-0.9706],\n",
       "         [-0.9705],\n",
       "         [-0.9703],\n",
       "         [-0.9702],\n",
       "         [-0.9700],\n",
       "         [-0.9699],\n",
       "         [-0.9697],\n",
       "         [-0.9696],\n",
       "         [-0.9694],\n",
       "         [-0.9693],\n",
       "         [-0.9691],\n",
       "         [-0.9690],\n",
       "         [-0.9688],\n",
       "         [-0.9687],\n",
       "         [-0.9685],\n",
       "         [-0.9684],\n",
       "         [-0.9682],\n",
       "         [-0.9681],\n",
       "         [-0.9679],\n",
       "         [-0.9678],\n",
       "         [-0.9676],\n",
       "         [-0.9675],\n",
       "         [-0.9673],\n",
       "         [-0.9672],\n",
       "         [-0.9670],\n",
       "         [-0.9669],\n",
       "         [-0.9667],\n",
       "         [-0.9666],\n",
       "         [-0.9664],\n",
       "         [-0.9662],\n",
       "         [-0.9661],\n",
       "         [-0.9659],\n",
       "         [-0.9658],\n",
       "         [-0.9656],\n",
       "         [-0.9655],\n",
       "         [-0.9653],\n",
       "         [-0.9652],\n",
       "         [-0.9650],\n",
       "         [-0.9649],\n",
       "         [-0.9647],\n",
       "         [-0.9646],\n",
       "         [-0.9644],\n",
       "         [-0.9642],\n",
       "         [-0.9641],\n",
       "         [-0.9639],\n",
       "         [-0.9638],\n",
       "         [-0.9636],\n",
       "         [-0.9635],\n",
       "         [-0.9633],\n",
       "         [-0.9631],\n",
       "         [-0.9630],\n",
       "         [-0.9628],\n",
       "         [-0.9627]]),\n",
       " tensor([[-0.9625],\n",
       "         [-0.9624],\n",
       "         [-0.9622],\n",
       "         [-0.9620],\n",
       "         [-0.9619],\n",
       "         [-0.9617],\n",
       "         [-0.9616],\n",
       "         [-0.9614],\n",
       "         [-0.9613],\n",
       "         [-0.9611],\n",
       "         [-0.9609],\n",
       "         [-0.9608],\n",
       "         [-0.9606],\n",
       "         [-0.9605],\n",
       "         [-0.9603],\n",
       "         [-0.9601],\n",
       "         [-0.9600],\n",
       "         [-0.9598],\n",
       "         [-0.9597],\n",
       "         [-0.9595],\n",
       "         [-0.9593],\n",
       "         [-0.9592],\n",
       "         [-0.9590],\n",
       "         [-0.9589],\n",
       "         [-0.9587],\n",
       "         [-0.9585],\n",
       "         [-0.9584],\n",
       "         [-0.9582],\n",
       "         [-0.9580],\n",
       "         [-0.9579],\n",
       "         [-0.9577],\n",
       "         [-0.9576],\n",
       "         [-0.9574],\n",
       "         [-0.9572],\n",
       "         [-0.9571],\n",
       "         [-0.9569],\n",
       "         [-0.9567],\n",
       "         [-0.9566],\n",
       "         [-0.9564],\n",
       "         [-0.9563],\n",
       "         [-0.9561],\n",
       "         [-0.9559],\n",
       "         [-0.9558],\n",
       "         [-0.9556],\n",
       "         [-0.9554],\n",
       "         [-0.9553],\n",
       "         [-0.9551],\n",
       "         [-0.9549],\n",
       "         [-0.9548],\n",
       "         [-0.9546],\n",
       "         [-0.9545],\n",
       "         [-0.9543],\n",
       "         [-0.9541],\n",
       "         [-0.9540],\n",
       "         [-0.9538],\n",
       "         [-0.9536],\n",
       "         [-0.9535],\n",
       "         [-0.9533],\n",
       "         [-0.9531],\n",
       "         [-0.9530],\n",
       "         [-0.9528],\n",
       "         [-0.9526],\n",
       "         [-0.9525],\n",
       "         [-0.9523],\n",
       "         [-0.9521],\n",
       "         [-0.9520],\n",
       "         [-0.9518],\n",
       "         [-0.9516],\n",
       "         [-0.9515],\n",
       "         [-0.9513],\n",
       "         [-0.9511],\n",
       "         [-0.9510],\n",
       "         [-0.9508],\n",
       "         [-0.9506],\n",
       "         [-0.9505],\n",
       "         [-0.9503],\n",
       "         [-0.9501],\n",
       "         [-0.9500],\n",
       "         [-0.9498],\n",
       "         [-0.9496],\n",
       "         [-0.9495],\n",
       "         [-0.9493],\n",
       "         [-0.9491],\n",
       "         [-0.9489],\n",
       "         [-0.9488],\n",
       "         [-0.9486],\n",
       "         [-0.9484],\n",
       "         [-0.9483],\n",
       "         [-0.9481],\n",
       "         [-0.9479],\n",
       "         [-0.9478],\n",
       "         [-0.9476],\n",
       "         [-0.9474],\n",
       "         [-0.9473],\n",
       "         [-0.9471],\n",
       "         [-0.9469],\n",
       "         [-0.9467],\n",
       "         [-0.9466],\n",
       "         [-0.9464],\n",
       "         [-0.9462],\n",
       "         [-0.9461],\n",
       "         [-0.9459],\n",
       "         [-0.9457],\n",
       "         [-0.9456],\n",
       "         [-0.9454],\n",
       "         [-0.9452],\n",
       "         [-0.9450],\n",
       "         [-0.9449],\n",
       "         [-0.9447],\n",
       "         [-0.9445],\n",
       "         [-0.9444],\n",
       "         [-0.9442],\n",
       "         [-0.9440],\n",
       "         [-0.9438],\n",
       "         [-0.9437],\n",
       "         [-0.9435],\n",
       "         [-0.9433],\n",
       "         [-0.9432],\n",
       "         [-0.9430],\n",
       "         [-0.9428],\n",
       "         [-0.9426],\n",
       "         [-0.9425],\n",
       "         [-0.9423],\n",
       "         [-0.9421],\n",
       "         [-0.9420],\n",
       "         [-0.9418],\n",
       "         [-0.9416],\n",
       "         [-0.9414]]),\n",
       " tensor([[-0.9413],\n",
       "         [-0.9411],\n",
       "         [-0.9409],\n",
       "         [-0.9407],\n",
       "         [-0.9406],\n",
       "         [-0.9404],\n",
       "         [-0.9402],\n",
       "         [-0.9400],\n",
       "         [-0.9399],\n",
       "         [-0.9397],\n",
       "         [-0.9395],\n",
       "         [-0.9393],\n",
       "         [-0.9392],\n",
       "         [-0.9390],\n",
       "         [-0.9388],\n",
       "         [-0.9387],\n",
       "         [-0.9385],\n",
       "         [-0.9383],\n",
       "         [-0.9381],\n",
       "         [-0.9380],\n",
       "         [-0.9378],\n",
       "         [-0.9376],\n",
       "         [-0.9374],\n",
       "         [-0.9373],\n",
       "         [-0.9371],\n",
       "         [-0.9369],\n",
       "         [-0.9367],\n",
       "         [-0.9365],\n",
       "         [-0.9364],\n",
       "         [-0.9362],\n",
       "         [-0.9360],\n",
       "         [-0.9358],\n",
       "         [-0.9357],\n",
       "         [-0.9355],\n",
       "         [-0.9353],\n",
       "         [-0.9351],\n",
       "         [-0.9350],\n",
       "         [-0.9348],\n",
       "         [-0.9346],\n",
       "         [-0.9344],\n",
       "         [-0.9343],\n",
       "         [-0.9341],\n",
       "         [-0.9339],\n",
       "         [-0.9337],\n",
       "         [-0.9336],\n",
       "         [-0.9334],\n",
       "         [-0.9332],\n",
       "         [-0.9330],\n",
       "         [-0.9328],\n",
       "         [-0.9327],\n",
       "         [-0.9325],\n",
       "         [-0.9323],\n",
       "         [-0.9321],\n",
       "         [-0.9320],\n",
       "         [-0.9318],\n",
       "         [-0.9316],\n",
       "         [-0.9314],\n",
       "         [-0.9312],\n",
       "         [-0.9311],\n",
       "         [-0.9309],\n",
       "         [-0.9307],\n",
       "         [-0.9305],\n",
       "         [-0.9304],\n",
       "         [-0.9302],\n",
       "         [-0.9300],\n",
       "         [-0.9298],\n",
       "         [-0.9296],\n",
       "         [-0.9295],\n",
       "         [-0.9293],\n",
       "         [-0.9291],\n",
       "         [-0.9289],\n",
       "         [-0.9287],\n",
       "         [-0.9286],\n",
       "         [-0.9284],\n",
       "         [-0.9282],\n",
       "         [-0.9280],\n",
       "         [-0.9278],\n",
       "         [-0.9277],\n",
       "         [-0.9275],\n",
       "         [-0.9273],\n",
       "         [-0.9271],\n",
       "         [-0.9269],\n",
       "         [-0.9268],\n",
       "         [-0.9266],\n",
       "         [-0.9264],\n",
       "         [-0.9262],\n",
       "         [-0.9261],\n",
       "         [-0.9259],\n",
       "         [-0.9257],\n",
       "         [-0.9255],\n",
       "         [-0.9253],\n",
       "         [-0.9251],\n",
       "         [-0.9250],\n",
       "         [-0.9248],\n",
       "         [-0.9246],\n",
       "         [-0.9244],\n",
       "         [-0.9242],\n",
       "         [-0.9241],\n",
       "         [-0.9239],\n",
       "         [-0.9237],\n",
       "         [-0.9235],\n",
       "         [-0.9233],\n",
       "         [-0.9232],\n",
       "         [-0.9230],\n",
       "         [-0.9228],\n",
       "         [-0.9226],\n",
       "         [-0.9224],\n",
       "         [-0.9223],\n",
       "         [-0.9221],\n",
       "         [-0.9219],\n",
       "         [-0.9217],\n",
       "         [-0.9215],\n",
       "         [-0.9213],\n",
       "         [-0.9212],\n",
       "         [-0.9210],\n",
       "         [-0.9208],\n",
       "         [-0.9206],\n",
       "         [-0.9204],\n",
       "         [-0.9203],\n",
       "         [-0.9201],\n",
       "         [-0.9199],\n",
       "         [-0.9197],\n",
       "         [-0.9195],\n",
       "         [-0.9193],\n",
       "         [-0.9192],\n",
       "         [-0.9190],\n",
       "         [-0.9188],\n",
       "         [-0.9186]]),\n",
       " tensor([[-0.9184],\n",
       "         [-0.9183],\n",
       "         [-0.9181],\n",
       "         [-0.9179],\n",
       "         [-0.9177],\n",
       "         [-0.9175],\n",
       "         [-0.9173],\n",
       "         [-0.9172],\n",
       "         [-0.9170],\n",
       "         [-0.9168],\n",
       "         [-0.9166],\n",
       "         [-0.9164],\n",
       "         [-0.9162],\n",
       "         [-0.9161],\n",
       "         [-0.9159],\n",
       "         [-0.9157],\n",
       "         [-0.9155],\n",
       "         [-0.9153],\n",
       "         [-0.9152],\n",
       "         [-0.9150],\n",
       "         [-0.9148],\n",
       "         [-0.9146],\n",
       "         [-0.9144],\n",
       "         [-0.9142],\n",
       "         [-0.9141],\n",
       "         [-0.9139],\n",
       "         [-0.9137],\n",
       "         [-0.9135],\n",
       "         [-0.9133],\n",
       "         [-0.9131],\n",
       "         [-0.9130],\n",
       "         [-0.9128],\n",
       "         [-0.9126],\n",
       "         [-0.9124],\n",
       "         [-0.9122],\n",
       "         [-0.9120],\n",
       "         [-0.9119],\n",
       "         [-0.9117],\n",
       "         [-0.9115],\n",
       "         [-0.9113],\n",
       "         [-0.9111],\n",
       "         [-0.9109],\n",
       "         [-0.9108],\n",
       "         [-0.9106],\n",
       "         [-0.9104],\n",
       "         [-0.9102],\n",
       "         [-0.9100],\n",
       "         [-0.9098],\n",
       "         [-0.9097],\n",
       "         [-0.9095],\n",
       "         [-0.9093],\n",
       "         [-0.9091],\n",
       "         [-0.9089],\n",
       "         [-0.9087],\n",
       "         [-0.9086],\n",
       "         [-0.9084],\n",
       "         [-0.9082],\n",
       "         [-0.9080],\n",
       "         [-0.9078],\n",
       "         [-0.9076],\n",
       "         [-0.9075],\n",
       "         [-0.9073],\n",
       "         [-0.9071],\n",
       "         [-0.9069],\n",
       "         [-0.9067],\n",
       "         [-0.9065],\n",
       "         [-0.9064],\n",
       "         [-0.9062],\n",
       "         [-0.9060],\n",
       "         [-0.9058],\n",
       "         [-0.9056],\n",
       "         [-0.9054],\n",
       "         [-0.9053],\n",
       "         [-0.9051],\n",
       "         [-0.9049],\n",
       "         [-0.9047],\n",
       "         [-0.9045],\n",
       "         [-0.9043],\n",
       "         [-0.9042],\n",
       "         [-0.9040],\n",
       "         [-0.9038],\n",
       "         [-0.9036],\n",
       "         [-0.9034],\n",
       "         [-0.9032],\n",
       "         [-0.9031],\n",
       "         [-0.9029],\n",
       "         [-0.9027],\n",
       "         [-0.9025],\n",
       "         [-0.9023],\n",
       "         [-0.9021],\n",
       "         [-0.9020],\n",
       "         [-0.9018],\n",
       "         [-0.9016],\n",
       "         [-0.9014],\n",
       "         [-0.9012],\n",
       "         [-0.9010],\n",
       "         [-0.9009],\n",
       "         [-0.9007],\n",
       "         [-0.9005],\n",
       "         [-0.9003],\n",
       "         [-0.9001],\n",
       "         [-0.8999],\n",
       "         [-0.8998],\n",
       "         [-0.8996],\n",
       "         [-0.8994],\n",
       "         [-0.8992],\n",
       "         [-0.8990],\n",
       "         [-0.8988],\n",
       "         [-0.8987],\n",
       "         [-0.8985],\n",
       "         [-0.8983],\n",
       "         [-0.8981],\n",
       "         [-0.8979],\n",
       "         [-0.8977],\n",
       "         [-0.8976],\n",
       "         [-0.8974],\n",
       "         [-0.8972],\n",
       "         [-0.8970],\n",
       "         [-0.8968],\n",
       "         [-0.8967],\n",
       "         [-0.8965],\n",
       "         [-0.8963],\n",
       "         [-0.8961],\n",
       "         [-0.8959],\n",
       "         [-0.8957],\n",
       "         [-0.8956],\n",
       "         [-0.8954],\n",
       "         [-0.8952]]),\n",
       " tensor([[-0.8950],\n",
       "         [-0.8948],\n",
       "         [-0.8947],\n",
       "         [-0.8945],\n",
       "         [-0.8943],\n",
       "         [-0.8941],\n",
       "         [-0.8939],\n",
       "         [-0.8937],\n",
       "         [-0.8936],\n",
       "         [-0.8934],\n",
       "         [-0.8932],\n",
       "         [-0.8930],\n",
       "         [-0.8928],\n",
       "         [-0.8927],\n",
       "         [-0.8925],\n",
       "         [-0.8923],\n",
       "         [-0.8921],\n",
       "         [-0.8919],\n",
       "         [-0.8917],\n",
       "         [-0.8916],\n",
       "         [-0.8914],\n",
       "         [-0.8912],\n",
       "         [-0.8910],\n",
       "         [-0.8908],\n",
       "         [-0.8907],\n",
       "         [-0.8905],\n",
       "         [-0.8903],\n",
       "         [-0.8901],\n",
       "         [-0.8899],\n",
       "         [-0.8898],\n",
       "         [-0.8896],\n",
       "         [-0.8894],\n",
       "         [-0.8892],\n",
       "         [-0.8890],\n",
       "         [-0.8889],\n",
       "         [-0.8887],\n",
       "         [-0.8885],\n",
       "         [-0.8883],\n",
       "         [-0.8881],\n",
       "         [-0.8880],\n",
       "         [-0.8878],\n",
       "         [-0.8876],\n",
       "         [-0.8874],\n",
       "         [-0.8872],\n",
       "         [-0.8871],\n",
       "         [-0.8869],\n",
       "         [-0.8867],\n",
       "         [-0.8865],\n",
       "         [-0.8863],\n",
       "         [-0.8862],\n",
       "         [-0.8860],\n",
       "         [-0.8858],\n",
       "         [-0.8856],\n",
       "         [-0.8854],\n",
       "         [-0.8853],\n",
       "         [-0.8851],\n",
       "         [-0.8849],\n",
       "         [-0.8847],\n",
       "         [-0.8845],\n",
       "         [-0.8844],\n",
       "         [-0.8842],\n",
       "         [-0.8840],\n",
       "         [-0.8838],\n",
       "         [-0.8837],\n",
       "         [-0.8835],\n",
       "         [-0.8833],\n",
       "         [-0.8831],\n",
       "         [-0.8829],\n",
       "         [-0.8828],\n",
       "         [-0.8826],\n",
       "         [-0.8824],\n",
       "         [-0.8822],\n",
       "         [-0.8820],\n",
       "         [-0.8819],\n",
       "         [-0.8817],\n",
       "         [-0.8815],\n",
       "         [-0.8813],\n",
       "         [-0.8812],\n",
       "         [-0.8810],\n",
       "         [-0.8808],\n",
       "         [-0.8806],\n",
       "         [-0.8804],\n",
       "         [-0.8803],\n",
       "         [-0.8801],\n",
       "         [-0.8799],\n",
       "         [-0.8797],\n",
       "         [-0.8796],\n",
       "         [-0.8794],\n",
       "         [-0.8792],\n",
       "         [-0.8790],\n",
       "         [-0.8788],\n",
       "         [-0.8787],\n",
       "         [-0.8785],\n",
       "         [-0.8783],\n",
       "         [-0.8781],\n",
       "         [-0.8780],\n",
       "         [-0.8778],\n",
       "         [-0.8776],\n",
       "         [-0.8774],\n",
       "         [-0.8773],\n",
       "         [-0.8771],\n",
       "         [-0.8769],\n",
       "         [-0.8767],\n",
       "         [-0.8766],\n",
       "         [-0.8764],\n",
       "         [-0.8762],\n",
       "         [-0.8760],\n",
       "         [-0.8758],\n",
       "         [-0.8757],\n",
       "         [-0.8755],\n",
       "         [-0.8753],\n",
       "         [-0.8751],\n",
       "         [-0.8750],\n",
       "         [-0.8748],\n",
       "         [-0.8746],\n",
       "         [-0.8744],\n",
       "         [-0.8743],\n",
       "         [-0.8741],\n",
       "         [-0.8739],\n",
       "         [-0.8737],\n",
       "         [-0.8736],\n",
       "         [-0.8734],\n",
       "         [-0.8732],\n",
       "         [-0.8730],\n",
       "         [-0.8729],\n",
       "         [-0.8727],\n",
       "         [-0.8725],\n",
       "         [-0.8723]]),\n",
       " tensor([[-0.8722],\n",
       "         [-0.8720],\n",
       "         [-0.8718],\n",
       "         [-0.8716],\n",
       "         [-0.8715],\n",
       "         [-0.8713],\n",
       "         [-0.8711],\n",
       "         [-0.8709],\n",
       "         [-0.8708],\n",
       "         [-0.8706],\n",
       "         [-0.8704],\n",
       "         [-0.8703],\n",
       "         [-0.8701],\n",
       "         [-0.8699],\n",
       "         [-0.8697],\n",
       "         [-0.8696],\n",
       "         [-0.8694],\n",
       "         [-0.8692],\n",
       "         [-0.8690],\n",
       "         [-0.8689],\n",
       "         [-0.8687],\n",
       "         [-0.8685],\n",
       "         [-0.8683],\n",
       "         [-0.8682],\n",
       "         [-0.8680],\n",
       "         [-0.8678],\n",
       "         [-0.8677],\n",
       "         [-0.8675],\n",
       "         [-0.8673],\n",
       "         [-0.8671],\n",
       "         [-0.8670],\n",
       "         [-0.8668],\n",
       "         [-0.8666],\n",
       "         [-0.8664],\n",
       "         [-0.8663],\n",
       "         [-0.8661],\n",
       "         [-0.8659],\n",
       "         [-0.8658],\n",
       "         [-0.8656],\n",
       "         [-0.8654],\n",
       "         [-0.8652],\n",
       "         [-0.8651],\n",
       "         [-0.8649],\n",
       "         [-0.8647],\n",
       "         [-0.8645],\n",
       "         [-0.8644],\n",
       "         [-0.8642],\n",
       "         [-0.8640],\n",
       "         [-0.8639],\n",
       "         [-0.8637],\n",
       "         [-0.8635],\n",
       "         [-0.8633],\n",
       "         [-0.8632],\n",
       "         [-0.8630],\n",
       "         [-0.8628],\n",
       "         [-0.8627],\n",
       "         [-0.8625],\n",
       "         [-0.8623],\n",
       "         [-0.8621],\n",
       "         [-0.8620],\n",
       "         [-0.8618],\n",
       "         [-0.8616],\n",
       "         [-0.8615],\n",
       "         [-0.8613],\n",
       "         [-0.8611],\n",
       "         [-0.8610],\n",
       "         [-0.8608],\n",
       "         [-0.8606],\n",
       "         [-0.8604],\n",
       "         [-0.8603],\n",
       "         [-0.8601],\n",
       "         [-0.8599],\n",
       "         [-0.8598],\n",
       "         [-0.8596],\n",
       "         [-0.8594],\n",
       "         [-0.8592],\n",
       "         [-0.8591],\n",
       "         [-0.8589],\n",
       "         [-0.8587],\n",
       "         [-0.8586],\n",
       "         [-0.8584],\n",
       "         [-0.8582],\n",
       "         [-0.8581],\n",
       "         [-0.8579],\n",
       "         [-0.8577],\n",
       "         [-0.8576],\n",
       "         [-0.8574],\n",
       "         [-0.8572],\n",
       "         [-0.8570],\n",
       "         [-0.8569],\n",
       "         [-0.8567],\n",
       "         [-0.8565],\n",
       "         [-0.8564],\n",
       "         [-0.8562],\n",
       "         [-0.8560],\n",
       "         [-0.8559],\n",
       "         [-0.8557],\n",
       "         [-0.8555],\n",
       "         [-0.8554],\n",
       "         [-0.8552],\n",
       "         [-0.8550],\n",
       "         [-0.8548],\n",
       "         [-0.8547],\n",
       "         [-0.8545],\n",
       "         [-0.8543],\n",
       "         [-0.8542],\n",
       "         [-0.8540],\n",
       "         [-0.8538],\n",
       "         [-0.8537],\n",
       "         [-0.8535],\n",
       "         [-0.8533],\n",
       "         [-0.8532],\n",
       "         [-0.8530],\n",
       "         [-0.8528],\n",
       "         [-0.8527],\n",
       "         [-0.8525],\n",
       "         [-0.8523],\n",
       "         [-0.8522],\n",
       "         [-0.8520],\n",
       "         [-0.8518],\n",
       "         [-0.8517],\n",
       "         [-0.8515],\n",
       "         [-0.8513],\n",
       "         [-0.8511],\n",
       "         [-0.8510],\n",
       "         [-0.8508],\n",
       "         [-0.8506],\n",
       "         [-0.8505]]),\n",
       " tensor([[-0.8503],\n",
       "         [-0.8501],\n",
       "         [-0.8500],\n",
       "         [-0.8498],\n",
       "         [-0.8496],\n",
       "         [-0.8495],\n",
       "         [-0.8493],\n",
       "         [-0.8491],\n",
       "         [-0.8490],\n",
       "         [-0.8488],\n",
       "         [-0.8486],\n",
       "         [-0.8485],\n",
       "         [-0.8483],\n",
       "         [-0.8481],\n",
       "         [-0.8480],\n",
       "         [-0.8478],\n",
       "         [-0.8476],\n",
       "         [-0.8475],\n",
       "         [-0.8473],\n",
       "         [-0.8471],\n",
       "         [-0.8470],\n",
       "         [-0.8468],\n",
       "         [-0.8466],\n",
       "         [-0.8465],\n",
       "         [-0.8463],\n",
       "         [-0.8461],\n",
       "         [-0.8460],\n",
       "         [-0.8458],\n",
       "         [-0.8457],\n",
       "         [-0.8455],\n",
       "         [-0.8453],\n",
       "         [-0.8452],\n",
       "         [-0.8450],\n",
       "         [-0.8448],\n",
       "         [-0.8447],\n",
       "         [-0.8445],\n",
       "         [-0.8443],\n",
       "         [-0.8442],\n",
       "         [-0.8440],\n",
       "         [-0.8438],\n",
       "         [-0.8437],\n",
       "         [-0.8435],\n",
       "         [-0.8433],\n",
       "         [-0.8432],\n",
       "         [-0.8430],\n",
       "         [-0.8428],\n",
       "         [-0.8427],\n",
       "         [-0.8425],\n",
       "         [-0.8423],\n",
       "         [-0.8422],\n",
       "         [-0.8420],\n",
       "         [-0.8419],\n",
       "         [-0.8417],\n",
       "         [-0.8415],\n",
       "         [-0.8414],\n",
       "         [-0.8412],\n",
       "         [-0.8410],\n",
       "         [-0.8409],\n",
       "         [-0.8407],\n",
       "         [-0.8405],\n",
       "         [-0.8404],\n",
       "         [-0.8402],\n",
       "         [-0.8400],\n",
       "         [-0.8399],\n",
       "         [-0.8397],\n",
       "         [-0.8396],\n",
       "         [-0.8394],\n",
       "         [-0.8392],\n",
       "         [-0.8391],\n",
       "         [-0.8389],\n",
       "         [-0.8387],\n",
       "         [-0.8385],\n",
       "         [-0.8384],\n",
       "         [-0.8382],\n",
       "         [-0.8380],\n",
       "         [-0.8378],\n",
       "         [-0.8377],\n",
       "         [-0.8375],\n",
       "         [-0.8373],\n",
       "         [-0.8371],\n",
       "         [-0.8370],\n",
       "         [-0.8368],\n",
       "         [-0.8366],\n",
       "         [-0.8364],\n",
       "         [-0.8362],\n",
       "         [-0.8361],\n",
       "         [-0.8359],\n",
       "         [-0.8357],\n",
       "         [-0.8355],\n",
       "         [-0.8354],\n",
       "         [-0.8352],\n",
       "         [-0.8350],\n",
       "         [-0.8348],\n",
       "         [-0.8347],\n",
       "         [-0.8345],\n",
       "         [-0.8343],\n",
       "         [-0.8341],\n",
       "         [-0.8340],\n",
       "         [-0.8338],\n",
       "         [-0.8336],\n",
       "         [-0.8334],\n",
       "         [-0.8333],\n",
       "         [-0.8331],\n",
       "         [-0.8329],\n",
       "         [-0.8328],\n",
       "         [-0.8326],\n",
       "         [-0.8324],\n",
       "         [-0.8322],\n",
       "         [-0.8321],\n",
       "         [-0.8319],\n",
       "         [-0.8317],\n",
       "         [-0.8315],\n",
       "         [-0.8313],\n",
       "         [-0.8312],\n",
       "         [-0.8310],\n",
       "         [-0.8308],\n",
       "         [-0.8306],\n",
       "         [-0.8304],\n",
       "         [-0.8302],\n",
       "         [-0.8300],\n",
       "         [-0.8298],\n",
       "         [-0.8296],\n",
       "         [-0.8295],\n",
       "         [-0.8293],\n",
       "         [-0.8291],\n",
       "         [-0.8289],\n",
       "         [-0.8287],\n",
       "         [-0.8285]]),\n",
       " tensor([[-0.8283],\n",
       "         [-0.8281],\n",
       "         [-0.8280],\n",
       "         [-0.8278],\n",
       "         [-0.8276],\n",
       "         [-0.8274],\n",
       "         [-0.8272],\n",
       "         [-0.8270],\n",
       "         [-0.8268],\n",
       "         [-0.8266],\n",
       "         [-0.8264],\n",
       "         [-0.8262],\n",
       "         [-0.8261],\n",
       "         [-0.8259],\n",
       "         [-0.8257],\n",
       "         [-0.8255],\n",
       "         [-0.8253],\n",
       "         [-0.8251],\n",
       "         [-0.8249],\n",
       "         [-0.8247],\n",
       "         [-0.8245],\n",
       "         [-0.8244],\n",
       "         [-0.8242],\n",
       "         [-0.8240],\n",
       "         [-0.8238],\n",
       "         [-0.8236],\n",
       "         [-0.8234],\n",
       "         [-0.8232],\n",
       "         [-0.8230],\n",
       "         [-0.8229],\n",
       "         [-0.8227],\n",
       "         [-0.8225],\n",
       "         [-0.8223],\n",
       "         [-0.8221],\n",
       "         [-0.8219],\n",
       "         [-0.8217],\n",
       "         [-0.8215],\n",
       "         [-0.8213],\n",
       "         [-0.8212],\n",
       "         [-0.8210],\n",
       "         [-0.8208],\n",
       "         [-0.8206],\n",
       "         [-0.8204],\n",
       "         [-0.8202],\n",
       "         [-0.8200],\n",
       "         [-0.8199],\n",
       "         [-0.8197],\n",
       "         [-0.8195],\n",
       "         [-0.8193],\n",
       "         [-0.8191],\n",
       "         [-0.8189],\n",
       "         [-0.8187],\n",
       "         [-0.8185],\n",
       "         [-0.8184],\n",
       "         [-0.8182],\n",
       "         [-0.8180],\n",
       "         [-0.8178],\n",
       "         [-0.8176],\n",
       "         [-0.8174],\n",
       "         [-0.8172],\n",
       "         [-0.8171],\n",
       "         [-0.8169],\n",
       "         [-0.8167],\n",
       "         [-0.8165],\n",
       "         [-0.8163],\n",
       "         [-0.8161],\n",
       "         [-0.8159],\n",
       "         [-0.8157],\n",
       "         [-0.8156],\n",
       "         [-0.8154],\n",
       "         [-0.8152],\n",
       "         [-0.8150],\n",
       "         [-0.8148],\n",
       "         [-0.8146],\n",
       "         [-0.8144],\n",
       "         [-0.8143],\n",
       "         [-0.8141],\n",
       "         [-0.8139],\n",
       "         [-0.8137],\n",
       "         [-0.8135],\n",
       "         [-0.8133],\n",
       "         [-0.8132],\n",
       "         [-0.8130],\n",
       "         [-0.8128],\n",
       "         [-0.8126],\n",
       "         [-0.8124],\n",
       "         [-0.8122],\n",
       "         [-0.8120],\n",
       "         [-0.8119],\n",
       "         [-0.8117],\n",
       "         [-0.8115],\n",
       "         [-0.8113],\n",
       "         [-0.8111],\n",
       "         [-0.8109],\n",
       "         [-0.8108],\n",
       "         [-0.8106],\n",
       "         [-0.8104],\n",
       "         [-0.8102],\n",
       "         [-0.8100],\n",
       "         [-0.8098],\n",
       "         [-0.8097],\n",
       "         [-0.8095],\n",
       "         [-0.8093],\n",
       "         [-0.8091],\n",
       "         [-0.8089],\n",
       "         [-0.8087],\n",
       "         [-0.8085],\n",
       "         [-0.8084],\n",
       "         [-0.8082],\n",
       "         [-0.8080],\n",
       "         [-0.8078],\n",
       "         [-0.8076],\n",
       "         [-0.8074],\n",
       "         [-0.8073],\n",
       "         [-0.8071],\n",
       "         [-0.8069],\n",
       "         [-0.8067],\n",
       "         [-0.8065],\n",
       "         [-0.8063],\n",
       "         [-0.8062],\n",
       "         [-0.8060],\n",
       "         [-0.8058],\n",
       "         [-0.8056],\n",
       "         [-0.8054],\n",
       "         [-0.8052],\n",
       "         [-0.8051],\n",
       "         [-0.8049],\n",
       "         [-0.8047]]),\n",
       " tensor([[-0.8045],\n",
       "         [-0.8043],\n",
       "         [-0.8042],\n",
       "         [-0.8040],\n",
       "         [-0.8038],\n",
       "         [-0.8036],\n",
       "         [-0.8034],\n",
       "         [-0.8032],\n",
       "         [-0.8031],\n",
       "         [-0.8029],\n",
       "         [-0.8027],\n",
       "         [-0.8025],\n",
       "         [-0.8023],\n",
       "         [-0.8021],\n",
       "         [-0.8020],\n",
       "         [-0.8018],\n",
       "         [-0.8016],\n",
       "         [-0.8014],\n",
       "         [-0.8012],\n",
       "         [-0.8011],\n",
       "         [-0.8009],\n",
       "         [-0.8007],\n",
       "         [-0.8005],\n",
       "         [-0.8003],\n",
       "         [-0.8002],\n",
       "         [-0.8000],\n",
       "         [-0.7998],\n",
       "         [-0.7996],\n",
       "         [-0.7994],\n",
       "         [-0.7992],\n",
       "         [-0.7991],\n",
       "         [-0.7989],\n",
       "         [-0.7987],\n",
       "         [-0.7985],\n",
       "         [-0.7983],\n",
       "         [-0.7982],\n",
       "         [-0.7980],\n",
       "         [-0.7978],\n",
       "         [-0.7976],\n",
       "         [-0.7974],\n",
       "         [-0.7973],\n",
       "         [-0.7971],\n",
       "         [-0.7969],\n",
       "         [-0.7967],\n",
       "         [-0.7965],\n",
       "         [-0.7964],\n",
       "         [-0.7962],\n",
       "         [-0.7960],\n",
       "         [-0.7958],\n",
       "         [-0.7956],\n",
       "         [-0.7955],\n",
       "         [-0.7953],\n",
       "         [-0.7951],\n",
       "         [-0.7949],\n",
       "         [-0.7947],\n",
       "         [-0.7946],\n",
       "         [-0.7944],\n",
       "         [-0.7942],\n",
       "         [-0.7940],\n",
       "         [-0.7939],\n",
       "         [-0.7937],\n",
       "         [-0.7935],\n",
       "         [-0.7933],\n",
       "         [-0.7931],\n",
       "         [-0.7930],\n",
       "         [-0.7928],\n",
       "         [-0.7926],\n",
       "         [-0.7924],\n",
       "         [-0.7922],\n",
       "         [-0.7921],\n",
       "         [-0.7919],\n",
       "         [-0.7917],\n",
       "         [-0.7915],\n",
       "         [-0.7914],\n",
       "         [-0.7912],\n",
       "         [-0.7910],\n",
       "         [-0.7908],\n",
       "         [-0.7906],\n",
       "         [-0.7905],\n",
       "         [-0.7903],\n",
       "         [-0.7901],\n",
       "         [-0.7899],\n",
       "         [-0.7898],\n",
       "         [-0.7896],\n",
       "         [-0.7894],\n",
       "         [-0.7892],\n",
       "         [-0.7890],\n",
       "         [-0.7889],\n",
       "         [-0.7887],\n",
       "         [-0.7885],\n",
       "         [-0.7883],\n",
       "         [-0.7882],\n",
       "         [-0.7880],\n",
       "         [-0.7878],\n",
       "         [-0.7876],\n",
       "         [-0.7874],\n",
       "         [-0.7873],\n",
       "         [-0.7871],\n",
       "         [-0.7869],\n",
       "         [-0.7867],\n",
       "         [-0.7866],\n",
       "         [-0.7864],\n",
       "         [-0.7862],\n",
       "         [-0.7860],\n",
       "         [-0.7859],\n",
       "         [-0.7857],\n",
       "         [-0.7855],\n",
       "         [-0.7853],\n",
       "         [-0.7852],\n",
       "         [-0.7850],\n",
       "         [-0.7848],\n",
       "         [-0.7846],\n",
       "         [-0.7844],\n",
       "         [-0.7843],\n",
       "         [-0.7841],\n",
       "         [-0.7839],\n",
       "         [-0.7837],\n",
       "         [-0.7836],\n",
       "         [-0.7834],\n",
       "         [-0.7832],\n",
       "         [-0.7830],\n",
       "         [-0.7829],\n",
       "         [-0.7827],\n",
       "         [-0.7825],\n",
       "         [-0.7823],\n",
       "         [-0.7822],\n",
       "         [-0.7820],\n",
       "         [-0.7818]]),\n",
       " tensor([[-0.7816],\n",
       "         [-0.7815],\n",
       "         [-0.7813],\n",
       "         [-0.7811],\n",
       "         [-0.7809],\n",
       "         [-0.7808],\n",
       "         [-0.7806],\n",
       "         [-0.7804],\n",
       "         [-0.7802],\n",
       "         [-0.7801],\n",
       "         [-0.7799],\n",
       "         [-0.7797],\n",
       "         [-0.7795],\n",
       "         [-0.7794],\n",
       "         [-0.7792],\n",
       "         [-0.7790],\n",
       "         [-0.7789],\n",
       "         [-0.7787],\n",
       "         [-0.7785],\n",
       "         [-0.7783],\n",
       "         [-0.7782],\n",
       "         [-0.7780],\n",
       "         [-0.7778],\n",
       "         [-0.7776],\n",
       "         [-0.7775],\n",
       "         [-0.7773],\n",
       "         [-0.7771],\n",
       "         [-0.7769],\n",
       "         [-0.7768],\n",
       "         [-0.7766],\n",
       "         [-0.7764],\n",
       "         [-0.7763],\n",
       "         [-0.7761],\n",
       "         [-0.7759],\n",
       "         [-0.7757],\n",
       "         [-0.7756],\n",
       "         [-0.7754],\n",
       "         [-0.7752],\n",
       "         [-0.7750],\n",
       "         [-0.7749],\n",
       "         [-0.7747],\n",
       "         [-0.7745],\n",
       "         [-0.7744],\n",
       "         [-0.7742],\n",
       "         [-0.7740],\n",
       "         [-0.7738],\n",
       "         [-0.7737],\n",
       "         [-0.7735],\n",
       "         [-0.7733],\n",
       "         [-0.7731],\n",
       "         [-0.7730],\n",
       "         [-0.7728],\n",
       "         [-0.7726],\n",
       "         [-0.7725],\n",
       "         [-0.7723],\n",
       "         [-0.7721],\n",
       "         [-0.7719],\n",
       "         [-0.7718],\n",
       "         [-0.7716],\n",
       "         [-0.7714],\n",
       "         [-0.7713],\n",
       "         [-0.7711],\n",
       "         [-0.7709],\n",
       "         [-0.7707],\n",
       "         [-0.7706],\n",
       "         [-0.7704],\n",
       "         [-0.7702],\n",
       "         [-0.7701],\n",
       "         [-0.7699],\n",
       "         [-0.7697],\n",
       "         [-0.7695],\n",
       "         [-0.7694],\n",
       "         [-0.7692],\n",
       "         [-0.7690],\n",
       "         [-0.7689],\n",
       "         [-0.7687],\n",
       "         [-0.7685],\n",
       "         [-0.7684],\n",
       "         [-0.7682],\n",
       "         [-0.7680],\n",
       "         [-0.7678],\n",
       "         [-0.7677],\n",
       "         [-0.7675],\n",
       "         [-0.7673],\n",
       "         [-0.7672],\n",
       "         [-0.7670],\n",
       "         [-0.7668],\n",
       "         [-0.7666],\n",
       "         [-0.7665],\n",
       "         [-0.7663],\n",
       "         [-0.7661],\n",
       "         [-0.7660],\n",
       "         [-0.7658],\n",
       "         [-0.7656],\n",
       "         [-0.7655],\n",
       "         [-0.7653],\n",
       "         [-0.7651],\n",
       "         [-0.7649],\n",
       "         [-0.7648],\n",
       "         [-0.7646],\n",
       "         [-0.7644],\n",
       "         [-0.7643],\n",
       "         [-0.7641],\n",
       "         [-0.7639],\n",
       "         [-0.7638],\n",
       "         [-0.7636],\n",
       "         [-0.7634],\n",
       "         [-0.7633],\n",
       "         [-0.7631],\n",
       "         [-0.7629],\n",
       "         [-0.7627],\n",
       "         [-0.7626],\n",
       "         [-0.7624],\n",
       "         [-0.7622],\n",
       "         [-0.7621],\n",
       "         [-0.7619],\n",
       "         [-0.7617],\n",
       "         [-0.7616],\n",
       "         [-0.7614],\n",
       "         [-0.7612],\n",
       "         [-0.7611],\n",
       "         [-0.7609],\n",
       "         [-0.7607],\n",
       "         [-0.7605],\n",
       "         [-0.7604],\n",
       "         [-0.7602],\n",
       "         [-0.7600],\n",
       "         [-0.7599]]),\n",
       " tensor([[-0.7597],\n",
       "         [-0.7595],\n",
       "         [-0.7594],\n",
       "         [-0.7592],\n",
       "         [-0.7590],\n",
       "         [-0.7589],\n",
       "         [-0.7587],\n",
       "         [-0.7585],\n",
       "         [-0.7584],\n",
       "         [-0.7582],\n",
       "         [-0.7580],\n",
       "         [-0.7579],\n",
       "         [-0.7577],\n",
       "         [-0.7575],\n",
       "         [-0.7573],\n",
       "         [-0.7572],\n",
       "         [-0.7570],\n",
       "         [-0.7568],\n",
       "         [-0.7567],\n",
       "         [-0.7565],\n",
       "         [-0.7563],\n",
       "         [-0.7562],\n",
       "         [-0.7560],\n",
       "         [-0.7558],\n",
       "         [-0.7557],\n",
       "         [-0.7555],\n",
       "         [-0.7553],\n",
       "         [-0.7552],\n",
       "         [-0.7550],\n",
       "         [-0.7548],\n",
       "         [-0.7547],\n",
       "         [-0.7545],\n",
       "         [-0.7543],\n",
       "         [-0.7542],\n",
       "         [-0.7540],\n",
       "         [-0.7538],\n",
       "         [-0.7537],\n",
       "         [-0.7535],\n",
       "         [-0.7533],\n",
       "         [-0.7532],\n",
       "         [-0.7530],\n",
       "         [-0.7528],\n",
       "         [-0.7527],\n",
       "         [-0.7525],\n",
       "         [-0.7523],\n",
       "         [-0.7522],\n",
       "         [-0.7520],\n",
       "         [-0.7518],\n",
       "         [-0.7516],\n",
       "         [-0.7515],\n",
       "         [-0.7513],\n",
       "         [-0.7511],\n",
       "         [-0.7510],\n",
       "         [-0.7508],\n",
       "         [-0.7506],\n",
       "         [-0.7505],\n",
       "         [-0.7503],\n",
       "         [-0.7501],\n",
       "         [-0.7500],\n",
       "         [-0.7498],\n",
       "         [-0.7496],\n",
       "         [-0.7495],\n",
       "         [-0.7493],\n",
       "         [-0.7491],\n",
       "         [-0.7490],\n",
       "         [-0.7488],\n",
       "         [-0.7486],\n",
       "         [-0.7485],\n",
       "         [-0.7483],\n",
       "         [-0.7481],\n",
       "         [-0.7480],\n",
       "         [-0.7478],\n",
       "         [-0.7476],\n",
       "         [-0.7475],\n",
       "         [-0.7473],\n",
       "         [-0.7471],\n",
       "         [-0.7470],\n",
       "         [-0.7468],\n",
       "         [-0.7466],\n",
       "         [-0.7465],\n",
       "         [-0.7463],\n",
       "         [-0.7461],\n",
       "         [-0.7460],\n",
       "         [-0.7458],\n",
       "         [-0.7456],\n",
       "         [-0.7455],\n",
       "         [-0.7453],\n",
       "         [-0.7451],\n",
       "         [-0.7450],\n",
       "         [-0.7448],\n",
       "         [-0.7446],\n",
       "         [-0.7445],\n",
       "         [-0.7443],\n",
       "         [-0.7442],\n",
       "         [-0.7440],\n",
       "         [-0.7438],\n",
       "         [-0.7437],\n",
       "         [-0.7435],\n",
       "         [-0.7433],\n",
       "         [-0.7432],\n",
       "         [-0.7430],\n",
       "         [-0.7428],\n",
       "         [-0.7427],\n",
       "         [-0.7425],\n",
       "         [-0.7423],\n",
       "         [-0.7422],\n",
       "         [-0.7420],\n",
       "         [-0.7418],\n",
       "         [-0.7417],\n",
       "         [-0.7415],\n",
       "         [-0.7413],\n",
       "         [-0.7412],\n",
       "         [-0.7410],\n",
       "         [-0.7408],\n",
       "         [-0.7407],\n",
       "         [-0.7405],\n",
       "         [-0.7403],\n",
       "         [-0.7402],\n",
       "         [-0.7400],\n",
       "         [-0.7398],\n",
       "         [-0.7397],\n",
       "         [-0.7395],\n",
       "         [-0.7393],\n",
       "         [-0.7392],\n",
       "         [-0.7390],\n",
       "         [-0.7388],\n",
       "         [-0.7387],\n",
       "         [-0.7385]]),\n",
       " tensor([[-0.7384],\n",
       "         [-0.7382],\n",
       "         [-0.7380],\n",
       "         [-0.7379],\n",
       "         [-0.7377],\n",
       "         [-0.7375],\n",
       "         [-0.7374],\n",
       "         [-0.7372],\n",
       "         [-0.7370],\n",
       "         [-0.7369],\n",
       "         [-0.7367],\n",
       "         [-0.7365],\n",
       "         [-0.7364],\n",
       "         [-0.7362],\n",
       "         [-0.7360],\n",
       "         [-0.7359],\n",
       "         [-0.7357],\n",
       "         [-0.7355],\n",
       "         [-0.7354],\n",
       "         [-0.7352],\n",
       "         [-0.7351],\n",
       "         [-0.7349],\n",
       "         [-0.7347],\n",
       "         [-0.7346],\n",
       "         [-0.7344],\n",
       "         [-0.7342],\n",
       "         [-0.7341],\n",
       "         [-0.7339],\n",
       "         [-0.7337],\n",
       "         [-0.7336],\n",
       "         [-0.7334],\n",
       "         [-0.7332],\n",
       "         [-0.7331],\n",
       "         [-0.7329],\n",
       "         [-0.7327],\n",
       "         [-0.7326],\n",
       "         [-0.7324],\n",
       "         [-0.7323],\n",
       "         [-0.7321],\n",
       "         [-0.7319],\n",
       "         [-0.7318],\n",
       "         [-0.7316],\n",
       "         [-0.7314],\n",
       "         [-0.7313],\n",
       "         [-0.7311],\n",
       "         [-0.7309],\n",
       "         [-0.7308],\n",
       "         [-0.7306],\n",
       "         [-0.7304],\n",
       "         [-0.7303],\n",
       "         [-0.7301],\n",
       "         [-0.7300],\n",
       "         [-0.7298],\n",
       "         [-0.7296],\n",
       "         [-0.7295],\n",
       "         [-0.7293],\n",
       "         [-0.7291],\n",
       "         [-0.7290],\n",
       "         [-0.7288],\n",
       "         [-0.7286],\n",
       "         [-0.7285],\n",
       "         [-0.7283],\n",
       "         [-0.7281],\n",
       "         [-0.7280],\n",
       "         [-0.7278],\n",
       "         [-0.7277],\n",
       "         [-0.7275],\n",
       "         [-0.7273],\n",
       "         [-0.7272],\n",
       "         [-0.7270],\n",
       "         [-0.7268],\n",
       "         [-0.7267],\n",
       "         [-0.7265],\n",
       "         [-0.7263],\n",
       "         [-0.7262],\n",
       "         [-0.7260],\n",
       "         [-0.7259],\n",
       "         [-0.7257],\n",
       "         [-0.7255],\n",
       "         [-0.7254],\n",
       "         [-0.7252],\n",
       "         [-0.7250],\n",
       "         [-0.7249],\n",
       "         [-0.7247],\n",
       "         [-0.7245],\n",
       "         [-0.7244],\n",
       "         [-0.7242],\n",
       "         [-0.7241],\n",
       "         [-0.7239],\n",
       "         [-0.7237],\n",
       "         [-0.7236],\n",
       "         [-0.7234],\n",
       "         [-0.7232],\n",
       "         [-0.7231],\n",
       "         [-0.7229],\n",
       "         [-0.7228],\n",
       "         [-0.7226],\n",
       "         [-0.7224],\n",
       "         [-0.7223],\n",
       "         [-0.7221],\n",
       "         [-0.7219],\n",
       "         [-0.7218],\n",
       "         [-0.7216],\n",
       "         [-0.7214],\n",
       "         [-0.7213],\n",
       "         [-0.7211],\n",
       "         [-0.7210],\n",
       "         [-0.7208],\n",
       "         [-0.7206],\n",
       "         [-0.7205],\n",
       "         [-0.7203],\n",
       "         [-0.7201],\n",
       "         [-0.7200],\n",
       "         [-0.7198],\n",
       "         [-0.7197],\n",
       "         [-0.7195],\n",
       "         [-0.7193],\n",
       "         [-0.7192],\n",
       "         [-0.7190],\n",
       "         [-0.7188],\n",
       "         [-0.7187],\n",
       "         [-0.7185],\n",
       "         [-0.7184],\n",
       "         [-0.7182],\n",
       "         [-0.7180],\n",
       "         [-0.7179],\n",
       "         [-0.7177],\n",
       "         [-0.7175]]),\n",
       " tensor([[-0.7174],\n",
       "         [-0.7172],\n",
       "         [-0.7171],\n",
       "         [-0.7169],\n",
       "         [-0.7167],\n",
       "         [-0.7166],\n",
       "         [-0.7164],\n",
       "         [-0.7162],\n",
       "         [-0.7161],\n",
       "         [-0.7159],\n",
       "         [-0.7158],\n",
       "         [-0.7156],\n",
       "         [-0.7154],\n",
       "         [-0.7153],\n",
       "         [-0.7151],\n",
       "         [-0.7149],\n",
       "         [-0.7148],\n",
       "         [-0.7146],\n",
       "         [-0.7145],\n",
       "         [-0.7143],\n",
       "         [-0.7141],\n",
       "         [-0.7140],\n",
       "         [-0.7138],\n",
       "         [-0.7136],\n",
       "         [-0.7135],\n",
       "         [-0.7133],\n",
       "         [-0.7132],\n",
       "         [-0.7130],\n",
       "         [-0.7128],\n",
       "         [-0.7127],\n",
       "         [-0.7125],\n",
       "         [-0.7123],\n",
       "         [-0.7122],\n",
       "         [-0.7120],\n",
       "         [-0.7119],\n",
       "         [-0.7117],\n",
       "         [-0.7115],\n",
       "         [-0.7114],\n",
       "         [-0.7112],\n",
       "         [-0.7111],\n",
       "         [-0.7109],\n",
       "         [-0.7107],\n",
       "         [-0.7106],\n",
       "         [-0.7104],\n",
       "         [-0.7102],\n",
       "         [-0.7101],\n",
       "         [-0.7099],\n",
       "         [-0.7098],\n",
       "         [-0.7096],\n",
       "         [-0.7094],\n",
       "         [-0.7093],\n",
       "         [-0.7091],\n",
       "         [-0.7089],\n",
       "         [-0.7088],\n",
       "         [-0.7086],\n",
       "         [-0.7085],\n",
       "         [-0.7083],\n",
       "         [-0.7081],\n",
       "         [-0.7080],\n",
       "         [-0.7078],\n",
       "         [-0.7076],\n",
       "         [-0.7075],\n",
       "         [-0.7073],\n",
       "         [-0.7072],\n",
       "         [-0.7070],\n",
       "         [-0.7068],\n",
       "         [-0.7067],\n",
       "         [-0.7065],\n",
       "         [-0.7064],\n",
       "         [-0.7062],\n",
       "         [-0.7060],\n",
       "         [-0.7059],\n",
       "         [-0.7057],\n",
       "         [-0.7055],\n",
       "         [-0.7054],\n",
       "         [-0.7052],\n",
       "         [-0.7051],\n",
       "         [-0.7049],\n",
       "         [-0.7047],\n",
       "         [-0.7046],\n",
       "         [-0.7044],\n",
       "         [-0.7042],\n",
       "         [-0.7041],\n",
       "         [-0.7039],\n",
       "         [-0.7038],\n",
       "         [-0.7036],\n",
       "         [-0.7034],\n",
       "         [-0.7033],\n",
       "         [-0.7031],\n",
       "         [-0.7030],\n",
       "         [-0.7028],\n",
       "         [-0.7026],\n",
       "         [-0.7025],\n",
       "         [-0.7023],\n",
       "         [-0.7021],\n",
       "         [-0.7020],\n",
       "         [-0.7018],\n",
       "         [-0.7017],\n",
       "         [-0.7015],\n",
       "         [-0.7013],\n",
       "         [-0.7012],\n",
       "         [-0.7010],\n",
       "         [-0.7008],\n",
       "         [-0.7007],\n",
       "         [-0.7005],\n",
       "         [-0.7004],\n",
       "         [-0.7002],\n",
       "         [-0.7000],\n",
       "         [-0.6999],\n",
       "         [-0.6997],\n",
       "         [-0.6995],\n",
       "         [-0.6994],\n",
       "         [-0.6992],\n",
       "         [-0.6991],\n",
       "         [-0.6989],\n",
       "         [-0.6987],\n",
       "         [-0.6986],\n",
       "         [-0.6984],\n",
       "         [-0.6983],\n",
       "         [-0.6981],\n",
       "         [-0.6979],\n",
       "         [-0.6978],\n",
       "         [-0.6976],\n",
       "         [-0.6974],\n",
       "         [-0.6973],\n",
       "         [-0.6971],\n",
       "         [-0.6970],\n",
       "         [-0.6968]]),\n",
       " tensor([[-0.6966],\n",
       "         [-0.6965],\n",
       "         [-0.6963],\n",
       "         [-0.6961],\n",
       "         [-0.6960],\n",
       "         [-0.6958],\n",
       "         [-0.6957],\n",
       "         [-0.6955],\n",
       "         [-0.6953],\n",
       "         [-0.6952],\n",
       "         [-0.6950],\n",
       "         [-0.6948],\n",
       "         [-0.6947],\n",
       "         [-0.6945],\n",
       "         [-0.6944],\n",
       "         [-0.6942],\n",
       "         [-0.6940],\n",
       "         [-0.6939],\n",
       "         [-0.6937],\n",
       "         [-0.6935],\n",
       "         [-0.6934],\n",
       "         [-0.6932],\n",
       "         [-0.6931],\n",
       "         [-0.6929],\n",
       "         [-0.6927],\n",
       "         [-0.6926],\n",
       "         [-0.6924],\n",
       "         [-0.6922],\n",
       "         [-0.6921],\n",
       "         [-0.6919],\n",
       "         [-0.6918],\n",
       "         [-0.6916],\n",
       "         [-0.6914],\n",
       "         [-0.6913],\n",
       "         [-0.6911],\n",
       "         [-0.6909],\n",
       "         [-0.6908],\n",
       "         [-0.6906],\n",
       "         [-0.6905],\n",
       "         [-0.6903],\n",
       "         [-0.6901],\n",
       "         [-0.6900],\n",
       "         [-0.6898],\n",
       "         [-0.6896],\n",
       "         [-0.6895],\n",
       "         [-0.6893],\n",
       "         [-0.6892],\n",
       "         [-0.6890],\n",
       "         [-0.6888],\n",
       "         [-0.6887],\n",
       "         [-0.6885],\n",
       "         [-0.6883],\n",
       "         [-0.6882],\n",
       "         [-0.6880],\n",
       "         [-0.6878],\n",
       "         [-0.6877],\n",
       "         [-0.6875],\n",
       "         [-0.6874],\n",
       "         [-0.6872],\n",
       "         [-0.6870],\n",
       "         [-0.6869],\n",
       "         [-0.6867],\n",
       "         [-0.6865],\n",
       "         [-0.6864],\n",
       "         [-0.6862],\n",
       "         [-0.6861],\n",
       "         [-0.6859],\n",
       "         [-0.6857],\n",
       "         [-0.6856],\n",
       "         [-0.6854],\n",
       "         [-0.6852],\n",
       "         [-0.6851],\n",
       "         [-0.6849],\n",
       "         [-0.6847],\n",
       "         [-0.6846],\n",
       "         [-0.6844],\n",
       "         [-0.6843],\n",
       "         [-0.6841],\n",
       "         [-0.6839],\n",
       "         [-0.6838],\n",
       "         [-0.6836],\n",
       "         [-0.6834],\n",
       "         [-0.6833],\n",
       "         [-0.6831],\n",
       "         [-0.6829],\n",
       "         [-0.6828],\n",
       "         [-0.6826],\n",
       "         [-0.6825],\n",
       "         [-0.6823],\n",
       "         [-0.6821],\n",
       "         [-0.6820],\n",
       "         [-0.6818],\n",
       "         [-0.6816],\n",
       "         [-0.6815],\n",
       "         [-0.6813],\n",
       "         [-0.6811],\n",
       "         [-0.6810],\n",
       "         [-0.6808],\n",
       "         [-0.6807],\n",
       "         [-0.6805],\n",
       "         [-0.6803],\n",
       "         [-0.6802],\n",
       "         [-0.6800],\n",
       "         [-0.6798],\n",
       "         [-0.6797],\n",
       "         [-0.6795],\n",
       "         [-0.6793],\n",
       "         [-0.6792],\n",
       "         [-0.6790],\n",
       "         [-0.6788],\n",
       "         [-0.6787],\n",
       "         [-0.6785],\n",
       "         [-0.6784],\n",
       "         [-0.6782],\n",
       "         [-0.6780],\n",
       "         [-0.6779],\n",
       "         [-0.6777],\n",
       "         [-0.6775],\n",
       "         [-0.6774],\n",
       "         [-0.6772],\n",
       "         [-0.6770],\n",
       "         [-0.6769],\n",
       "         [-0.6767],\n",
       "         [-0.6765],\n",
       "         [-0.6764],\n",
       "         [-0.6762],\n",
       "         [-0.6761],\n",
       "         [-0.6759]]),\n",
       " tensor([[-0.6757],\n",
       "         [-0.6756],\n",
       "         [-0.6754],\n",
       "         [-0.6752],\n",
       "         [-0.6751],\n",
       "         [-0.6749],\n",
       "         [-0.6747],\n",
       "         [-0.6746],\n",
       "         [-0.6744],\n",
       "         [-0.6742],\n",
       "         [-0.6741],\n",
       "         [-0.6739],\n",
       "         [-0.6738],\n",
       "         [-0.6736],\n",
       "         [-0.6734],\n",
       "         [-0.6733],\n",
       "         [-0.6731],\n",
       "         [-0.6729],\n",
       "         [-0.6728],\n",
       "         [-0.6726],\n",
       "         [-0.6724],\n",
       "         [-0.6723],\n",
       "         [-0.6721],\n",
       "         [-0.6719],\n",
       "         [-0.6718],\n",
       "         [-0.6716],\n",
       "         [-0.6714],\n",
       "         [-0.6713],\n",
       "         [-0.6711],\n",
       "         [-0.6709],\n",
       "         [-0.6708],\n",
       "         [-0.6706],\n",
       "         [-0.6704],\n",
       "         [-0.6703],\n",
       "         [-0.6701],\n",
       "         [-0.6700],\n",
       "         [-0.6698],\n",
       "         [-0.6696],\n",
       "         [-0.6695],\n",
       "         [-0.6693],\n",
       "         [-0.6691],\n",
       "         [-0.6690],\n",
       "         [-0.6688],\n",
       "         [-0.6686],\n",
       "         [-0.6685],\n",
       "         [-0.6683],\n",
       "         [-0.6681],\n",
       "         [-0.6680],\n",
       "         [-0.6678],\n",
       "         [-0.6676],\n",
       "         [-0.6675],\n",
       "         [-0.6673],\n",
       "         [-0.6671],\n",
       "         [-0.6670],\n",
       "         [-0.6668],\n",
       "         [-0.6666],\n",
       "         [-0.6665],\n",
       "         [-0.6663],\n",
       "         [-0.6661],\n",
       "         [-0.6660],\n",
       "         [-0.6658],\n",
       "         [-0.6656],\n",
       "         [-0.6655],\n",
       "         [-0.6653],\n",
       "         [-0.6651],\n",
       "         [-0.6650],\n",
       "         [-0.6648],\n",
       "         [-0.6646],\n",
       "         [-0.6645],\n",
       "         [-0.6643],\n",
       "         [-0.6642],\n",
       "         [-0.6640],\n",
       "         [-0.6638],\n",
       "         [-0.6637],\n",
       "         [-0.6635],\n",
       "         [-0.6633],\n",
       "         [-0.6632],\n",
       "         [-0.6630],\n",
       "         [-0.6628],\n",
       "         [-0.6627],\n",
       "         [-0.6625],\n",
       "         [-0.6623],\n",
       "         [-0.6622],\n",
       "         [-0.6620],\n",
       "         [-0.6618],\n",
       "         [-0.6617],\n",
       "         [-0.6615],\n",
       "         [-0.6613],\n",
       "         [-0.6612],\n",
       "         [-0.6610],\n",
       "         [-0.6608],\n",
       "         [-0.6607],\n",
       "         [-0.6605],\n",
       "         [-0.6603],\n",
       "         [-0.6601],\n",
       "         [-0.6600],\n",
       "         [-0.6598],\n",
       "         [-0.6596],\n",
       "         [-0.6595],\n",
       "         [-0.6593],\n",
       "         [-0.6591],\n",
       "         [-0.6590],\n",
       "         [-0.6588],\n",
       "         [-0.6586],\n",
       "         [-0.6585],\n",
       "         [-0.6583],\n",
       "         [-0.6581],\n",
       "         [-0.6580],\n",
       "         [-0.6578],\n",
       "         [-0.6576],\n",
       "         [-0.6575],\n",
       "         [-0.6573],\n",
       "         [-0.6571],\n",
       "         [-0.6570],\n",
       "         [-0.6568],\n",
       "         [-0.6566],\n",
       "         [-0.6565],\n",
       "         [-0.6563],\n",
       "         [-0.6561],\n",
       "         [-0.6560],\n",
       "         [-0.6558],\n",
       "         [-0.6556],\n",
       "         [-0.6555],\n",
       "         [-0.6553],\n",
       "         [-0.6551],\n",
       "         [-0.6550],\n",
       "         [-0.6548],\n",
       "         [-0.6546]]),\n",
       " tensor([[-0.6544],\n",
       "         [-0.6543],\n",
       "         [-0.6541],\n",
       "         [-0.6539],\n",
       "         [-0.6538],\n",
       "         [-0.6536],\n",
       "         [-0.6534],\n",
       "         [-0.6533],\n",
       "         [-0.6531],\n",
       "         [-0.6529],\n",
       "         [-0.6528],\n",
       "         [-0.6526],\n",
       "         [-0.6524],\n",
       "         [-0.6523],\n",
       "         [-0.6521],\n",
       "         [-0.6519],\n",
       "         [-0.6517],\n",
       "         [-0.6516],\n",
       "         [-0.6514],\n",
       "         [-0.6512],\n",
       "         [-0.6511],\n",
       "         [-0.6509],\n",
       "         [-0.6507],\n",
       "         [-0.6506],\n",
       "         [-0.6504],\n",
       "         [-0.6502],\n",
       "         [-0.6501],\n",
       "         [-0.6499],\n",
       "         [-0.6497],\n",
       "         [-0.6495],\n",
       "         [-0.6494],\n",
       "         [-0.6492],\n",
       "         [-0.6490],\n",
       "         [-0.6489],\n",
       "         [-0.6487],\n",
       "         [-0.6485],\n",
       "         [-0.6484],\n",
       "         [-0.6482],\n",
       "         [-0.6480],\n",
       "         [-0.6479],\n",
       "         [-0.6477],\n",
       "         [-0.6475],\n",
       "         [-0.6473],\n",
       "         [-0.6472],\n",
       "         [-0.6470],\n",
       "         [-0.6468],\n",
       "         [-0.6467],\n",
       "         [-0.6465],\n",
       "         [-0.6463],\n",
       "         [-0.6461],\n",
       "         [-0.6460],\n",
       "         [-0.6458],\n",
       "         [-0.6456],\n",
       "         [-0.6455],\n",
       "         [-0.6453],\n",
       "         [-0.6451],\n",
       "         [-0.6450],\n",
       "         [-0.6448],\n",
       "         [-0.6446],\n",
       "         [-0.6444],\n",
       "         [-0.6443],\n",
       "         [-0.6441],\n",
       "         [-0.6439],\n",
       "         [-0.6438],\n",
       "         [-0.6436],\n",
       "         [-0.6434],\n",
       "         [-0.6432],\n",
       "         [-0.6431],\n",
       "         [-0.6429],\n",
       "         [-0.6427],\n",
       "         [-0.6426],\n",
       "         [-0.6424],\n",
       "         [-0.6422],\n",
       "         [-0.6420],\n",
       "         [-0.6419],\n",
       "         [-0.6417],\n",
       "         [-0.6415],\n",
       "         [-0.6414],\n",
       "         [-0.6412],\n",
       "         [-0.6410],\n",
       "         [-0.6408],\n",
       "         [-0.6407],\n",
       "         [-0.6405],\n",
       "         [-0.6403],\n",
       "         [-0.6402],\n",
       "         [-0.6400],\n",
       "         [-0.6398],\n",
       "         [-0.6396],\n",
       "         [-0.6395],\n",
       "         [-0.6393],\n",
       "         [-0.6391],\n",
       "         [-0.6390],\n",
       "         [-0.6388],\n",
       "         [-0.6386],\n",
       "         [-0.6384],\n",
       "         [-0.6383],\n",
       "         [-0.6381],\n",
       "         [-0.6379],\n",
       "         [-0.6378],\n",
       "         [-0.6376],\n",
       "         [-0.6374],\n",
       "         [-0.6372],\n",
       "         [-0.6371],\n",
       "         [-0.6369],\n",
       "         [-0.6367],\n",
       "         [-0.6365],\n",
       "         [-0.6364],\n",
       "         [-0.6362],\n",
       "         [-0.6360],\n",
       "         [-0.6359],\n",
       "         [-0.6357],\n",
       "         [-0.6355],\n",
       "         [-0.6353],\n",
       "         [-0.6352],\n",
       "         [-0.6350],\n",
       "         [-0.6348],\n",
       "         [-0.6346],\n",
       "         [-0.6345],\n",
       "         [-0.6343],\n",
       "         [-0.6341],\n",
       "         [-0.6339],\n",
       "         [-0.6338],\n",
       "         [-0.6336],\n",
       "         [-0.6334],\n",
       "         [-0.6333],\n",
       "         [-0.6331],\n",
       "         [-0.6329],\n",
       "         [-0.6327]]),\n",
       " tensor([[-0.6326],\n",
       "         [-0.6324],\n",
       "         [-0.6322],\n",
       "         [-0.6320],\n",
       "         [-0.6319],\n",
       "         [-0.6317],\n",
       "         [-0.6315],\n",
       "         [-0.6313],\n",
       "         [-0.6312],\n",
       "         [-0.6310],\n",
       "         [-0.6308],\n",
       "         [-0.6306],\n",
       "         [-0.6305],\n",
       "         [-0.6303],\n",
       "         [-0.6301],\n",
       "         [-0.6299],\n",
       "         [-0.6298],\n",
       "         [-0.6296],\n",
       "         [-0.6294],\n",
       "         [-0.6292],\n",
       "         [-0.6291],\n",
       "         [-0.6289],\n",
       "         [-0.6287],\n",
       "         [-0.6285],\n",
       "         [-0.6284],\n",
       "         [-0.6282],\n",
       "         [-0.6280],\n",
       "         [-0.6279],\n",
       "         [-0.6277],\n",
       "         [-0.6275],\n",
       "         [-0.6273],\n",
       "         [-0.6272],\n",
       "         [-0.6270],\n",
       "         [-0.6268],\n",
       "         [-0.6266],\n",
       "         [-0.6264],\n",
       "         [-0.6263],\n",
       "         [-0.6261],\n",
       "         [-0.6259],\n",
       "         [-0.6257],\n",
       "         [-0.6256],\n",
       "         [-0.6254],\n",
       "         [-0.6252],\n",
       "         [-0.6250],\n",
       "         [-0.6249],\n",
       "         [-0.6247],\n",
       "         [-0.6245],\n",
       "         [-0.6243],\n",
       "         [-0.6242],\n",
       "         [-0.6240],\n",
       "         [-0.6238],\n",
       "         [-0.6236],\n",
       "         [-0.6235],\n",
       "         [-0.6233],\n",
       "         [-0.6231],\n",
       "         [-0.6229],\n",
       "         [-0.6228],\n",
       "         [-0.6226],\n",
       "         [-0.6224],\n",
       "         [-0.6222],\n",
       "         [-0.6221],\n",
       "         [-0.6219],\n",
       "         [-0.6217],\n",
       "         [-0.6215],\n",
       "         [-0.6214],\n",
       "         [-0.6212],\n",
       "         [-0.6210],\n",
       "         [-0.6208],\n",
       "         [-0.6206],\n",
       "         [-0.6205],\n",
       "         [-0.6203],\n",
       "         [-0.6201],\n",
       "         [-0.6199],\n",
       "         [-0.6198],\n",
       "         [-0.6196],\n",
       "         [-0.6194],\n",
       "         [-0.6192],\n",
       "         [-0.6191],\n",
       "         [-0.6189],\n",
       "         [-0.6187],\n",
       "         [-0.6185],\n",
       "         [-0.6183],\n",
       "         [-0.6182],\n",
       "         [-0.6180],\n",
       "         [-0.6178],\n",
       "         [-0.6176],\n",
       "         [-0.6175],\n",
       "         [-0.6173],\n",
       "         [-0.6171],\n",
       "         [-0.6169],\n",
       "         [-0.6168],\n",
       "         [-0.6166],\n",
       "         [-0.6164],\n",
       "         [-0.6162],\n",
       "         [-0.6160],\n",
       "         [-0.6159],\n",
       "         [-0.6157],\n",
       "         [-0.6155],\n",
       "         [-0.6153],\n",
       "         [-0.6152],\n",
       "         [-0.6150],\n",
       "         [-0.6148],\n",
       "         [-0.6146],\n",
       "         [-0.6144],\n",
       "         [-0.6143],\n",
       "         [-0.6141],\n",
       "         [-0.6139],\n",
       "         [-0.6137],\n",
       "         [-0.6136],\n",
       "         [-0.6134],\n",
       "         [-0.6132],\n",
       "         [-0.6130],\n",
       "         [-0.6128],\n",
       "         [-0.6127],\n",
       "         [-0.6125],\n",
       "         [-0.6123],\n",
       "         [-0.6121],\n",
       "         [-0.6120],\n",
       "         [-0.6118],\n",
       "         [-0.6116],\n",
       "         [-0.6114],\n",
       "         [-0.6112],\n",
       "         [-0.6111],\n",
       "         [-0.6109],\n",
       "         [-0.6107],\n",
       "         [-0.6105],\n",
       "         [-0.6104],\n",
       "         [-0.6102]]),\n",
       " tensor([[-0.6100],\n",
       "         [-0.6098],\n",
       "         [-0.6096],\n",
       "         [-0.6095],\n",
       "         [-0.6093],\n",
       "         [-0.6091],\n",
       "         [-0.6089],\n",
       "         [-0.6087],\n",
       "         [-0.6086],\n",
       "         [-0.6084],\n",
       "         [-0.6082],\n",
       "         [-0.6080],\n",
       "         [-0.6078],\n",
       "         [-0.6077],\n",
       "         [-0.6075],\n",
       "         [-0.6073],\n",
       "         [-0.6071],\n",
       "         [-0.6070],\n",
       "         [-0.6068],\n",
       "         [-0.6066],\n",
       "         [-0.6064],\n",
       "         [-0.6062],\n",
       "         [-0.6061],\n",
       "         [-0.6059],\n",
       "         [-0.6057],\n",
       "         [-0.6055],\n",
       "         [-0.6053],\n",
       "         [-0.6052],\n",
       "         [-0.6050],\n",
       "         [-0.6048],\n",
       "         [-0.6046],\n",
       "         [-0.6044],\n",
       "         [-0.6043],\n",
       "         [-0.6041],\n",
       "         [-0.6039],\n",
       "         [-0.6037],\n",
       "         [-0.6035],\n",
       "         [-0.6034],\n",
       "         [-0.6032],\n",
       "         [-0.6030],\n",
       "         [-0.6028],\n",
       "         [-0.6026],\n",
       "         [-0.6025],\n",
       "         [-0.6023],\n",
       "         [-0.6021],\n",
       "         [-0.6019],\n",
       "         [-0.6017],\n",
       "         [-0.6016],\n",
       "         [-0.6014],\n",
       "         [-0.6012],\n",
       "         [-0.6010],\n",
       "         [-0.6008],\n",
       "         [-0.6007],\n",
       "         [-0.6005],\n",
       "         [-0.6003],\n",
       "         [-0.6001],\n",
       "         [-0.5999],\n",
       "         [-0.5997],\n",
       "         [-0.5996],\n",
       "         [-0.5994],\n",
       "         [-0.5992],\n",
       "         [-0.5990],\n",
       "         [-0.5988],\n",
       "         [-0.5987],\n",
       "         [-0.5985],\n",
       "         [-0.5983],\n",
       "         [-0.5981],\n",
       "         [-0.5979],\n",
       "         [-0.5978],\n",
       "         [-0.5976],\n",
       "         [-0.5974],\n",
       "         [-0.5972],\n",
       "         [-0.5970],\n",
       "         [-0.5968],\n",
       "         [-0.5967],\n",
       "         [-0.5965],\n",
       "         [-0.5963],\n",
       "         [-0.5961],\n",
       "         [-0.5959],\n",
       "         [-0.5958],\n",
       "         [-0.5956],\n",
       "         [-0.5954],\n",
       "         [-0.5952],\n",
       "         [-0.5950],\n",
       "         [-0.5948],\n",
       "         [-0.5947],\n",
       "         [-0.5945],\n",
       "         [-0.5943],\n",
       "         [-0.5941],\n",
       "         [-0.5939],\n",
       "         [-0.5938],\n",
       "         [-0.5936],\n",
       "         [-0.5934],\n",
       "         [-0.5932],\n",
       "         [-0.5930],\n",
       "         [-0.5928],\n",
       "         [-0.5927],\n",
       "         [-0.5925],\n",
       "         [-0.5923],\n",
       "         [-0.5921],\n",
       "         [-0.5919],\n",
       "         [-0.5917],\n",
       "         [-0.5916],\n",
       "         [-0.5914],\n",
       "         [-0.5912],\n",
       "         [-0.5910],\n",
       "         [-0.5908],\n",
       "         [-0.5907],\n",
       "         [-0.5905],\n",
       "         [-0.5903],\n",
       "         [-0.5901],\n",
       "         [-0.5899],\n",
       "         [-0.5897],\n",
       "         [-0.5896],\n",
       "         [-0.5894],\n",
       "         [-0.5892],\n",
       "         [-0.5890],\n",
       "         [-0.5888],\n",
       "         [-0.5886],\n",
       "         [-0.5885],\n",
       "         [-0.5883],\n",
       "         [-0.5881],\n",
       "         [-0.5879],\n",
       "         [-0.5877],\n",
       "         [-0.5875],\n",
       "         [-0.5874],\n",
       "         [-0.5872],\n",
       "         [-0.5870]]),\n",
       " tensor([[-0.5868],\n",
       "         [-0.5866],\n",
       "         [-0.5864],\n",
       "         [-0.5863],\n",
       "         [-0.5861],\n",
       "         [-0.5859],\n",
       "         [-0.5857],\n",
       "         [-0.5855],\n",
       "         [-0.5853],\n",
       "         [-0.5851],\n",
       "         [-0.5850],\n",
       "         [-0.5848],\n",
       "         [-0.5846],\n",
       "         [-0.5844],\n",
       "         [-0.5842],\n",
       "         [-0.5840],\n",
       "         [-0.5839],\n",
       "         [-0.5837],\n",
       "         [-0.5835],\n",
       "         [-0.5833],\n",
       "         [-0.5831],\n",
       "         [-0.5829],\n",
       "         [-0.5828],\n",
       "         [-0.5826],\n",
       "         [-0.5824],\n",
       "         [-0.5822],\n",
       "         [-0.5820],\n",
       "         [-0.5818],\n",
       "         [-0.5816],\n",
       "         [-0.5815],\n",
       "         [-0.5813],\n",
       "         [-0.5811],\n",
       "         [-0.5809],\n",
       "         [-0.5807],\n",
       "         [-0.5805],\n",
       "         [-0.5803],\n",
       "         [-0.5802],\n",
       "         [-0.5800],\n",
       "         [-0.5798],\n",
       "         [-0.5796],\n",
       "         [-0.5794],\n",
       "         [-0.5792],\n",
       "         [-0.5791],\n",
       "         [-0.5789],\n",
       "         [-0.5787],\n",
       "         [-0.5785],\n",
       "         [-0.5783],\n",
       "         [-0.5781],\n",
       "         [-0.5779],\n",
       "         [-0.5778],\n",
       "         [-0.5776],\n",
       "         [-0.5774],\n",
       "         [-0.5772],\n",
       "         [-0.5770],\n",
       "         [-0.5768],\n",
       "         [-0.5766],\n",
       "         [-0.5765],\n",
       "         [-0.5763],\n",
       "         [-0.5761],\n",
       "         [-0.5759],\n",
       "         [-0.5757],\n",
       "         [-0.5755],\n",
       "         [-0.5753],\n",
       "         [-0.5752],\n",
       "         [-0.5750],\n",
       "         [-0.5748],\n",
       "         [-0.5746],\n",
       "         [-0.5744],\n",
       "         [-0.5742],\n",
       "         [-0.5740],\n",
       "         [-0.5739],\n",
       "         [-0.5737],\n",
       "         [-0.5735],\n",
       "         [-0.5733],\n",
       "         [-0.5731],\n",
       "         [-0.5729],\n",
       "         [-0.5727],\n",
       "         [-0.5725],\n",
       "         [-0.5724],\n",
       "         [-0.5722],\n",
       "         [-0.5720],\n",
       "         [-0.5718],\n",
       "         [-0.5716],\n",
       "         [-0.5714],\n",
       "         [-0.5712],\n",
       "         [-0.5711],\n",
       "         [-0.5709],\n",
       "         [-0.5707],\n",
       "         [-0.5705],\n",
       "         [-0.5703],\n",
       "         [-0.5701],\n",
       "         [-0.5699],\n",
       "         [-0.5697],\n",
       "         [-0.5696],\n",
       "         [-0.5694],\n",
       "         [-0.5692],\n",
       "         [-0.5690],\n",
       "         [-0.5688],\n",
       "         [-0.5686],\n",
       "         [-0.5684],\n",
       "         [-0.5683],\n",
       "         [-0.5681],\n",
       "         [-0.5679],\n",
       "         [-0.5677],\n",
       "         [-0.5675],\n",
       "         [-0.5673],\n",
       "         [-0.5671],\n",
       "         [-0.5669],\n",
       "         [-0.5668],\n",
       "         [-0.5666],\n",
       "         [-0.5664],\n",
       "         [-0.5662],\n",
       "         [-0.5660],\n",
       "         [-0.5658],\n",
       "         [-0.5656],\n",
       "         [-0.5654],\n",
       "         [-0.5653],\n",
       "         [-0.5651],\n",
       "         [-0.5649],\n",
       "         [-0.5647],\n",
       "         [-0.5645],\n",
       "         [-0.5643],\n",
       "         [-0.5641],\n",
       "         [-0.5639],\n",
       "         [-0.5638],\n",
       "         [-0.5636],\n",
       "         [-0.5634],\n",
       "         [-0.5632]]),\n",
       " tensor([[-0.5630],\n",
       "         [-0.5628],\n",
       "         [-0.5626],\n",
       "         [-0.5624],\n",
       "         [-0.5623],\n",
       "         [-0.5621],\n",
       "         [-0.5619],\n",
       "         [-0.5617],\n",
       "         [-0.5615],\n",
       "         [-0.5613],\n",
       "         [-0.5611],\n",
       "         [-0.5609],\n",
       "         [-0.5608],\n",
       "         [-0.5606],\n",
       "         [-0.5604],\n",
       "         [-0.5602],\n",
       "         [-0.5600],\n",
       "         [-0.5598],\n",
       "         [-0.5596],\n",
       "         [-0.5594],\n",
       "         [-0.5593],\n",
       "         [-0.5591],\n",
       "         [-0.5589],\n",
       "         [-0.5587],\n",
       "         [-0.5585],\n",
       "         [-0.5583],\n",
       "         [-0.5581],\n",
       "         [-0.5579],\n",
       "         [-0.5577],\n",
       "         [-0.5576],\n",
       "         [-0.5574],\n",
       "         [-0.5572],\n",
       "         [-0.5570],\n",
       "         [-0.5568],\n",
       "         [-0.5566],\n",
       "         [-0.5564],\n",
       "         [-0.5562],\n",
       "         [-0.5561],\n",
       "         [-0.5559],\n",
       "         [-0.5557],\n",
       "         [-0.5555],\n",
       "         [-0.5553],\n",
       "         [-0.5551],\n",
       "         [-0.5549],\n",
       "         [-0.5547],\n",
       "         [-0.5545],\n",
       "         [-0.5544],\n",
       "         [-0.5542],\n",
       "         [-0.5540],\n",
       "         [-0.5538],\n",
       "         [-0.5536],\n",
       "         [-0.5534],\n",
       "         [-0.5532],\n",
       "         [-0.5530],\n",
       "         [-0.5529],\n",
       "         [-0.5527],\n",
       "         [-0.5525],\n",
       "         [-0.5523],\n",
       "         [-0.5521],\n",
       "         [-0.5519],\n",
       "         [-0.5517],\n",
       "         [-0.5515],\n",
       "         [-0.5513],\n",
       "         [-0.5512],\n",
       "         [-0.5510],\n",
       "         [-0.5508],\n",
       "         [-0.5506],\n",
       "         [-0.5504],\n",
       "         [-0.5502],\n",
       "         [-0.5500],\n",
       "         [-0.5498],\n",
       "         [-0.5496],\n",
       "         [-0.5495],\n",
       "         [-0.5493],\n",
       "         [-0.5491],\n",
       "         [-0.5489],\n",
       "         [-0.5487],\n",
       "         [-0.5485],\n",
       "         [-0.5483],\n",
       "         [-0.5481],\n",
       "         [-0.5479],\n",
       "         [-0.5478],\n",
       "         [-0.5476],\n",
       "         [-0.5474],\n",
       "         [-0.5472],\n",
       "         [-0.5470],\n",
       "         [-0.5468],\n",
       "         [-0.5466],\n",
       "         [-0.5464],\n",
       "         [-0.5462],\n",
       "         [-0.5461],\n",
       "         [-0.5459],\n",
       "         [-0.5457],\n",
       "         [-0.5455],\n",
       "         [-0.5453],\n",
       "         [-0.5451],\n",
       "         [-0.5449],\n",
       "         [-0.5447],\n",
       "         [-0.5445],\n",
       "         [-0.5444],\n",
       "         [-0.5442],\n",
       "         [-0.5440],\n",
       "         [-0.5438],\n",
       "         [-0.5436],\n",
       "         [-0.5434],\n",
       "         [-0.5432],\n",
       "         [-0.5430],\n",
       "         [-0.5428],\n",
       "         [-0.5426],\n",
       "         [-0.5425],\n",
       "         [-0.5423],\n",
       "         [-0.5421],\n",
       "         [-0.5419],\n",
       "         [-0.5417],\n",
       "         [-0.5415],\n",
       "         [-0.5413],\n",
       "         [-0.5411],\n",
       "         [-0.5409],\n",
       "         [-0.5408],\n",
       "         [-0.5406],\n",
       "         [-0.5404],\n",
       "         [-0.5402],\n",
       "         [-0.5400],\n",
       "         [-0.5398],\n",
       "         [-0.5396],\n",
       "         [-0.5394],\n",
       "         [-0.5392],\n",
       "         [-0.5391]]),\n",
       " tensor([[-0.5389],\n",
       "         [-0.5387],\n",
       "         [-0.5385],\n",
       "         [-0.5383],\n",
       "         [-0.5381],\n",
       "         [-0.5379],\n",
       "         [-0.5377],\n",
       "         [-0.5375],\n",
       "         [-0.5373],\n",
       "         [-0.5372],\n",
       "         [-0.5370],\n",
       "         [-0.5368],\n",
       "         [-0.5366],\n",
       "         [-0.5364],\n",
       "         [-0.5362],\n",
       "         [-0.5360],\n",
       "         [-0.5358],\n",
       "         [-0.5356],\n",
       "         [-0.5354],\n",
       "         [-0.5353],\n",
       "         [-0.5351],\n",
       "         [-0.5349],\n",
       "         [-0.5347],\n",
       "         [-0.5345],\n",
       "         [-0.5343],\n",
       "         [-0.5341],\n",
       "         [-0.5339],\n",
       "         [-0.5337],\n",
       "         [-0.5335],\n",
       "         [-0.5334],\n",
       "         [-0.5332],\n",
       "         [-0.5330],\n",
       "         [-0.5328],\n",
       "         [-0.5326],\n",
       "         [-0.5324],\n",
       "         [-0.5322],\n",
       "         [-0.5320],\n",
       "         [-0.5318],\n",
       "         [-0.5316],\n",
       "         [-0.5315],\n",
       "         [-0.5313],\n",
       "         [-0.5311],\n",
       "         [-0.5309],\n",
       "         [-0.5307],\n",
       "         [-0.5305],\n",
       "         [-0.5303],\n",
       "         [-0.5301],\n",
       "         [-0.5299],\n",
       "         [-0.5297],\n",
       "         [-0.5296],\n",
       "         [-0.5294],\n",
       "         [-0.5292],\n",
       "         [-0.5290],\n",
       "         [-0.5288],\n",
       "         [-0.5286],\n",
       "         [-0.5284],\n",
       "         [-0.5282],\n",
       "         [-0.5280],\n",
       "         [-0.5278],\n",
       "         [-0.5277],\n",
       "         [-0.5275],\n",
       "         [-0.5273],\n",
       "         [-0.5271],\n",
       "         [-0.5269],\n",
       "         [-0.5267],\n",
       "         [-0.5265],\n",
       "         [-0.5263],\n",
       "         [-0.5261],\n",
       "         [-0.5259],\n",
       "         [-0.5257],\n",
       "         [-0.5256],\n",
       "         [-0.5254],\n",
       "         [-0.5252],\n",
       "         [-0.5250],\n",
       "         [-0.5248],\n",
       "         [-0.5246],\n",
       "         [-0.5244],\n",
       "         [-0.5242],\n",
       "         [-0.5240],\n",
       "         [-0.5238],\n",
       "         [-0.5237],\n",
       "         [-0.5235],\n",
       "         [-0.5233],\n",
       "         [-0.5231],\n",
       "         [-0.5229],\n",
       "         [-0.5227],\n",
       "         [-0.5225],\n",
       "         [-0.5223],\n",
       "         [-0.5221],\n",
       "         [-0.5219],\n",
       "         [-0.5217],\n",
       "         [-0.5216],\n",
       "         [-0.5214],\n",
       "         [-0.5212],\n",
       "         [-0.5210],\n",
       "         [-0.5208],\n",
       "         [-0.5206],\n",
       "         [-0.5204],\n",
       "         [-0.5202],\n",
       "         [-0.5200],\n",
       "         [-0.5198],\n",
       "         [-0.5196],\n",
       "         [-0.5195],\n",
       "         [-0.5193],\n",
       "         [-0.5191],\n",
       "         [-0.5189],\n",
       "         [-0.5187],\n",
       "         [-0.5185],\n",
       "         [-0.5183],\n",
       "         [-0.5181],\n",
       "         [-0.5179],\n",
       "         [-0.5177],\n",
       "         [-0.5175],\n",
       "         [-0.5173],\n",
       "         [-0.5172],\n",
       "         [-0.5170],\n",
       "         [-0.5168],\n",
       "         [-0.5166],\n",
       "         [-0.5164],\n",
       "         [-0.5162],\n",
       "         [-0.5160],\n",
       "         [-0.5158],\n",
       "         [-0.5156],\n",
       "         [-0.5154],\n",
       "         [-0.5152],\n",
       "         [-0.5150],\n",
       "         [-0.5149],\n",
       "         [-0.5147]]),\n",
       " tensor([[-0.5145],\n",
       "         [-0.5143],\n",
       "         [-0.5141],\n",
       "         [-0.5139],\n",
       "         [-0.5137],\n",
       "         [-0.5135],\n",
       "         [-0.5133],\n",
       "         [-0.5131],\n",
       "         [-0.5129],\n",
       "         [-0.5127],\n",
       "         [-0.5126],\n",
       "         [-0.5124],\n",
       "         [-0.5122],\n",
       "         [-0.5120],\n",
       "         [-0.5118],\n",
       "         [-0.5116],\n",
       "         [-0.5114],\n",
       "         [-0.5112],\n",
       "         [-0.5110],\n",
       "         [-0.5108],\n",
       "         [-0.5106],\n",
       "         [-0.5104],\n",
       "         [-0.5103],\n",
       "         [-0.5101],\n",
       "         [-0.5099],\n",
       "         [-0.5097],\n",
       "         [-0.5095],\n",
       "         [-0.5093],\n",
       "         [-0.5091],\n",
       "         [-0.5089],\n",
       "         [-0.5087],\n",
       "         [-0.5085],\n",
       "         [-0.5083],\n",
       "         [-0.5081],\n",
       "         [-0.5079],\n",
       "         [-0.5078],\n",
       "         [-0.5076],\n",
       "         [-0.5074],\n",
       "         [-0.5072],\n",
       "         [-0.5070],\n",
       "         [-0.5068],\n",
       "         [-0.5066],\n",
       "         [-0.5064],\n",
       "         [-0.5062],\n",
       "         [-0.5060],\n",
       "         [-0.5058],\n",
       "         [-0.5056],\n",
       "         [-0.5054],\n",
       "         [-0.5052],\n",
       "         [-0.5051],\n",
       "         [-0.5049],\n",
       "         [-0.5047],\n",
       "         [-0.5045],\n",
       "         [-0.5043],\n",
       "         [-0.5041],\n",
       "         [-0.5039],\n",
       "         [-0.5037],\n",
       "         [-0.5035],\n",
       "         [-0.5033],\n",
       "         [-0.5031],\n",
       "         [-0.5029],\n",
       "         [-0.5027],\n",
       "         [-0.5025],\n",
       "         [-0.5024],\n",
       "         [-0.5022],\n",
       "         [-0.5020],\n",
       "         [-0.5018],\n",
       "         [-0.5016],\n",
       "         [-0.5014],\n",
       "         [-0.5012],\n",
       "         [-0.5010],\n",
       "         [-0.5008],\n",
       "         [-0.5006],\n",
       "         [-0.5004],\n",
       "         [-0.5002],\n",
       "         [-0.5000],\n",
       "         [-0.4998],\n",
       "         [-0.4997],\n",
       "         [-0.4995],\n",
       "         [-0.4993],\n",
       "         [-0.4991],\n",
       "         [-0.4989],\n",
       "         [-0.4987],\n",
       "         [-0.4985],\n",
       "         [-0.4983],\n",
       "         [-0.4981],\n",
       "         [-0.4979],\n",
       "         [-0.4977],\n",
       "         [-0.4975],\n",
       "         [-0.4973],\n",
       "         [-0.4971],\n",
       "         [-0.4969],\n",
       "         [-0.4968],\n",
       "         [-0.4966],\n",
       "         [-0.4964],\n",
       "         [-0.4962],\n",
       "         [-0.4960],\n",
       "         [-0.4958],\n",
       "         [-0.4956],\n",
       "         [-0.4954],\n",
       "         [-0.4952],\n",
       "         [-0.4950],\n",
       "         [-0.4948],\n",
       "         [-0.4946],\n",
       "         [-0.4944],\n",
       "         [-0.4942],\n",
       "         [-0.4940],\n",
       "         [-0.4938],\n",
       "         [-0.4937],\n",
       "         [-0.4935],\n",
       "         [-0.4933],\n",
       "         [-0.4931],\n",
       "         [-0.4929],\n",
       "         [-0.4927],\n",
       "         [-0.4925],\n",
       "         [-0.4923],\n",
       "         [-0.4921],\n",
       "         [-0.4919],\n",
       "         [-0.4917],\n",
       "         [-0.4915],\n",
       "         [-0.4913],\n",
       "         [-0.4911],\n",
       "         [-0.4909],\n",
       "         [-0.4907],\n",
       "         [-0.4905],\n",
       "         [-0.4904],\n",
       "         [-0.4902],\n",
       "         [-0.4900]]),\n",
       " tensor([[-0.4898],\n",
       "         [-0.4896],\n",
       "         [-0.4894],\n",
       "         [-0.4892],\n",
       "         [-0.4890],\n",
       "         [-0.4888],\n",
       "         [-0.4886],\n",
       "         [-0.4884],\n",
       "         [-0.4882],\n",
       "         [-0.4880],\n",
       "         [-0.4878],\n",
       "         [-0.4876],\n",
       "         [-0.4874],\n",
       "         [-0.4872],\n",
       "         [-0.4870],\n",
       "         [-0.4869],\n",
       "         [-0.4867],\n",
       "         [-0.4865],\n",
       "         [-0.4863],\n",
       "         [-0.4861],\n",
       "         [-0.4859],\n",
       "         [-0.4857],\n",
       "         [-0.4855],\n",
       "         [-0.4853],\n",
       "         [-0.4851],\n",
       "         [-0.4849],\n",
       "         [-0.4847],\n",
       "         [-0.4845],\n",
       "         [-0.4843],\n",
       "         [-0.4841],\n",
       "         [-0.4839],\n",
       "         [-0.4837],\n",
       "         [-0.4835],\n",
       "         [-0.4833],\n",
       "         [-0.4832],\n",
       "         [-0.4830],\n",
       "         [-0.4828],\n",
       "         [-0.4826],\n",
       "         [-0.4824],\n",
       "         [-0.4822],\n",
       "         [-0.4820],\n",
       "         [-0.4818],\n",
       "         [-0.4816],\n",
       "         [-0.4814],\n",
       "         [-0.4812],\n",
       "         [-0.4810],\n",
       "         [-0.4808],\n",
       "         [-0.4806],\n",
       "         [-0.4804],\n",
       "         [-0.4802],\n",
       "         [-0.4800],\n",
       "         [-0.4798],\n",
       "         [-0.4796],\n",
       "         [-0.4794],\n",
       "         [-0.4792],\n",
       "         [-0.4791],\n",
       "         [-0.4789],\n",
       "         [-0.4787],\n",
       "         [-0.4785],\n",
       "         [-0.4783],\n",
       "         [-0.4781],\n",
       "         [-0.4779],\n",
       "         [-0.4777],\n",
       "         [-0.4775],\n",
       "         [-0.4773],\n",
       "         [-0.4771],\n",
       "         [-0.4769],\n",
       "         [-0.4767],\n",
       "         [-0.4765],\n",
       "         [-0.4763],\n",
       "         [-0.4761],\n",
       "         [-0.4759],\n",
       "         [-0.4757],\n",
       "         [-0.4755],\n",
       "         [-0.4753],\n",
       "         [-0.4751],\n",
       "         [-0.4749],\n",
       "         [-0.4747],\n",
       "         [-0.4745],\n",
       "         [-0.4743],\n",
       "         [-0.4742],\n",
       "         [-0.4740],\n",
       "         [-0.4738],\n",
       "         [-0.4736],\n",
       "         [-0.4734],\n",
       "         [-0.4732],\n",
       "         [-0.4730],\n",
       "         [-0.4728],\n",
       "         [-0.4726],\n",
       "         [-0.4724],\n",
       "         [-0.4722],\n",
       "         [-0.4720],\n",
       "         [-0.4718],\n",
       "         [-0.4716],\n",
       "         [-0.4714],\n",
       "         [-0.4712],\n",
       "         [-0.4710],\n",
       "         [-0.4708],\n",
       "         [-0.4706],\n",
       "         [-0.4704],\n",
       "         [-0.4702],\n",
       "         [-0.4700],\n",
       "         [-0.4698],\n",
       "         [-0.4696],\n",
       "         [-0.4694],\n",
       "         [-0.4692],\n",
       "         [-0.4690],\n",
       "         [-0.4688],\n",
       "         [-0.4686],\n",
       "         [-0.4684],\n",
       "         [-0.4683],\n",
       "         [-0.4681],\n",
       "         [-0.4679],\n",
       "         [-0.4677],\n",
       "         [-0.4675],\n",
       "         [-0.4673],\n",
       "         [-0.4671],\n",
       "         [-0.4669],\n",
       "         [-0.4667],\n",
       "         [-0.4665],\n",
       "         [-0.4663],\n",
       "         [-0.4661],\n",
       "         [-0.4659],\n",
       "         [-0.4657],\n",
       "         [-0.4655],\n",
       "         [-0.4653],\n",
       "         [-0.4651],\n",
       "         [-0.4649]]),\n",
       " tensor([[-0.4647],\n",
       "         [-0.4645],\n",
       "         [-0.4643],\n",
       "         [-0.4641],\n",
       "         [-0.4639],\n",
       "         [-0.4637],\n",
       "         [-0.4635],\n",
       "         [-0.4633],\n",
       "         [-0.4631],\n",
       "         [-0.4629],\n",
       "         [-0.4627],\n",
       "         [-0.4625],\n",
       "         [-0.4623],\n",
       "         [-0.4621],\n",
       "         [-0.4619],\n",
       "         [-0.4617],\n",
       "         [-0.4615],\n",
       "         [-0.4613],\n",
       "         [-0.4611],\n",
       "         [-0.4609],\n",
       "         [-0.4607],\n",
       "         [-0.4605],\n",
       "         [-0.4603],\n",
       "         [-0.4601],\n",
       "         [-0.4599],\n",
       "         [-0.4597],\n",
       "         [-0.4595],\n",
       "         [-0.4593],\n",
       "         [-0.4591],\n",
       "         [-0.4590],\n",
       "         [-0.4588],\n",
       "         [-0.4586],\n",
       "         [-0.4584],\n",
       "         [-0.4582],\n",
       "         [-0.4580],\n",
       "         [-0.4578],\n",
       "         [-0.4576],\n",
       "         [-0.4574],\n",
       "         [-0.4572],\n",
       "         [-0.4570],\n",
       "         [-0.4568],\n",
       "         [-0.4566],\n",
       "         [-0.4564],\n",
       "         [-0.4562],\n",
       "         [-0.4560],\n",
       "         [-0.4558],\n",
       "         [-0.4556],\n",
       "         [-0.4554],\n",
       "         [-0.4552],\n",
       "         [-0.4550],\n",
       "         [-0.4548],\n",
       "         [-0.4546],\n",
       "         [-0.4544],\n",
       "         [-0.4542],\n",
       "         [-0.4540],\n",
       "         [-0.4538],\n",
       "         [-0.4536],\n",
       "         [-0.4534],\n",
       "         [-0.4532],\n",
       "         [-0.4530],\n",
       "         [-0.4528],\n",
       "         [-0.4526],\n",
       "         [-0.4524],\n",
       "         [-0.4522],\n",
       "         [-0.4520],\n",
       "         [-0.4518],\n",
       "         [-0.4516],\n",
       "         [-0.4514],\n",
       "         [-0.4512],\n",
       "         [-0.4510],\n",
       "         [-0.4508],\n",
       "         [-0.4506],\n",
       "         [-0.4504],\n",
       "         [-0.4502],\n",
       "         [-0.4500],\n",
       "         [-0.4498],\n",
       "         [-0.4496],\n",
       "         [-0.4494],\n",
       "         [-0.4492],\n",
       "         [-0.4490],\n",
       "         [-0.4488],\n",
       "         [-0.4486],\n",
       "         [-0.4484],\n",
       "         [-0.4482],\n",
       "         [-0.4480],\n",
       "         [-0.4478],\n",
       "         [-0.4476],\n",
       "         [-0.4474],\n",
       "         [-0.4472],\n",
       "         [-0.4470],\n",
       "         [-0.4468],\n",
       "         [-0.4466],\n",
       "         [-0.4464],\n",
       "         [-0.4462],\n",
       "         [-0.4460],\n",
       "         [-0.4458],\n",
       "         [-0.4456],\n",
       "         [-0.4454],\n",
       "         [-0.4451],\n",
       "         [-0.4449],\n",
       "         [-0.4447],\n",
       "         [-0.4445],\n",
       "         [-0.4443],\n",
       "         [-0.4441],\n",
       "         [-0.4439],\n",
       "         [-0.4437],\n",
       "         [-0.4435],\n",
       "         [-0.4433],\n",
       "         [-0.4431],\n",
       "         [-0.4429],\n",
       "         [-0.4427],\n",
       "         [-0.4425],\n",
       "         [-0.4423],\n",
       "         [-0.4421],\n",
       "         [-0.4419],\n",
       "         [-0.4417],\n",
       "         [-0.4415],\n",
       "         [-0.4413],\n",
       "         [-0.4411],\n",
       "         [-0.4409],\n",
       "         [-0.4407],\n",
       "         [-0.4405],\n",
       "         [-0.4403],\n",
       "         [-0.4401],\n",
       "         [-0.4399],\n",
       "         [-0.4397],\n",
       "         [-0.4395],\n",
       "         [-0.4393]]),\n",
       " tensor([[-0.4391],\n",
       "         [-0.4389],\n",
       "         [-0.4387],\n",
       "         [-0.4385],\n",
       "         [-0.4383],\n",
       "         [-0.4381],\n",
       "         [-0.4379],\n",
       "         [-0.4377],\n",
       "         [-0.4375],\n",
       "         [-0.4373],\n",
       "         [-0.4371],\n",
       "         [-0.4369],\n",
       "         [-0.4366],\n",
       "         [-0.4364],\n",
       "         [-0.4362],\n",
       "         [-0.4360],\n",
       "         [-0.4358],\n",
       "         [-0.4356],\n",
       "         [-0.4354],\n",
       "         [-0.4352],\n",
       "         [-0.4350],\n",
       "         [-0.4348],\n",
       "         [-0.4346],\n",
       "         [-0.4344],\n",
       "         [-0.4342],\n",
       "         [-0.4340],\n",
       "         [-0.4338],\n",
       "         [-0.4336],\n",
       "         [-0.4334],\n",
       "         [-0.4332],\n",
       "         [-0.4330],\n",
       "         [-0.4328],\n",
       "         [-0.4326],\n",
       "         [-0.4324],\n",
       "         [-0.4322],\n",
       "         [-0.4320],\n",
       "         [-0.4317],\n",
       "         [-0.4315],\n",
       "         [-0.4313],\n",
       "         [-0.4311],\n",
       "         [-0.4309],\n",
       "         [-0.4307],\n",
       "         [-0.4305],\n",
       "         [-0.4303],\n",
       "         [-0.4301],\n",
       "         [-0.4299],\n",
       "         [-0.4297],\n",
       "         [-0.4295],\n",
       "         [-0.4293],\n",
       "         [-0.4291],\n",
       "         [-0.4289],\n",
       "         [-0.4287],\n",
       "         [-0.4285],\n",
       "         [-0.4283],\n",
       "         [-0.4281],\n",
       "         [-0.4279],\n",
       "         [-0.4276],\n",
       "         [-0.4274],\n",
       "         [-0.4272],\n",
       "         [-0.4270],\n",
       "         [-0.4268],\n",
       "         [-0.4266],\n",
       "         [-0.4264],\n",
       "         [-0.4262],\n",
       "         [-0.4260],\n",
       "         [-0.4258],\n",
       "         [-0.4256],\n",
       "         [-0.4254],\n",
       "         [-0.4252],\n",
       "         [-0.4250],\n",
       "         [-0.4248],\n",
       "         [-0.4246],\n",
       "         [-0.4243],\n",
       "         [-0.4241],\n",
       "         [-0.4239],\n",
       "         [-0.4237],\n",
       "         [-0.4235],\n",
       "         [-0.4233],\n",
       "         [-0.4231],\n",
       "         [-0.4229],\n",
       "         [-0.4227],\n",
       "         [-0.4225],\n",
       "         [-0.4223],\n",
       "         [-0.4221],\n",
       "         [-0.4219],\n",
       "         [-0.4217],\n",
       "         [-0.4214],\n",
       "         [-0.4212],\n",
       "         [-0.4210],\n",
       "         [-0.4208],\n",
       "         [-0.4206],\n",
       "         [-0.4204],\n",
       "         [-0.4202],\n",
       "         [-0.4200],\n",
       "         [-0.4198],\n",
       "         [-0.4196],\n",
       "         [-0.4194],\n",
       "         [-0.4192],\n",
       "         [-0.4190],\n",
       "         [-0.4187],\n",
       "         [-0.4185],\n",
       "         [-0.4183],\n",
       "         [-0.4181],\n",
       "         [-0.4179],\n",
       "         [-0.4177],\n",
       "         [-0.4175],\n",
       "         [-0.4173],\n",
       "         [-0.4171],\n",
       "         [-0.4169],\n",
       "         [-0.4167],\n",
       "         [-0.4165],\n",
       "         [-0.4162],\n",
       "         [-0.4160],\n",
       "         [-0.4158],\n",
       "         [-0.4156],\n",
       "         [-0.4154],\n",
       "         [-0.4152],\n",
       "         [-0.4150],\n",
       "         [-0.4148],\n",
       "         [-0.4146],\n",
       "         [-0.4144],\n",
       "         [-0.4141],\n",
       "         [-0.4139],\n",
       "         [-0.4137],\n",
       "         [-0.4135],\n",
       "         [-0.4133],\n",
       "         [-0.4131],\n",
       "         [-0.4129]]),\n",
       " tensor([[-0.4127],\n",
       "         [-0.4125],\n",
       "         [-0.4123],\n",
       "         [-0.4120],\n",
       "         [-0.4118],\n",
       "         [-0.4116],\n",
       "         [-0.4114],\n",
       "         [-0.4112],\n",
       "         [-0.4110],\n",
       "         [-0.4108],\n",
       "         [-0.4106],\n",
       "         [-0.4104],\n",
       "         [-0.4102],\n",
       "         [-0.4099],\n",
       "         [-0.4097],\n",
       "         [-0.4095],\n",
       "         [-0.4093],\n",
       "         [-0.4091],\n",
       "         [-0.4089],\n",
       "         [-0.4087],\n",
       "         [-0.4085],\n",
       "         [-0.4083],\n",
       "         [-0.4080],\n",
       "         [-0.4078],\n",
       "         [-0.4076],\n",
       "         [-0.4074],\n",
       "         [-0.4072],\n",
       "         [-0.4070],\n",
       "         [-0.4068],\n",
       "         [-0.4066],\n",
       "         [-0.4063],\n",
       "         [-0.4061],\n",
       "         [-0.4059],\n",
       "         [-0.4057],\n",
       "         [-0.4055],\n",
       "         [-0.4053],\n",
       "         [-0.4051],\n",
       "         [-0.4049],\n",
       "         [-0.4046],\n",
       "         [-0.4044],\n",
       "         [-0.4042],\n",
       "         [-0.4040],\n",
       "         [-0.4038],\n",
       "         [-0.4036],\n",
       "         [-0.4034],\n",
       "         [-0.4032],\n",
       "         [-0.4029],\n",
       "         [-0.4027],\n",
       "         [-0.4025],\n",
       "         [-0.4023],\n",
       "         [-0.4021],\n",
       "         [-0.4019],\n",
       "         [-0.4017],\n",
       "         [-0.4015],\n",
       "         [-0.4012],\n",
       "         [-0.4010],\n",
       "         [-0.4008],\n",
       "         [-0.4006],\n",
       "         [-0.4004],\n",
       "         [-0.4002],\n",
       "         [-0.4000],\n",
       "         [-0.3997],\n",
       "         [-0.3995],\n",
       "         [-0.3993],\n",
       "         [-0.3991],\n",
       "         [-0.3989],\n",
       "         [-0.3987],\n",
       "         [-0.3985],\n",
       "         [-0.3982],\n",
       "         [-0.3980],\n",
       "         [-0.3978],\n",
       "         [-0.3976],\n",
       "         [-0.3974],\n",
       "         [-0.3972],\n",
       "         [-0.3970],\n",
       "         [-0.3967],\n",
       "         [-0.3965],\n",
       "         [-0.3963],\n",
       "         [-0.3961],\n",
       "         [-0.3959],\n",
       "         [-0.3957],\n",
       "         [-0.3954],\n",
       "         [-0.3952],\n",
       "         [-0.3950],\n",
       "         [-0.3948],\n",
       "         [-0.3946],\n",
       "         [-0.3944],\n",
       "         [-0.3942],\n",
       "         [-0.3939],\n",
       "         [-0.3937],\n",
       "         [-0.3935],\n",
       "         [-0.3933],\n",
       "         [-0.3931],\n",
       "         [-0.3929],\n",
       "         [-0.3926],\n",
       "         [-0.3924],\n",
       "         [-0.3922],\n",
       "         [-0.3920],\n",
       "         [-0.3918],\n",
       "         [-0.3916],\n",
       "         [-0.3913],\n",
       "         [-0.3911],\n",
       "         [-0.3909],\n",
       "         [-0.3907],\n",
       "         [-0.3905],\n",
       "         [-0.3903],\n",
       "         [-0.3900],\n",
       "         [-0.3898],\n",
       "         [-0.3896],\n",
       "         [-0.3894],\n",
       "         [-0.3892],\n",
       "         [-0.3889],\n",
       "         [-0.3887],\n",
       "         [-0.3885],\n",
       "         [-0.3883],\n",
       "         [-0.3881],\n",
       "         [-0.3879],\n",
       "         [-0.3876],\n",
       "         [-0.3874],\n",
       "         [-0.3872],\n",
       "         [-0.3870],\n",
       "         [-0.3868],\n",
       "         [-0.3865],\n",
       "         [-0.3863],\n",
       "         [-0.3861],\n",
       "         [-0.3859],\n",
       "         [-0.3857],\n",
       "         [-0.3855]]),\n",
       " tensor([[-0.3852],\n",
       "         [-0.3850],\n",
       "         [-0.3848],\n",
       "         [-0.3846],\n",
       "         [-0.3844],\n",
       "         [-0.3841],\n",
       "         [-0.3839],\n",
       "         [-0.3837],\n",
       "         [-0.3835],\n",
       "         [-0.3833],\n",
       "         [-0.3830],\n",
       "         [-0.3828],\n",
       "         [-0.3826],\n",
       "         [-0.3824],\n",
       "         [-0.3822],\n",
       "         [-0.3819],\n",
       "         [-0.3817],\n",
       "         [-0.3815],\n",
       "         [-0.3813],\n",
       "         [-0.3811],\n",
       "         [-0.3808],\n",
       "         [-0.3806],\n",
       "         [-0.3804],\n",
       "         [-0.3802],\n",
       "         [-0.3800],\n",
       "         [-0.3797],\n",
       "         [-0.3795],\n",
       "         [-0.3793],\n",
       "         [-0.3791],\n",
       "         [-0.3788],\n",
       "         [-0.3786],\n",
       "         [-0.3784],\n",
       "         [-0.3782],\n",
       "         [-0.3780],\n",
       "         [-0.3777],\n",
       "         [-0.3775],\n",
       "         [-0.3773],\n",
       "         [-0.3771],\n",
       "         [-0.3769],\n",
       "         [-0.3766],\n",
       "         [-0.3764],\n",
       "         [-0.3762],\n",
       "         [-0.3760],\n",
       "         [-0.3757],\n",
       "         [-0.3755],\n",
       "         [-0.3753],\n",
       "         [-0.3751],\n",
       "         [-0.3749],\n",
       "         [-0.3746],\n",
       "         [-0.3744],\n",
       "         [-0.3742],\n",
       "         [-0.3740],\n",
       "         [-0.3737],\n",
       "         [-0.3735],\n",
       "         [-0.3733],\n",
       "         [-0.3731],\n",
       "         [-0.3728],\n",
       "         [-0.3726],\n",
       "         [-0.3724],\n",
       "         [-0.3722],\n",
       "         [-0.3720],\n",
       "         [-0.3717],\n",
       "         [-0.3715],\n",
       "         [-0.3713],\n",
       "         [-0.3711],\n",
       "         [-0.3708],\n",
       "         [-0.3706],\n",
       "         [-0.3704],\n",
       "         [-0.3702],\n",
       "         [-0.3699],\n",
       "         [-0.3697],\n",
       "         [-0.3695],\n",
       "         [-0.3693],\n",
       "         [-0.3690],\n",
       "         [-0.3688],\n",
       "         [-0.3686],\n",
       "         [-0.3684],\n",
       "         [-0.3681],\n",
       "         [-0.3679],\n",
       "         [-0.3677],\n",
       "         [-0.3675],\n",
       "         [-0.3672],\n",
       "         [-0.3670],\n",
       "         [-0.3668],\n",
       "         [-0.3666],\n",
       "         [-0.3663],\n",
       "         [-0.3661],\n",
       "         [-0.3659],\n",
       "         [-0.3657],\n",
       "         [-0.3654],\n",
       "         [-0.3652],\n",
       "         [-0.3650],\n",
       "         [-0.3647],\n",
       "         [-0.3645],\n",
       "         [-0.3643],\n",
       "         [-0.3641],\n",
       "         [-0.3638],\n",
       "         [-0.3636],\n",
       "         [-0.3634],\n",
       "         [-0.3632],\n",
       "         [-0.3629],\n",
       "         [-0.3627],\n",
       "         [-0.3625],\n",
       "         [-0.3623],\n",
       "         [-0.3620],\n",
       "         [-0.3618],\n",
       "         [-0.3616],\n",
       "         [-0.3613],\n",
       "         [-0.3611],\n",
       "         [-0.3609],\n",
       "         [-0.3607],\n",
       "         [-0.3604],\n",
       "         [-0.3602],\n",
       "         [-0.3600],\n",
       "         [-0.3597],\n",
       "         [-0.3595],\n",
       "         [-0.3593],\n",
       "         [-0.3591],\n",
       "         [-0.3588],\n",
       "         [-0.3586],\n",
       "         [-0.3584],\n",
       "         [-0.3581],\n",
       "         [-0.3579],\n",
       "         [-0.3577],\n",
       "         [-0.3575],\n",
       "         [-0.3572],\n",
       "         [-0.3570],\n",
       "         [-0.3568]]),\n",
       " tensor([[-0.3565],\n",
       "         [-0.3563],\n",
       "         [-0.3561],\n",
       "         [-0.3558],\n",
       "         [-0.3556],\n",
       "         [-0.3554],\n",
       "         [-0.3552],\n",
       "         [-0.3549],\n",
       "         [-0.3547],\n",
       "         [-0.3545],\n",
       "         [-0.3542],\n",
       "         [-0.3540],\n",
       "         [-0.3538],\n",
       "         [-0.3535],\n",
       "         [-0.3533],\n",
       "         [-0.3531],\n",
       "         [-0.3529],\n",
       "         [-0.3526],\n",
       "         [-0.3524],\n",
       "         [-0.3522],\n",
       "         [-0.3519],\n",
       "         [-0.3517],\n",
       "         [-0.3515],\n",
       "         [-0.3512],\n",
       "         [-0.3510],\n",
       "         [-0.3508],\n",
       "         [-0.3505],\n",
       "         [-0.3503],\n",
       "         [-0.3501],\n",
       "         [-0.3498],\n",
       "         [-0.3496],\n",
       "         [-0.3494],\n",
       "         [-0.3491],\n",
       "         [-0.3489],\n",
       "         [-0.3487],\n",
       "         [-0.3484],\n",
       "         [-0.3482],\n",
       "         [-0.3480],\n",
       "         [-0.3477],\n",
       "         [-0.3475],\n",
       "         [-0.3473],\n",
       "         [-0.3470],\n",
       "         [-0.3468],\n",
       "         [-0.3466],\n",
       "         [-0.3463],\n",
       "         [-0.3461],\n",
       "         [-0.3459],\n",
       "         [-0.3456],\n",
       "         [-0.3454],\n",
       "         [-0.3452],\n",
       "         [-0.3449],\n",
       "         [-0.3447],\n",
       "         [-0.3445],\n",
       "         [-0.3442],\n",
       "         [-0.3440],\n",
       "         [-0.3438],\n",
       "         [-0.3435],\n",
       "         [-0.3433],\n",
       "         [-0.3431],\n",
       "         [-0.3428],\n",
       "         [-0.3426],\n",
       "         [-0.3424],\n",
       "         [-0.3421],\n",
       "         [-0.3419],\n",
       "         [-0.3416],\n",
       "         [-0.3414],\n",
       "         [-0.3412],\n",
       "         [-0.3409],\n",
       "         [-0.3407],\n",
       "         [-0.3405],\n",
       "         [-0.3402],\n",
       "         [-0.3400],\n",
       "         [-0.3398],\n",
       "         [-0.3395],\n",
       "         [-0.3393],\n",
       "         [-0.3390],\n",
       "         [-0.3388],\n",
       "         [-0.3386],\n",
       "         [-0.3383],\n",
       "         [-0.3381],\n",
       "         [-0.3379],\n",
       "         [-0.3376],\n",
       "         [-0.3374],\n",
       "         [-0.3371],\n",
       "         [-0.3369],\n",
       "         [-0.3367],\n",
       "         [-0.3364],\n",
       "         [-0.3362],\n",
       "         [-0.3360],\n",
       "         [-0.3357],\n",
       "         [-0.3355],\n",
       "         [-0.3352],\n",
       "         [-0.3350],\n",
       "         [-0.3348],\n",
       "         [-0.3345],\n",
       "         [-0.3343],\n",
       "         [-0.3340],\n",
       "         [-0.3338],\n",
       "         [-0.3336],\n",
       "         [-0.3333],\n",
       "         [-0.3331],\n",
       "         [-0.3329],\n",
       "         [-0.3326],\n",
       "         [-0.3324],\n",
       "         [-0.3321],\n",
       "         [-0.3319],\n",
       "         [-0.3317],\n",
       "         [-0.3314],\n",
       "         [-0.3312],\n",
       "         [-0.3309],\n",
       "         [-0.3307],\n",
       "         [-0.3305],\n",
       "         [-0.3302],\n",
       "         [-0.3300],\n",
       "         [-0.3297],\n",
       "         [-0.3295],\n",
       "         [-0.3292],\n",
       "         [-0.3290],\n",
       "         [-0.3288],\n",
       "         [-0.3285],\n",
       "         [-0.3283],\n",
       "         [-0.3280],\n",
       "         [-0.3278],\n",
       "         [-0.3276],\n",
       "         [-0.3273],\n",
       "         [-0.3271],\n",
       "         [-0.3268],\n",
       "         [-0.3266]]),\n",
       " tensor([[-0.3263],\n",
       "         [-0.3261],\n",
       "         [-0.3259],\n",
       "         [-0.3256],\n",
       "         [-0.3254],\n",
       "         [-0.3251],\n",
       "         [-0.3249],\n",
       "         [-0.3247],\n",
       "         [-0.3244],\n",
       "         [-0.3242],\n",
       "         [-0.3239],\n",
       "         [-0.3237],\n",
       "         [-0.3234],\n",
       "         [-0.3232],\n",
       "         [-0.3229],\n",
       "         [-0.3227],\n",
       "         [-0.3225],\n",
       "         [-0.3222],\n",
       "         [-0.3220],\n",
       "         [-0.3217],\n",
       "         [-0.3215],\n",
       "         [-0.3212],\n",
       "         [-0.3210],\n",
       "         [-0.3208],\n",
       "         [-0.3205],\n",
       "         [-0.3203],\n",
       "         [-0.3200],\n",
       "         [-0.3198],\n",
       "         [-0.3195],\n",
       "         [-0.3193],\n",
       "         [-0.3190],\n",
       "         [-0.3188],\n",
       "         [-0.3186],\n",
       "         [-0.3183],\n",
       "         [-0.3181],\n",
       "         [-0.3178],\n",
       "         [-0.3176],\n",
       "         [-0.3173],\n",
       "         [-0.3171],\n",
       "         [-0.3168],\n",
       "         [-0.3166],\n",
       "         [-0.3164],\n",
       "         [-0.3161],\n",
       "         [-0.3159],\n",
       "         [-0.3156],\n",
       "         [-0.3154],\n",
       "         [-0.3151],\n",
       "         [-0.3149],\n",
       "         [-0.3146],\n",
       "         [-0.3144],\n",
       "         [-0.3142],\n",
       "         [-0.3139],\n",
       "         [-0.3137],\n",
       "         [-0.3134],\n",
       "         [-0.3132],\n",
       "         [-0.3129],\n",
       "         [-0.3127],\n",
       "         [-0.3124],\n",
       "         [-0.3122],\n",
       "         [-0.3119],\n",
       "         [-0.3117],\n",
       "         [-0.3114],\n",
       "         [-0.3112],\n",
       "         [-0.3110],\n",
       "         [-0.3107],\n",
       "         [-0.3105],\n",
       "         [-0.3102],\n",
       "         [-0.3100],\n",
       "         [-0.3097],\n",
       "         [-0.3095],\n",
       "         [-0.3092],\n",
       "         [-0.3090],\n",
       "         [-0.3087],\n",
       "         [-0.3085],\n",
       "         [-0.3082],\n",
       "         [-0.3080],\n",
       "         [-0.3077],\n",
       "         [-0.3075],\n",
       "         [-0.3072],\n",
       "         [-0.3070],\n",
       "         [-0.3067],\n",
       "         [-0.3065],\n",
       "         [-0.3062],\n",
       "         [-0.3060],\n",
       "         [-0.3058],\n",
       "         [-0.3055],\n",
       "         [-0.3053],\n",
       "         [-0.3050],\n",
       "         [-0.3048],\n",
       "         [-0.3045],\n",
       "         [-0.3043],\n",
       "         [-0.3041],\n",
       "         [-0.3038],\n",
       "         [-0.3036],\n",
       "         [-0.3034],\n",
       "         [-0.3031],\n",
       "         [-0.3029],\n",
       "         [-0.3027],\n",
       "         [-0.3025],\n",
       "         [-0.3022],\n",
       "         [-0.3020],\n",
       "         [-0.3018],\n",
       "         [-0.3015],\n",
       "         [-0.3013],\n",
       "         [-0.3011],\n",
       "         [-0.3008],\n",
       "         [-0.3006],\n",
       "         [-0.3004],\n",
       "         [-0.3001],\n",
       "         [-0.2999],\n",
       "         [-0.2997],\n",
       "         [-0.2995],\n",
       "         [-0.2992],\n",
       "         [-0.2990],\n",
       "         [-0.2988],\n",
       "         [-0.2985],\n",
       "         [-0.2983],\n",
       "         [-0.2981],\n",
       "         [-0.2979],\n",
       "         [-0.2976],\n",
       "         [-0.2974],\n",
       "         [-0.2972],\n",
       "         [-0.2969],\n",
       "         [-0.2967],\n",
       "         [-0.2965],\n",
       "         [-0.2963],\n",
       "         [-0.2960],\n",
       "         [-0.2958]]),\n",
       " tensor([[-0.2956],\n",
       "         [-0.2953],\n",
       "         [-0.2951],\n",
       "         [-0.2949],\n",
       "         [-0.2947],\n",
       "         [-0.2944],\n",
       "         [-0.2942],\n",
       "         [-0.2940],\n",
       "         [-0.2937],\n",
       "         [-0.2935],\n",
       "         [-0.2933],\n",
       "         [-0.2930],\n",
       "         [-0.2928],\n",
       "         [-0.2926],\n",
       "         [-0.2923],\n",
       "         [-0.2921],\n",
       "         [-0.2919],\n",
       "         [-0.2917],\n",
       "         [-0.2914],\n",
       "         [-0.2912],\n",
       "         [-0.2910],\n",
       "         [-0.2907],\n",
       "         [-0.2905],\n",
       "         [-0.2903],\n",
       "         [-0.2900],\n",
       "         [-0.2898],\n",
       "         [-0.2896],\n",
       "         [-0.2893],\n",
       "         [-0.2891],\n",
       "         [-0.2889],\n",
       "         [-0.2886],\n",
       "         [-0.2884],\n",
       "         [-0.2882],\n",
       "         [-0.2879],\n",
       "         [-0.2877],\n",
       "         [-0.2875],\n",
       "         [-0.2872],\n",
       "         [-0.2870],\n",
       "         [-0.2868],\n",
       "         [-0.2865],\n",
       "         [-0.2863],\n",
       "         [-0.2861],\n",
       "         [-0.2858],\n",
       "         [-0.2856],\n",
       "         [-0.2854],\n",
       "         [-0.2851],\n",
       "         [-0.2849],\n",
       "         [-0.2847],\n",
       "         [-0.2844],\n",
       "         [-0.2842],\n",
       "         [-0.2840],\n",
       "         [-0.2837],\n",
       "         [-0.2835],\n",
       "         [-0.2833],\n",
       "         [-0.2830],\n",
       "         [-0.2828],\n",
       "         [-0.2825],\n",
       "         [-0.2823],\n",
       "         [-0.2821],\n",
       "         [-0.2818],\n",
       "         [-0.2816],\n",
       "         [-0.2814],\n",
       "         [-0.2811],\n",
       "         [-0.2809],\n",
       "         [-0.2807],\n",
       "         [-0.2804],\n",
       "         [-0.2802],\n",
       "         [-0.2799],\n",
       "         [-0.2797],\n",
       "         [-0.2795],\n",
       "         [-0.2792],\n",
       "         [-0.2790],\n",
       "         [-0.2788],\n",
       "         [-0.2785],\n",
       "         [-0.2783],\n",
       "         [-0.2780],\n",
       "         [-0.2778],\n",
       "         [-0.2776],\n",
       "         [-0.2773],\n",
       "         [-0.2771],\n",
       "         [-0.2769],\n",
       "         [-0.2766],\n",
       "         [-0.2764],\n",
       "         [-0.2761],\n",
       "         [-0.2759],\n",
       "         [-0.2757],\n",
       "         [-0.2754],\n",
       "         [-0.2752],\n",
       "         [-0.2749],\n",
       "         [-0.2747],\n",
       "         [-0.2745],\n",
       "         [-0.2742],\n",
       "         [-0.2740],\n",
       "         [-0.2737],\n",
       "         [-0.2735],\n",
       "         [-0.2733],\n",
       "         [-0.2730],\n",
       "         [-0.2728],\n",
       "         [-0.2725],\n",
       "         [-0.2723],\n",
       "         [-0.2721],\n",
       "         [-0.2718],\n",
       "         [-0.2716],\n",
       "         [-0.2713],\n",
       "         [-0.2711],\n",
       "         [-0.2709],\n",
       "         [-0.2706],\n",
       "         [-0.2704],\n",
       "         [-0.2701],\n",
       "         [-0.2699],\n",
       "         [-0.2696],\n",
       "         [-0.2694],\n",
       "         [-0.2692],\n",
       "         [-0.2689],\n",
       "         [-0.2687],\n",
       "         [-0.2684],\n",
       "         [-0.2682],\n",
       "         [-0.2679],\n",
       "         [-0.2677],\n",
       "         [-0.2675],\n",
       "         [-0.2672],\n",
       "         [-0.2670],\n",
       "         [-0.2667],\n",
       "         [-0.2665],\n",
       "         [-0.2662],\n",
       "         [-0.2660],\n",
       "         [-0.2658],\n",
       "         [-0.2655]]),\n",
       " tensor([[-0.2653],\n",
       "         [-0.2650],\n",
       "         [-0.2648],\n",
       "         [-0.2645],\n",
       "         [-0.2643],\n",
       "         [-0.2640],\n",
       "         [-0.2638],\n",
       "         [-0.2636],\n",
       "         [-0.2633],\n",
       "         [-0.2631],\n",
       "         [-0.2628],\n",
       "         [-0.2626],\n",
       "         [-0.2623],\n",
       "         [-0.2621],\n",
       "         [-0.2618],\n",
       "         [-0.2616],\n",
       "         [-0.2613],\n",
       "         [-0.2611],\n",
       "         [-0.2609],\n",
       "         [-0.2606],\n",
       "         [-0.2604],\n",
       "         [-0.2601],\n",
       "         [-0.2599],\n",
       "         [-0.2596],\n",
       "         [-0.2594],\n",
       "         [-0.2591],\n",
       "         [-0.2589],\n",
       "         [-0.2586],\n",
       "         [-0.2584],\n",
       "         [-0.2581],\n",
       "         [-0.2579],\n",
       "         [-0.2577],\n",
       "         [-0.2574],\n",
       "         [-0.2572],\n",
       "         [-0.2569],\n",
       "         [-0.2567],\n",
       "         [-0.2564],\n",
       "         [-0.2562],\n",
       "         [-0.2559],\n",
       "         [-0.2557],\n",
       "         [-0.2554],\n",
       "         [-0.2552],\n",
       "         [-0.2549],\n",
       "         [-0.2547],\n",
       "         [-0.2544],\n",
       "         [-0.2542],\n",
       "         [-0.2539],\n",
       "         [-0.2537],\n",
       "         [-0.2534],\n",
       "         [-0.2532],\n",
       "         [-0.2529],\n",
       "         [-0.2527],\n",
       "         [-0.2524],\n",
       "         [-0.2522],\n",
       "         [-0.2519],\n",
       "         [-0.2517],\n",
       "         [-0.2514],\n",
       "         [-0.2512],\n",
       "         [-0.2509],\n",
       "         [-0.2507],\n",
       "         [-0.2504],\n",
       "         [-0.2502],\n",
       "         [-0.2499],\n",
       "         [-0.2497],\n",
       "         [-0.2494],\n",
       "         [-0.2492],\n",
       "         [-0.2489],\n",
       "         [-0.2487],\n",
       "         [-0.2484],\n",
       "         [-0.2482],\n",
       "         [-0.2479],\n",
       "         [-0.2477],\n",
       "         [-0.2474],\n",
       "         [-0.2472],\n",
       "         [-0.2469],\n",
       "         [-0.2467],\n",
       "         [-0.2464],\n",
       "         [-0.2462],\n",
       "         [-0.2459],\n",
       "         [-0.2457],\n",
       "         [-0.2454],\n",
       "         [-0.2452],\n",
       "         [-0.2449],\n",
       "         [-0.2447],\n",
       "         [-0.2444],\n",
       "         [-0.2442],\n",
       "         [-0.2439],\n",
       "         [-0.2436],\n",
       "         [-0.2434],\n",
       "         [-0.2431],\n",
       "         [-0.2429],\n",
       "         [-0.2426],\n",
       "         [-0.2424],\n",
       "         [-0.2421],\n",
       "         [-0.2419],\n",
       "         [-0.2416],\n",
       "         [-0.2414],\n",
       "         [-0.2411],\n",
       "         [-0.2409],\n",
       "         [-0.2406],\n",
       "         [-0.2404],\n",
       "         [-0.2401],\n",
       "         [-0.2398],\n",
       "         [-0.2396],\n",
       "         [-0.2393],\n",
       "         [-0.2391],\n",
       "         [-0.2388],\n",
       "         [-0.2386],\n",
       "         [-0.2383],\n",
       "         [-0.2381],\n",
       "         [-0.2378],\n",
       "         [-0.2376],\n",
       "         [-0.2373],\n",
       "         [-0.2370],\n",
       "         [-0.2368],\n",
       "         [-0.2365],\n",
       "         [-0.2363],\n",
       "         [-0.2360],\n",
       "         [-0.2358],\n",
       "         [-0.2355],\n",
       "         [-0.2353],\n",
       "         [-0.2350],\n",
       "         [-0.2347],\n",
       "         [-0.2345],\n",
       "         [-0.2342],\n",
       "         [-0.2340],\n",
       "         [-0.2337],\n",
       "         [-0.2335]]),\n",
       " tensor([[-0.2332],\n",
       "         [-0.2329],\n",
       "         [-0.2327],\n",
       "         [-0.2324],\n",
       "         [-0.2322],\n",
       "         [-0.2319],\n",
       "         [-0.2317],\n",
       "         [-0.2314],\n",
       "         [-0.2311],\n",
       "         [-0.2309],\n",
       "         [-0.2306],\n",
       "         [-0.2304],\n",
       "         [-0.2301],\n",
       "         [-0.2299],\n",
       "         [-0.2296],\n",
       "         [-0.2293],\n",
       "         [-0.2291],\n",
       "         [-0.2288],\n",
       "         [-0.2286],\n",
       "         [-0.2283],\n",
       "         [-0.2281],\n",
       "         [-0.2278],\n",
       "         [-0.2275],\n",
       "         [-0.2273],\n",
       "         [-0.2270],\n",
       "         [-0.2268],\n",
       "         [-0.2265],\n",
       "         [-0.2262],\n",
       "         [-0.2260],\n",
       "         [-0.2257],\n",
       "         [-0.2255],\n",
       "         [-0.2252],\n",
       "         [-0.2249],\n",
       "         [-0.2247],\n",
       "         [-0.2244],\n",
       "         [-0.2242],\n",
       "         [-0.2239],\n",
       "         [-0.2237],\n",
       "         [-0.2234],\n",
       "         [-0.2231],\n",
       "         [-0.2229],\n",
       "         [-0.2226],\n",
       "         [-0.2224],\n",
       "         [-0.2221],\n",
       "         [-0.2218],\n",
       "         [-0.2216],\n",
       "         [-0.2213],\n",
       "         [-0.2210],\n",
       "         [-0.2208],\n",
       "         [-0.2205],\n",
       "         [-0.2203],\n",
       "         [-0.2200],\n",
       "         [-0.2197],\n",
       "         [-0.2195],\n",
       "         [-0.2192],\n",
       "         [-0.2190],\n",
       "         [-0.2187],\n",
       "         [-0.2184],\n",
       "         [-0.2182],\n",
       "         [-0.2179],\n",
       "         [-0.2177],\n",
       "         [-0.2174],\n",
       "         [-0.2171],\n",
       "         [-0.2169],\n",
       "         [-0.2166],\n",
       "         [-0.2163],\n",
       "         [-0.2161],\n",
       "         [-0.2158],\n",
       "         [-0.2156],\n",
       "         [-0.2153],\n",
       "         [-0.2150],\n",
       "         [-0.2148],\n",
       "         [-0.2145],\n",
       "         [-0.2143],\n",
       "         [-0.2140],\n",
       "         [-0.2137],\n",
       "         [-0.2135],\n",
       "         [-0.2132],\n",
       "         [-0.2129],\n",
       "         [-0.2127],\n",
       "         [-0.2124],\n",
       "         [-0.2121],\n",
       "         [-0.2119],\n",
       "         [-0.2116],\n",
       "         [-0.2114],\n",
       "         [-0.2111],\n",
       "         [-0.2108],\n",
       "         [-0.2106],\n",
       "         [-0.2103],\n",
       "         [-0.2100],\n",
       "         [-0.2098],\n",
       "         [-0.2095],\n",
       "         [-0.2092],\n",
       "         [-0.2090],\n",
       "         [-0.2087],\n",
       "         [-0.2085],\n",
       "         [-0.2082],\n",
       "         [-0.2079],\n",
       "         [-0.2077],\n",
       "         [-0.2074],\n",
       "         [-0.2071],\n",
       "         [-0.2069],\n",
       "         [-0.2066],\n",
       "         [-0.2063],\n",
       "         [-0.2061],\n",
       "         [-0.2058],\n",
       "         [-0.2055],\n",
       "         [-0.2053],\n",
       "         [-0.2050],\n",
       "         [-0.2047],\n",
       "         [-0.2045],\n",
       "         [-0.2042],\n",
       "         [-0.2039],\n",
       "         [-0.2037],\n",
       "         [-0.2034],\n",
       "         [-0.2031],\n",
       "         [-0.2029],\n",
       "         [-0.2026],\n",
       "         [-0.2023],\n",
       "         [-0.2021],\n",
       "         [-0.2018],\n",
       "         [-0.2015],\n",
       "         [-0.2013],\n",
       "         [-0.2010],\n",
       "         [-0.2007],\n",
       "         [-0.2005],\n",
       "         [-0.2002],\n",
       "         [-0.1999]]),\n",
       " tensor([[-0.1997],\n",
       "         [-0.1994],\n",
       "         [-0.1991],\n",
       "         [-0.1989],\n",
       "         [-0.1986],\n",
       "         [-0.1983],\n",
       "         [-0.1981],\n",
       "         [-0.1978],\n",
       "         [-0.1975],\n",
       "         [-0.1973],\n",
       "         [-0.1970],\n",
       "         [-0.1967],\n",
       "         [-0.1965],\n",
       "         [-0.1962],\n",
       "         [-0.1959],\n",
       "         [-0.1956],\n",
       "         [-0.1954],\n",
       "         [-0.1951],\n",
       "         [-0.1948],\n",
       "         [-0.1946],\n",
       "         [-0.1943],\n",
       "         [-0.1940],\n",
       "         [-0.1938],\n",
       "         [-0.1935],\n",
       "         [-0.1932],\n",
       "         [-0.1929],\n",
       "         [-0.1927],\n",
       "         [-0.1924],\n",
       "         [-0.1921],\n",
       "         [-0.1919],\n",
       "         [-0.1916],\n",
       "         [-0.1913],\n",
       "         [-0.1911],\n",
       "         [-0.1908],\n",
       "         [-0.1905],\n",
       "         [-0.1902],\n",
       "         [-0.1900],\n",
       "         [-0.1897],\n",
       "         [-0.1894],\n",
       "         [-0.1892],\n",
       "         [-0.1889],\n",
       "         [-0.1886],\n",
       "         [-0.1883],\n",
       "         [-0.1881],\n",
       "         [-0.1878],\n",
       "         [-0.1875],\n",
       "         [-0.1872],\n",
       "         [-0.1870],\n",
       "         [-0.1867],\n",
       "         [-0.1864],\n",
       "         [-0.1862],\n",
       "         [-0.1859],\n",
       "         [-0.1856],\n",
       "         [-0.1853],\n",
       "         [-0.1851],\n",
       "         [-0.1848],\n",
       "         [-0.1845],\n",
       "         [-0.1842],\n",
       "         [-0.1840],\n",
       "         [-0.1837],\n",
       "         [-0.1834],\n",
       "         [-0.1831],\n",
       "         [-0.1829],\n",
       "         [-0.1826],\n",
       "         [-0.1823],\n",
       "         [-0.1820],\n",
       "         [-0.1818],\n",
       "         [-0.1815],\n",
       "         [-0.1812],\n",
       "         [-0.1809],\n",
       "         [-0.1807],\n",
       "         [-0.1804],\n",
       "         [-0.1801],\n",
       "         [-0.1798],\n",
       "         [-0.1796],\n",
       "         [-0.1793],\n",
       "         [-0.1790],\n",
       "         [-0.1787],\n",
       "         [-0.1785],\n",
       "         [-0.1782],\n",
       "         [-0.1779],\n",
       "         [-0.1776],\n",
       "         [-0.1774],\n",
       "         [-0.1771],\n",
       "         [-0.1768],\n",
       "         [-0.1765],\n",
       "         [-0.1763],\n",
       "         [-0.1760],\n",
       "         [-0.1757],\n",
       "         [-0.1754],\n",
       "         [-0.1751],\n",
       "         [-0.1749],\n",
       "         [-0.1746],\n",
       "         [-0.1743],\n",
       "         [-0.1740],\n",
       "         [-0.1738],\n",
       "         [-0.1735],\n",
       "         [-0.1732],\n",
       "         [-0.1729],\n",
       "         [-0.1726],\n",
       "         [-0.1724],\n",
       "         [-0.1721],\n",
       "         [-0.1718],\n",
       "         [-0.1715],\n",
       "         [-0.1712],\n",
       "         [-0.1710],\n",
       "         [-0.1707],\n",
       "         [-0.1704],\n",
       "         [-0.1701],\n",
       "         [-0.1698],\n",
       "         [-0.1696],\n",
       "         [-0.1693],\n",
       "         [-0.1690],\n",
       "         [-0.1687],\n",
       "         [-0.1684],\n",
       "         [-0.1682],\n",
       "         [-0.1679],\n",
       "         [-0.1676],\n",
       "         [-0.1673],\n",
       "         [-0.1670],\n",
       "         [-0.1668],\n",
       "         [-0.1665],\n",
       "         [-0.1662],\n",
       "         [-0.1659],\n",
       "         [-0.1656],\n",
       "         [-0.1653],\n",
       "         [-0.1651],\n",
       "         [-0.1648]]),\n",
       " tensor([[-0.1645],\n",
       "         [-0.1642],\n",
       "         [-0.1639],\n",
       "         [-0.1637],\n",
       "         [-0.1634],\n",
       "         [-0.1631],\n",
       "         [-0.1628],\n",
       "         [-0.1625],\n",
       "         [-0.1622],\n",
       "         [-0.1620],\n",
       "         [-0.1617],\n",
       "         [-0.1614],\n",
       "         [-0.1611],\n",
       "         [-0.1608],\n",
       "         [-0.1605],\n",
       "         [-0.1603],\n",
       "         [-0.1600],\n",
       "         [-0.1597],\n",
       "         [-0.1594],\n",
       "         [-0.1591],\n",
       "         [-0.1588],\n",
       "         [-0.1585],\n",
       "         [-0.1583],\n",
       "         [-0.1580],\n",
       "         [-0.1577],\n",
       "         [-0.1574],\n",
       "         [-0.1571],\n",
       "         [-0.1568],\n",
       "         [-0.1565],\n",
       "         [-0.1563],\n",
       "         [-0.1560],\n",
       "         [-0.1557],\n",
       "         [-0.1554],\n",
       "         [-0.1551],\n",
       "         [-0.1548],\n",
       "         [-0.1545],\n",
       "         [-0.1543],\n",
       "         [-0.1540],\n",
       "         [-0.1537],\n",
       "         [-0.1534],\n",
       "         [-0.1531],\n",
       "         [-0.1528],\n",
       "         [-0.1525],\n",
       "         [-0.1522],\n",
       "         [-0.1520],\n",
       "         [-0.1517],\n",
       "         [-0.1514],\n",
       "         [-0.1511],\n",
       "         [-0.1508],\n",
       "         [-0.1505],\n",
       "         [-0.1502],\n",
       "         [-0.1499],\n",
       "         [-0.1496],\n",
       "         [-0.1494],\n",
       "         [-0.1491],\n",
       "         [-0.1488],\n",
       "         [-0.1485],\n",
       "         [-0.1482],\n",
       "         [-0.1479],\n",
       "         [-0.1476],\n",
       "         [-0.1473],\n",
       "         [-0.1470],\n",
       "         [-0.1467],\n",
       "         [-0.1465],\n",
       "         [-0.1462],\n",
       "         [-0.1459],\n",
       "         [-0.1456],\n",
       "         [-0.1453],\n",
       "         [-0.1450],\n",
       "         [-0.1447],\n",
       "         [-0.1444],\n",
       "         [-0.1441],\n",
       "         [-0.1438],\n",
       "         [-0.1435],\n",
       "         [-0.1432],\n",
       "         [-0.1430],\n",
       "         [-0.1427],\n",
       "         [-0.1424],\n",
       "         [-0.1421],\n",
       "         [-0.1418],\n",
       "         [-0.1415],\n",
       "         [-0.1412],\n",
       "         [-0.1409],\n",
       "         [-0.1406],\n",
       "         [-0.1403],\n",
       "         [-0.1400],\n",
       "         [-0.1397],\n",
       "         [-0.1394],\n",
       "         [-0.1391],\n",
       "         [-0.1388],\n",
       "         [-0.1386],\n",
       "         [-0.1383],\n",
       "         [-0.1380],\n",
       "         [-0.1377],\n",
       "         [-0.1374],\n",
       "         [-0.1371],\n",
       "         [-0.1368],\n",
       "         [-0.1365],\n",
       "         [-0.1362],\n",
       "         [-0.1359],\n",
       "         [-0.1356],\n",
       "         [-0.1353],\n",
       "         [-0.1350],\n",
       "         [-0.1347],\n",
       "         [-0.1344],\n",
       "         [-0.1341],\n",
       "         [-0.1338],\n",
       "         [-0.1335],\n",
       "         [-0.1332],\n",
       "         [-0.1329],\n",
       "         [-0.1326],\n",
       "         [-0.1323],\n",
       "         [-0.1320],\n",
       "         [-0.1317],\n",
       "         [-0.1314],\n",
       "         [-0.1311],\n",
       "         [-0.1308],\n",
       "         [-0.1305],\n",
       "         [-0.1303],\n",
       "         [-0.1300],\n",
       "         [-0.1297],\n",
       "         [-0.1294],\n",
       "         [-0.1291],\n",
       "         [-0.1288],\n",
       "         [-0.1285],\n",
       "         [-0.1282],\n",
       "         [-0.1279],\n",
       "         [-0.1276]]),\n",
       " tensor([[-0.1273],\n",
       "         [-0.1270],\n",
       "         [-0.1267],\n",
       "         [-0.1264],\n",
       "         [-0.1261],\n",
       "         [-0.1258],\n",
       "         [-0.1255],\n",
       "         [-0.1252],\n",
       "         [-0.1249],\n",
       "         [-0.1246],\n",
       "         [-0.1242],\n",
       "         [-0.1239],\n",
       "         [-0.1236],\n",
       "         [-0.1233],\n",
       "         [-0.1230],\n",
       "         [-0.1227],\n",
       "         [-0.1224],\n",
       "         [-0.1221],\n",
       "         [-0.1218],\n",
       "         [-0.1215],\n",
       "         [-0.1212],\n",
       "         [-0.1209],\n",
       "         [-0.1206],\n",
       "         [-0.1203],\n",
       "         [-0.1200],\n",
       "         [-0.1197],\n",
       "         [-0.1194],\n",
       "         [-0.1191],\n",
       "         [-0.1188],\n",
       "         [-0.1185],\n",
       "         [-0.1182],\n",
       "         [-0.1179],\n",
       "         [-0.1176],\n",
       "         [-0.1173],\n",
       "         [-0.1170],\n",
       "         [-0.1167],\n",
       "         [-0.1163],\n",
       "         [-0.1160],\n",
       "         [-0.1157],\n",
       "         [-0.1154],\n",
       "         [-0.1151],\n",
       "         [-0.1148],\n",
       "         [-0.1145],\n",
       "         [-0.1142],\n",
       "         [-0.1139],\n",
       "         [-0.1136],\n",
       "         [-0.1133],\n",
       "         [-0.1130],\n",
       "         [-0.1127],\n",
       "         [-0.1124],\n",
       "         [-0.1120],\n",
       "         [-0.1117],\n",
       "         [-0.1114],\n",
       "         [-0.1111],\n",
       "         [-0.1108],\n",
       "         [-0.1105],\n",
       "         [-0.1102],\n",
       "         [-0.1099],\n",
       "         [-0.1096],\n",
       "         [-0.1093],\n",
       "         [-0.1089],\n",
       "         [-0.1086],\n",
       "         [-0.1083],\n",
       "         [-0.1080],\n",
       "         [-0.1077],\n",
       "         [-0.1074],\n",
       "         [-0.1071],\n",
       "         [-0.1068],\n",
       "         [-0.1065],\n",
       "         [-0.1061],\n",
       "         [-0.1058],\n",
       "         [-0.1055],\n",
       "         [-0.1052],\n",
       "         [-0.1049],\n",
       "         [-0.1046],\n",
       "         [-0.1043],\n",
       "         [-0.1040],\n",
       "         [-0.1036],\n",
       "         [-0.1033],\n",
       "         [-0.1030],\n",
       "         [-0.1027],\n",
       "         [-0.1024],\n",
       "         [-0.1021],\n",
       "         [-0.1017],\n",
       "         [-0.1014],\n",
       "         [-0.1011],\n",
       "         [-0.1008],\n",
       "         [-0.1005],\n",
       "         [-0.1002],\n",
       "         [-0.0999],\n",
       "         [-0.0995],\n",
       "         [-0.0992],\n",
       "         [-0.0989],\n",
       "         [-0.0986],\n",
       "         [-0.0983],\n",
       "         [-0.0979],\n",
       "         [-0.0976],\n",
       "         [-0.0973],\n",
       "         [-0.0970],\n",
       "         [-0.0967],\n",
       "         [-0.0964],\n",
       "         [-0.0960],\n",
       "         [-0.0957],\n",
       "         [-0.0954],\n",
       "         [-0.0951],\n",
       "         [-0.0948],\n",
       "         [-0.0944],\n",
       "         [-0.0941],\n",
       "         [-0.0938],\n",
       "         [-0.0935],\n",
       "         [-0.0932],\n",
       "         [-0.0928],\n",
       "         [-0.0925],\n",
       "         [-0.0922],\n",
       "         [-0.0919],\n",
       "         [-0.0915],\n",
       "         [-0.0912],\n",
       "         [-0.0909],\n",
       "         [-0.0906],\n",
       "         [-0.0902],\n",
       "         [-0.0899],\n",
       "         [-0.0896],\n",
       "         [-0.0893],\n",
       "         [-0.0890],\n",
       "         [-0.0886],\n",
       "         [-0.0883],\n",
       "         [-0.0880],\n",
       "         [-0.0877]]),\n",
       " tensor([[-0.0873],\n",
       "         [-0.0870],\n",
       "         [-0.0867],\n",
       "         [-0.0863],\n",
       "         [-0.0860],\n",
       "         [-0.0857],\n",
       "         [-0.0854],\n",
       "         [-0.0850],\n",
       "         [-0.0847],\n",
       "         [-0.0844],\n",
       "         [-0.0841],\n",
       "         [-0.0837],\n",
       "         [-0.0834],\n",
       "         [-0.0831],\n",
       "         [-0.0827],\n",
       "         [-0.0824],\n",
       "         [-0.0821],\n",
       "         [-0.0818],\n",
       "         [-0.0814],\n",
       "         [-0.0811],\n",
       "         [-0.0808],\n",
       "         [-0.0804],\n",
       "         [-0.0801],\n",
       "         [-0.0798],\n",
       "         [-0.0794],\n",
       "         [-0.0791],\n",
       "         [-0.0788],\n",
       "         [-0.0784],\n",
       "         [-0.0781],\n",
       "         [-0.0778],\n",
       "         [-0.0774],\n",
       "         [-0.0771],\n",
       "         [-0.0768],\n",
       "         [-0.0764],\n",
       "         [-0.0761],\n",
       "         [-0.0758],\n",
       "         [-0.0754],\n",
       "         [-0.0751],\n",
       "         [-0.0748],\n",
       "         [-0.0744],\n",
       "         [-0.0741],\n",
       "         [-0.0738],\n",
       "         [-0.0734],\n",
       "         [-0.0731],\n",
       "         [-0.0727],\n",
       "         [-0.0724],\n",
       "         [-0.0721],\n",
       "         [-0.0717],\n",
       "         [-0.0714],\n",
       "         [-0.0710],\n",
       "         [-0.0707],\n",
       "         [-0.0704],\n",
       "         [-0.0700],\n",
       "         [-0.0697],\n",
       "         [-0.0694],\n",
       "         [-0.0690],\n",
       "         [-0.0687],\n",
       "         [-0.0683],\n",
       "         [-0.0680],\n",
       "         [-0.0676],\n",
       "         [-0.0673],\n",
       "         [-0.0670],\n",
       "         [-0.0666],\n",
       "         [-0.0663],\n",
       "         [-0.0659],\n",
       "         [-0.0656],\n",
       "         [-0.0652],\n",
       "         [-0.0649],\n",
       "         [-0.0646],\n",
       "         [-0.0642],\n",
       "         [-0.0639],\n",
       "         [-0.0635],\n",
       "         [-0.0632],\n",
       "         [-0.0628],\n",
       "         [-0.0625],\n",
       "         [-0.0621],\n",
       "         [-0.0618],\n",
       "         [-0.0614],\n",
       "         [-0.0611],\n",
       "         [-0.0608],\n",
       "         [-0.0604],\n",
       "         [-0.0601],\n",
       "         [-0.0597],\n",
       "         [-0.0594],\n",
       "         [-0.0590],\n",
       "         [-0.0587],\n",
       "         [-0.0583],\n",
       "         [-0.0580],\n",
       "         [-0.0576],\n",
       "         [-0.0573],\n",
       "         [-0.0569],\n",
       "         [-0.0566],\n",
       "         [-0.0562],\n",
       "         [-0.0559],\n",
       "         [-0.0555],\n",
       "         [-0.0551],\n",
       "         [-0.0548],\n",
       "         [-0.0544],\n",
       "         [-0.0541],\n",
       "         [-0.0537],\n",
       "         [-0.0534],\n",
       "         [-0.0530],\n",
       "         [-0.0527],\n",
       "         [-0.0523],\n",
       "         [-0.0520],\n",
       "         [-0.0516],\n",
       "         [-0.0513],\n",
       "         [-0.0509],\n",
       "         [-0.0505],\n",
       "         [-0.0502],\n",
       "         [-0.0498],\n",
       "         [-0.0495],\n",
       "         [-0.0491],\n",
       "         [-0.0487],\n",
       "         [-0.0484],\n",
       "         [-0.0480],\n",
       "         [-0.0477],\n",
       "         [-0.0473],\n",
       "         [-0.0470],\n",
       "         [-0.0466],\n",
       "         [-0.0462],\n",
       "         [-0.0459],\n",
       "         [-0.0455],\n",
       "         [-0.0451],\n",
       "         [-0.0448],\n",
       "         [-0.0444],\n",
       "         [-0.0441],\n",
       "         [-0.0437]]),\n",
       " tensor([[-0.0433],\n",
       "         [-0.0430],\n",
       "         [-0.0426],\n",
       "         [-0.0422],\n",
       "         [-0.0419],\n",
       "         [-0.0415],\n",
       "         [-0.0412],\n",
       "         [-0.0408],\n",
       "         [-0.0404],\n",
       "         [-0.0401],\n",
       "         [-0.0397],\n",
       "         [-0.0393],\n",
       "         [-0.0390],\n",
       "         [-0.0386],\n",
       "         [-0.0382],\n",
       "         [-0.0379],\n",
       "         [-0.0375],\n",
       "         [-0.0371],\n",
       "         [-0.0367],\n",
       "         [-0.0364],\n",
       "         [-0.0360],\n",
       "         [-0.0356],\n",
       "         [-0.0353],\n",
       "         [-0.0349],\n",
       "         [-0.0345],\n",
       "         [-0.0341],\n",
       "         [-0.0338],\n",
       "         [-0.0334],\n",
       "         [-0.0330],\n",
       "         [-0.0327],\n",
       "         [-0.0323],\n",
       "         [-0.0319],\n",
       "         [-0.0315],\n",
       "         [-0.0312],\n",
       "         [-0.0308],\n",
       "         [-0.0304],\n",
       "         [-0.0300],\n",
       "         [-0.0297],\n",
       "         [-0.0293],\n",
       "         [-0.0289],\n",
       "         [-0.0285],\n",
       "         [-0.0282],\n",
       "         [-0.0278],\n",
       "         [-0.0274],\n",
       "         [-0.0270],\n",
       "         [-0.0266],\n",
       "         [-0.0263],\n",
       "         [-0.0259],\n",
       "         [-0.0255],\n",
       "         [-0.0251],\n",
       "         [-0.0247],\n",
       "         [-0.0244],\n",
       "         [-0.0240],\n",
       "         [-0.0236],\n",
       "         [-0.0232],\n",
       "         [-0.0228],\n",
       "         [-0.0225],\n",
       "         [-0.0221],\n",
       "         [-0.0217],\n",
       "         [-0.0213],\n",
       "         [-0.0209],\n",
       "         [-0.0205],\n",
       "         [-0.0201],\n",
       "         [-0.0198],\n",
       "         [-0.0194],\n",
       "         [-0.0190],\n",
       "         [-0.0186],\n",
       "         [-0.0182],\n",
       "         [-0.0178],\n",
       "         [-0.0174],\n",
       "         [-0.0170],\n",
       "         [-0.0167],\n",
       "         [-0.0163],\n",
       "         [-0.0161],\n",
       "         [-0.0159],\n",
       "         [-0.0156],\n",
       "         [-0.0154],\n",
       "         [-0.0151],\n",
       "         [-0.0149],\n",
       "         [-0.0146],\n",
       "         [-0.0144],\n",
       "         [-0.0142],\n",
       "         [-0.0139],\n",
       "         [-0.0137],\n",
       "         [-0.0134],\n",
       "         [-0.0132],\n",
       "         [-0.0129],\n",
       "         [-0.0127],\n",
       "         [-0.0124],\n",
       "         [-0.0122],\n",
       "         [-0.0119],\n",
       "         [-0.0117],\n",
       "         [-0.0114],\n",
       "         [-0.0112],\n",
       "         [-0.0110],\n",
       "         [-0.0107],\n",
       "         [-0.0105],\n",
       "         [-0.0102],\n",
       "         [-0.0100],\n",
       "         [-0.0097],\n",
       "         [-0.0095],\n",
       "         [-0.0092],\n",
       "         [-0.0090],\n",
       "         [-0.0087],\n",
       "         [-0.0085],\n",
       "         [-0.0082],\n",
       "         [-0.0080],\n",
       "         [-0.0077],\n",
       "         [-0.0075],\n",
       "         [-0.0072],\n",
       "         [-0.0070],\n",
       "         [-0.0067],\n",
       "         [-0.0065],\n",
       "         [-0.0062],\n",
       "         [-0.0059],\n",
       "         [-0.0057],\n",
       "         [-0.0054],\n",
       "         [-0.0052],\n",
       "         [-0.0049],\n",
       "         [-0.0047],\n",
       "         [-0.0044],\n",
       "         [-0.0042],\n",
       "         [-0.0039],\n",
       "         [-0.0037],\n",
       "         [-0.0034],\n",
       "         [-0.0031],\n",
       "         [-0.0029],\n",
       "         [-0.0026]]),\n",
       " tensor([[-2.3775e-03],\n",
       "         [-2.1206e-03],\n",
       "         [-1.8634e-03],\n",
       "         [-1.6059e-03],\n",
       "         [-1.3480e-03],\n",
       "         [-1.0901e-03],\n",
       "         [-8.3175e-04],\n",
       "         [-5.7316e-04],\n",
       "         [-3.1418e-04],\n",
       "         [-5.5075e-05],\n",
       "         [ 2.0432e-04],\n",
       "         [ 4.6417e-04],\n",
       "         [ 7.2399e-04],\n",
       "         [ 9.8431e-04],\n",
       "         [ 1.2449e-03],\n",
       "         [ 1.5056e-03],\n",
       "         [ 1.7667e-03],\n",
       "         [ 2.0282e-03],\n",
       "         [ 2.2896e-03],\n",
       "         [ 2.5516e-03],\n",
       "         [ 2.8136e-03],\n",
       "         [ 3.0760e-03],\n",
       "         [ 3.3387e-03],\n",
       "         [ 3.6017e-03],\n",
       "         [ 3.8650e-03],\n",
       "         [ 4.1283e-03],\n",
       "         [ 4.3920e-03],\n",
       "         [ 4.6562e-03],\n",
       "         [ 4.9207e-03],\n",
       "         [ 5.1853e-03],\n",
       "         [ 5.4500e-03],\n",
       "         [ 5.7151e-03],\n",
       "         [ 5.9807e-03],\n",
       "         [ 6.2463e-03],\n",
       "         [ 6.5123e-03],\n",
       "         [ 6.7783e-03],\n",
       "         [ 7.0451e-03],\n",
       "         [ 7.3118e-03],\n",
       "         [ 7.5788e-03],\n",
       "         [ 7.8463e-03],\n",
       "         [ 8.1138e-03],\n",
       "         [ 8.3818e-03],\n",
       "         [ 8.6499e-03],\n",
       "         [ 8.9185e-03],\n",
       "         [ 9.1872e-03],\n",
       "         [ 9.4563e-03],\n",
       "         [ 9.7254e-03],\n",
       "         [ 9.9951e-03],\n",
       "         [ 1.0265e-02],\n",
       "         [ 1.0535e-02],\n",
       "         [ 1.0805e-02],\n",
       "         [ 1.1076e-02],\n",
       "         [ 1.1347e-02],\n",
       "         [ 1.1618e-02],\n",
       "         [ 1.1890e-02],\n",
       "         [ 1.2162e-02],\n",
       "         [ 1.2434e-02],\n",
       "         [ 1.2706e-02],\n",
       "         [ 1.2978e-02],\n",
       "         [ 1.3251e-02],\n",
       "         [ 1.3525e-02],\n",
       "         [ 1.3798e-02],\n",
       "         [ 1.4072e-02],\n",
       "         [ 1.4346e-02],\n",
       "         [ 1.4620e-02],\n",
       "         [ 1.4895e-02],\n",
       "         [ 1.5170e-02],\n",
       "         [ 1.5445e-02],\n",
       "         [ 1.5720e-02],\n",
       "         [ 1.5996e-02],\n",
       "         [ 1.6272e-02],\n",
       "         [ 1.6548e-02],\n",
       "         [ 1.6824e-02],\n",
       "         [ 1.7101e-02],\n",
       "         [ 1.7378e-02],\n",
       "         [ 1.7655e-02],\n",
       "         [ 1.7933e-02],\n",
       "         [ 1.8210e-02],\n",
       "         [ 1.8488e-02],\n",
       "         [ 1.8767e-02],\n",
       "         [ 1.9045e-02],\n",
       "         [ 1.9324e-02],\n",
       "         [ 1.9603e-02],\n",
       "         [ 1.9882e-02],\n",
       "         [ 2.0162e-02],\n",
       "         [ 2.0442e-02],\n",
       "         [ 2.0723e-02],\n",
       "         [ 2.1003e-02],\n",
       "         [ 2.1284e-02],\n",
       "         [ 2.1565e-02],\n",
       "         [ 2.1847e-02],\n",
       "         [ 2.2128e-02],\n",
       "         [ 2.2410e-02],\n",
       "         [ 2.2692e-02],\n",
       "         [ 2.2975e-02],\n",
       "         [ 2.3258e-02],\n",
       "         [ 2.3541e-02],\n",
       "         [ 2.3825e-02],\n",
       "         [ 2.4108e-02],\n",
       "         [ 2.4392e-02],\n",
       "         [ 2.4676e-02],\n",
       "         [ 2.4960e-02],\n",
       "         [ 2.5245e-02],\n",
       "         [ 2.5530e-02],\n",
       "         [ 2.5815e-02],\n",
       "         [ 2.6101e-02],\n",
       "         [ 2.6387e-02],\n",
       "         [ 2.6673e-02],\n",
       "         [ 2.6959e-02],\n",
       "         [ 2.7246e-02],\n",
       "         [ 2.7532e-02],\n",
       "         [ 2.7820e-02],\n",
       "         [ 2.8107e-02],\n",
       "         [ 2.8395e-02],\n",
       "         [ 2.8683e-02],\n",
       "         [ 2.8971e-02],\n",
       "         [ 2.9260e-02],\n",
       "         [ 2.9548e-02],\n",
       "         [ 2.9838e-02],\n",
       "         [ 3.0127e-02],\n",
       "         [ 3.0417e-02],\n",
       "         [ 3.0707e-02],\n",
       "         [ 3.0997e-02],\n",
       "         [ 3.1288e-02],\n",
       "         [ 3.1578e-02],\n",
       "         [ 3.1870e-02],\n",
       "         [ 3.2161e-02],\n",
       "         [ 3.2452e-02]]),\n",
       " tensor([[0.0327],\n",
       "         [0.0330],\n",
       "         [0.0333],\n",
       "         [0.0336],\n",
       "         [0.0339],\n",
       "         [0.0342],\n",
       "         [0.0345],\n",
       "         [0.0348],\n",
       "         [0.0351],\n",
       "         [0.0354],\n",
       "         [0.0357],\n",
       "         [0.0360],\n",
       "         [0.0363],\n",
       "         [0.0366],\n",
       "         [0.0369],\n",
       "         [0.0372],\n",
       "         [0.0375],\n",
       "         [0.0377],\n",
       "         [0.0380],\n",
       "         [0.0383],\n",
       "         [0.0386],\n",
       "         [0.0389],\n",
       "         [0.0392],\n",
       "         [0.0395],\n",
       "         [0.0398],\n",
       "         [0.0401],\n",
       "         [0.0404],\n",
       "         [0.0407],\n",
       "         [0.0410],\n",
       "         [0.0413],\n",
       "         [0.0416],\n",
       "         [0.0419],\n",
       "         [0.0422],\n",
       "         [0.0425],\n",
       "         [0.0428],\n",
       "         [0.0431],\n",
       "         [0.0434],\n",
       "         [0.0437],\n",
       "         [0.0440],\n",
       "         [0.0443],\n",
       "         [0.0446],\n",
       "         [0.0449],\n",
       "         [0.0452],\n",
       "         [0.0456],\n",
       "         [0.0459],\n",
       "         [0.0462],\n",
       "         [0.0465],\n",
       "         [0.0468],\n",
       "         [0.0471],\n",
       "         [0.0474],\n",
       "         [0.0477],\n",
       "         [0.0480],\n",
       "         [0.0483],\n",
       "         [0.0486],\n",
       "         [0.0489],\n",
       "         [0.0492],\n",
       "         [0.0495],\n",
       "         [0.0498],\n",
       "         [0.0501],\n",
       "         [0.0504],\n",
       "         [0.0508],\n",
       "         [0.0511],\n",
       "         [0.0514],\n",
       "         [0.0517],\n",
       "         [0.0520],\n",
       "         [0.0523],\n",
       "         [0.0526],\n",
       "         [0.0529],\n",
       "         [0.0532],\n",
       "         [0.0535],\n",
       "         [0.0538],\n",
       "         [0.0542],\n",
       "         [0.0545],\n",
       "         [0.0548],\n",
       "         [0.0551],\n",
       "         [0.0554],\n",
       "         [0.0557],\n",
       "         [0.0560],\n",
       "         [0.0563],\n",
       "         [0.0567],\n",
       "         [0.0570],\n",
       "         [0.0573],\n",
       "         [0.0576],\n",
       "         [0.0579],\n",
       "         [0.0582],\n",
       "         [0.0585],\n",
       "         [0.0588],\n",
       "         [0.0592],\n",
       "         [0.0595],\n",
       "         [0.0598],\n",
       "         [0.0601],\n",
       "         [0.0604],\n",
       "         [0.0607],\n",
       "         [0.0611],\n",
       "         [0.0614],\n",
       "         [0.0617],\n",
       "         [0.0620],\n",
       "         [0.0623],\n",
       "         [0.0626],\n",
       "         [0.0630],\n",
       "         [0.0633],\n",
       "         [0.0636],\n",
       "         [0.0639],\n",
       "         [0.0642],\n",
       "         [0.0646],\n",
       "         [0.0649],\n",
       "         [0.0652],\n",
       "         [0.0655],\n",
       "         [0.0658],\n",
       "         [0.0662],\n",
       "         [0.0665],\n",
       "         [0.0668],\n",
       "         [0.0671],\n",
       "         [0.0674],\n",
       "         [0.0678],\n",
       "         [0.0681],\n",
       "         [0.0684],\n",
       "         [0.0687],\n",
       "         [0.0691],\n",
       "         [0.0694],\n",
       "         [0.0697],\n",
       "         [0.0700],\n",
       "         [0.0703],\n",
       "         [0.0707],\n",
       "         [0.0710],\n",
       "         [0.0713],\n",
       "         [0.0716],\n",
       "         [0.0720]]),\n",
       " tensor([[0.0723],\n",
       "         [0.0726],\n",
       "         [0.0729],\n",
       "         [0.0733],\n",
       "         [0.0736],\n",
       "         [0.0739],\n",
       "         [0.0743],\n",
       "         [0.0746],\n",
       "         [0.0749],\n",
       "         [0.0752],\n",
       "         [0.0756],\n",
       "         [0.0759],\n",
       "         [0.0762],\n",
       "         [0.0766],\n",
       "         [0.0769],\n",
       "         [0.0772],\n",
       "         [0.0775],\n",
       "         [0.0779],\n",
       "         [0.0782],\n",
       "         [0.0785],\n",
       "         [0.0789],\n",
       "         [0.0792],\n",
       "         [0.0795],\n",
       "         [0.0799],\n",
       "         [0.0802],\n",
       "         [0.0805],\n",
       "         [0.0809],\n",
       "         [0.0812],\n",
       "         [0.0815],\n",
       "         [0.0819],\n",
       "         [0.0822],\n",
       "         [0.0825],\n",
       "         [0.0829],\n",
       "         [0.0832],\n",
       "         [0.0835],\n",
       "         [0.0839],\n",
       "         [0.0842],\n",
       "         [0.0845],\n",
       "         [0.0849],\n",
       "         [0.0852],\n",
       "         [0.0855],\n",
       "         [0.0859],\n",
       "         [0.0862],\n",
       "         [0.0865],\n",
       "         [0.0869],\n",
       "         [0.0872],\n",
       "         [0.0876],\n",
       "         [0.0879],\n",
       "         [0.0882],\n",
       "         [0.0886],\n",
       "         [0.0889],\n",
       "         [0.0893],\n",
       "         [0.0896],\n",
       "         [0.0899],\n",
       "         [0.0903],\n",
       "         [0.0906],\n",
       "         [0.0910],\n",
       "         [0.0913],\n",
       "         [0.0916],\n",
       "         [0.0920],\n",
       "         [0.0923],\n",
       "         [0.0927],\n",
       "         [0.0930],\n",
       "         [0.0933],\n",
       "         [0.0937],\n",
       "         [0.0940],\n",
       "         [0.0944],\n",
       "         [0.0947],\n",
       "         [0.0951],\n",
       "         [0.0954],\n",
       "         [0.0958],\n",
       "         [0.0961],\n",
       "         [0.0964],\n",
       "         [0.0968],\n",
       "         [0.0971],\n",
       "         [0.0975],\n",
       "         [0.0978],\n",
       "         [0.0982],\n",
       "         [0.0985],\n",
       "         [0.0989],\n",
       "         [0.0992],\n",
       "         [0.0996],\n",
       "         [0.0999],\n",
       "         [0.1003],\n",
       "         [0.1006],\n",
       "         [0.1010],\n",
       "         [0.1013],\n",
       "         [0.1016],\n",
       "         [0.1020],\n",
       "         [0.1023],\n",
       "         [0.1027],\n",
       "         [0.1030],\n",
       "         [0.1034],\n",
       "         [0.1037],\n",
       "         [0.1041],\n",
       "         [0.1045],\n",
       "         [0.1048],\n",
       "         [0.1052],\n",
       "         [0.1055],\n",
       "         [0.1059],\n",
       "         [0.1062],\n",
       "         [0.1066],\n",
       "         [0.1069],\n",
       "         [0.1073],\n",
       "         [0.1076],\n",
       "         [0.1080],\n",
       "         [0.1083],\n",
       "         [0.1087],\n",
       "         [0.1090],\n",
       "         [0.1094],\n",
       "         [0.1098],\n",
       "         [0.1101],\n",
       "         [0.1105],\n",
       "         [0.1108],\n",
       "         [0.1112],\n",
       "         [0.1115],\n",
       "         [0.1119],\n",
       "         [0.1122],\n",
       "         [0.1126],\n",
       "         [0.1130],\n",
       "         [0.1133],\n",
       "         [0.1137],\n",
       "         [0.1140],\n",
       "         [0.1144],\n",
       "         [0.1148],\n",
       "         [0.1151],\n",
       "         [0.1155],\n",
       "         [0.1158]]),\n",
       " tensor([[0.1162],\n",
       "         [0.1166],\n",
       "         [0.1169],\n",
       "         [0.1173],\n",
       "         [0.1176],\n",
       "         [0.1180],\n",
       "         [0.1184],\n",
       "         [0.1187],\n",
       "         [0.1191],\n",
       "         [0.1194],\n",
       "         [0.1198],\n",
       "         [0.1202],\n",
       "         [0.1205],\n",
       "         [0.1209],\n",
       "         [0.1213],\n",
       "         [0.1216],\n",
       "         [0.1220],\n",
       "         [0.1224],\n",
       "         [0.1227],\n",
       "         [0.1231],\n",
       "         [0.1234],\n",
       "         [0.1238],\n",
       "         [0.1242],\n",
       "         [0.1245],\n",
       "         [0.1249],\n",
       "         [0.1253],\n",
       "         [0.1256],\n",
       "         [0.1260],\n",
       "         [0.1264],\n",
       "         [0.1267],\n",
       "         [0.1271],\n",
       "         [0.1275],\n",
       "         [0.1278],\n",
       "         [0.1282],\n",
       "         [0.1286],\n",
       "         [0.1290],\n",
       "         [0.1293],\n",
       "         [0.1297],\n",
       "         [0.1301],\n",
       "         [0.1304],\n",
       "         [0.1308],\n",
       "         [0.1312],\n",
       "         [0.1315],\n",
       "         [0.1319],\n",
       "         [0.1323],\n",
       "         [0.1327],\n",
       "         [0.1330],\n",
       "         [0.1334],\n",
       "         [0.1338],\n",
       "         [0.1341],\n",
       "         [0.1345],\n",
       "         [0.1349],\n",
       "         [0.1353],\n",
       "         [0.1356],\n",
       "         [0.1360],\n",
       "         [0.1364],\n",
       "         [0.1368],\n",
       "         [0.1371],\n",
       "         [0.1375],\n",
       "         [0.1379],\n",
       "         [0.1383],\n",
       "         [0.1386],\n",
       "         [0.1390],\n",
       "         [0.1394],\n",
       "         [0.1398],\n",
       "         [0.1401],\n",
       "         [0.1405],\n",
       "         [0.1409],\n",
       "         [0.1413],\n",
       "         [0.1416],\n",
       "         [0.1420],\n",
       "         [0.1424],\n",
       "         [0.1428],\n",
       "         [0.1432],\n",
       "         [0.1435],\n",
       "         [0.1439],\n",
       "         [0.1443],\n",
       "         [0.1447],\n",
       "         [0.1451],\n",
       "         [0.1454],\n",
       "         [0.1458],\n",
       "         [0.1462],\n",
       "         [0.1466],\n",
       "         [0.1470],\n",
       "         [0.1473],\n",
       "         [0.1477],\n",
       "         [0.1481],\n",
       "         [0.1485],\n",
       "         [0.1489],\n",
       "         [0.1492],\n",
       "         [0.1496],\n",
       "         [0.1500],\n",
       "         [0.1504],\n",
       "         [0.1508],\n",
       "         [0.1512],\n",
       "         [0.1515],\n",
       "         [0.1519],\n",
       "         [0.1523],\n",
       "         [0.1527],\n",
       "         [0.1531],\n",
       "         [0.1535],\n",
       "         [0.1538],\n",
       "         [0.1542],\n",
       "         [0.1546],\n",
       "         [0.1550],\n",
       "         [0.1554],\n",
       "         [0.1558],\n",
       "         [0.1562],\n",
       "         [0.1565],\n",
       "         [0.1569],\n",
       "         [0.1573],\n",
       "         [0.1577],\n",
       "         [0.1581],\n",
       "         [0.1585],\n",
       "         [0.1589],\n",
       "         [0.1593],\n",
       "         [0.1596],\n",
       "         [0.1600],\n",
       "         [0.1604],\n",
       "         [0.1608],\n",
       "         [0.1612],\n",
       "         [0.1616],\n",
       "         [0.1620],\n",
       "         [0.1624],\n",
       "         [0.1628],\n",
       "         [0.1631],\n",
       "         [0.1635],\n",
       "         [0.1639]]),\n",
       " tensor([[0.1643],\n",
       "         [0.1647],\n",
       "         [0.1651],\n",
       "         [0.1655],\n",
       "         [0.1659],\n",
       "         [0.1663],\n",
       "         [0.1667],\n",
       "         [0.1671],\n",
       "         [0.1675],\n",
       "         [0.1678],\n",
       "         [0.1682],\n",
       "         [0.1686],\n",
       "         [0.1690],\n",
       "         [0.1694],\n",
       "         [0.1698],\n",
       "         [0.1702],\n",
       "         [0.1706],\n",
       "         [0.1710],\n",
       "         [0.1714],\n",
       "         [0.1718],\n",
       "         [0.1722],\n",
       "         [0.1726],\n",
       "         [0.1730],\n",
       "         [0.1734],\n",
       "         [0.1738],\n",
       "         [0.1742],\n",
       "         [0.1746],\n",
       "         [0.1750],\n",
       "         [0.1753],\n",
       "         [0.1757],\n",
       "         [0.1761],\n",
       "         [0.1765],\n",
       "         [0.1769],\n",
       "         [0.1773],\n",
       "         [0.1777],\n",
       "         [0.1781],\n",
       "         [0.1785],\n",
       "         [0.1789],\n",
       "         [0.1793],\n",
       "         [0.1797],\n",
       "         [0.1801],\n",
       "         [0.1805],\n",
       "         [0.1809],\n",
       "         [0.1813],\n",
       "         [0.1817],\n",
       "         [0.1821],\n",
       "         [0.1825],\n",
       "         [0.1829],\n",
       "         [0.1833],\n",
       "         [0.1837],\n",
       "         [0.1841],\n",
       "         [0.1845],\n",
       "         [0.1849],\n",
       "         [0.1853],\n",
       "         [0.1857],\n",
       "         [0.1861],\n",
       "         [0.1865],\n",
       "         [0.1870],\n",
       "         [0.1874],\n",
       "         [0.1878],\n",
       "         [0.1882],\n",
       "         [0.1886],\n",
       "         [0.1890],\n",
       "         [0.1894],\n",
       "         [0.1898],\n",
       "         [0.1902],\n",
       "         [0.1906],\n",
       "         [0.1910],\n",
       "         [0.1914],\n",
       "         [0.1918],\n",
       "         [0.1922],\n",
       "         [0.1926],\n",
       "         [0.1930],\n",
       "         [0.1934],\n",
       "         [0.1938],\n",
       "         [0.1942],\n",
       "         [0.1947],\n",
       "         [0.1951],\n",
       "         [0.1955],\n",
       "         [0.1959],\n",
       "         [0.1963],\n",
       "         [0.1967],\n",
       "         [0.1971],\n",
       "         [0.1975],\n",
       "         [0.1979],\n",
       "         [0.1983],\n",
       "         [0.1987],\n",
       "         [0.1992],\n",
       "         [0.1996],\n",
       "         [0.2000],\n",
       "         [0.2004],\n",
       "         [0.2008],\n",
       "         [0.2012],\n",
       "         [0.2016],\n",
       "         [0.2020],\n",
       "         [0.2024],\n",
       "         [0.2028],\n",
       "         [0.2033],\n",
       "         [0.2037],\n",
       "         [0.2041],\n",
       "         [0.2045],\n",
       "         [0.2049],\n",
       "         [0.2053],\n",
       "         [0.2057],\n",
       "         [0.2062],\n",
       "         [0.2066],\n",
       "         [0.2070],\n",
       "         [0.2074],\n",
       "         [0.2078],\n",
       "         [0.2082],\n",
       "         [0.2086],\n",
       "         [0.2091],\n",
       "         [0.2095],\n",
       "         [0.2099],\n",
       "         [0.2103],\n",
       "         [0.2107],\n",
       "         [0.2111],\n",
       "         [0.2116],\n",
       "         [0.2120],\n",
       "         [0.2124],\n",
       "         [0.2128],\n",
       "         [0.2132],\n",
       "         [0.2136],\n",
       "         [0.2141],\n",
       "         [0.2145],\n",
       "         [0.2149],\n",
       "         [0.2153],\n",
       "         [0.2157]]),\n",
       " tensor([[0.2161],\n",
       "         [0.2166],\n",
       "         [0.2170],\n",
       "         [0.2174],\n",
       "         [0.2178],\n",
       "         [0.2182],\n",
       "         [0.2187],\n",
       "         [0.2191],\n",
       "         [0.2195],\n",
       "         [0.2199],\n",
       "         [0.2203],\n",
       "         [0.2208],\n",
       "         [0.2212],\n",
       "         [0.2216],\n",
       "         [0.2220],\n",
       "         [0.2225],\n",
       "         [0.2229],\n",
       "         [0.2233],\n",
       "         [0.2237],\n",
       "         [0.2242],\n",
       "         [0.2246],\n",
       "         [0.2250],\n",
       "         [0.2254],\n",
       "         [0.2259],\n",
       "         [0.2263],\n",
       "         [0.2267],\n",
       "         [0.2271],\n",
       "         [0.2276],\n",
       "         [0.2280],\n",
       "         [0.2284],\n",
       "         [0.2288],\n",
       "         [0.2293],\n",
       "         [0.2297],\n",
       "         [0.2301],\n",
       "         [0.2305],\n",
       "         [0.2310],\n",
       "         [0.2314],\n",
       "         [0.2318],\n",
       "         [0.2322],\n",
       "         [0.2327],\n",
       "         [0.2331],\n",
       "         [0.2335],\n",
       "         [0.2340],\n",
       "         [0.2344],\n",
       "         [0.2348],\n",
       "         [0.2352],\n",
       "         [0.2357],\n",
       "         [0.2361],\n",
       "         [0.2365],\n",
       "         [0.2370],\n",
       "         [0.2374],\n",
       "         [0.2378],\n",
       "         [0.2383],\n",
       "         [0.2387],\n",
       "         [0.2391],\n",
       "         [0.2396],\n",
       "         [0.2400],\n",
       "         [0.2404],\n",
       "         [0.2409],\n",
       "         [0.2413],\n",
       "         [0.2417],\n",
       "         [0.2422],\n",
       "         [0.2426],\n",
       "         [0.2430],\n",
       "         [0.2435],\n",
       "         [0.2439],\n",
       "         [0.2443],\n",
       "         [0.2448],\n",
       "         [0.2452],\n",
       "         [0.2456],\n",
       "         [0.2461],\n",
       "         [0.2465],\n",
       "         [0.2469],\n",
       "         [0.2474],\n",
       "         [0.2478],\n",
       "         [0.2483],\n",
       "         [0.2487],\n",
       "         [0.2491],\n",
       "         [0.2496],\n",
       "         [0.2500],\n",
       "         [0.2504],\n",
       "         [0.2509],\n",
       "         [0.2513],\n",
       "         [0.2518],\n",
       "         [0.2522],\n",
       "         [0.2527],\n",
       "         [0.2531],\n",
       "         [0.2535],\n",
       "         [0.2540],\n",
       "         [0.2544],\n",
       "         [0.2549],\n",
       "         [0.2553],\n",
       "         [0.2557],\n",
       "         [0.2562],\n",
       "         [0.2566],\n",
       "         [0.2571],\n",
       "         [0.2575],\n",
       "         [0.2580],\n",
       "         [0.2584],\n",
       "         [0.2588],\n",
       "         [0.2593],\n",
       "         [0.2597],\n",
       "         [0.2602],\n",
       "         [0.2606],\n",
       "         [0.2611],\n",
       "         [0.2615],\n",
       "         [0.2620],\n",
       "         [0.2624],\n",
       "         [0.2629],\n",
       "         [0.2633],\n",
       "         [0.2638],\n",
       "         [0.2642],\n",
       "         [0.2647],\n",
       "         [0.2651],\n",
       "         [0.2656],\n",
       "         [0.2660],\n",
       "         [0.2665],\n",
       "         [0.2669],\n",
       "         [0.2674],\n",
       "         [0.2678],\n",
       "         [0.2682],\n",
       "         [0.2686],\n",
       "         [0.2690],\n",
       "         [0.2694],\n",
       "         [0.2698],\n",
       "         [0.2702],\n",
       "         [0.2706],\n",
       "         [0.2710]]),\n",
       " tensor([[0.2714],\n",
       "         [0.2718],\n",
       "         [0.2722],\n",
       "         [0.2726],\n",
       "         [0.2730],\n",
       "         [0.2734],\n",
       "         [0.2738],\n",
       "         [0.2742],\n",
       "         [0.2746],\n",
       "         [0.2750],\n",
       "         [0.2754],\n",
       "         [0.2758],\n",
       "         [0.2762],\n",
       "         [0.2766],\n",
       "         [0.2770],\n",
       "         [0.2774],\n",
       "         [0.2778],\n",
       "         [0.2782],\n",
       "         [0.2786],\n",
       "         [0.2790],\n",
       "         [0.2795],\n",
       "         [0.2799],\n",
       "         [0.2803],\n",
       "         [0.2807],\n",
       "         [0.2811],\n",
       "         [0.2815],\n",
       "         [0.2819],\n",
       "         [0.2823],\n",
       "         [0.2827],\n",
       "         [0.2831],\n",
       "         [0.2835],\n",
       "         [0.2839],\n",
       "         [0.2843],\n",
       "         [0.2847],\n",
       "         [0.2851],\n",
       "         [0.2856],\n",
       "         [0.2860],\n",
       "         [0.2864],\n",
       "         [0.2868],\n",
       "         [0.2872],\n",
       "         [0.2876],\n",
       "         [0.2880],\n",
       "         [0.2884],\n",
       "         [0.2888],\n",
       "         [0.2892],\n",
       "         [0.2897],\n",
       "         [0.2901],\n",
       "         [0.2905],\n",
       "         [0.2909],\n",
       "         [0.2913],\n",
       "         [0.2917],\n",
       "         [0.2921],\n",
       "         [0.2925],\n",
       "         [0.2930],\n",
       "         [0.2934],\n",
       "         [0.2938],\n",
       "         [0.2942],\n",
       "         [0.2946],\n",
       "         [0.2950],\n",
       "         [0.2955],\n",
       "         [0.2959],\n",
       "         [0.2963],\n",
       "         [0.2967],\n",
       "         [0.2971],\n",
       "         [0.2975],\n",
       "         [0.2979],\n",
       "         [0.2984],\n",
       "         [0.2988],\n",
       "         [0.2992],\n",
       "         [0.2996],\n",
       "         [0.3000],\n",
       "         [0.3004],\n",
       "         [0.3009],\n",
       "         [0.3013],\n",
       "         [0.3017],\n",
       "         [0.3021],\n",
       "         [0.3025],\n",
       "         [0.3030],\n",
       "         [0.3034],\n",
       "         [0.3038],\n",
       "         [0.3042],\n",
       "         [0.3046],\n",
       "         [0.3051],\n",
       "         [0.3055],\n",
       "         [0.3059],\n",
       "         [0.3063],\n",
       "         [0.3067],\n",
       "         [0.3072],\n",
       "         [0.3076],\n",
       "         [0.3080],\n",
       "         [0.3084],\n",
       "         [0.3088],\n",
       "         [0.3093],\n",
       "         [0.3097],\n",
       "         [0.3101],\n",
       "         [0.3105],\n",
       "         [0.3110],\n",
       "         [0.3114],\n",
       "         [0.3118],\n",
       "         [0.3122],\n",
       "         [0.3126],\n",
       "         [0.3131],\n",
       "         [0.3135],\n",
       "         [0.3139],\n",
       "         [0.3143],\n",
       "         [0.3148],\n",
       "         [0.3152],\n",
       "         [0.3156],\n",
       "         [0.3160],\n",
       "         [0.3165],\n",
       "         [0.3169],\n",
       "         [0.3173],\n",
       "         [0.3177],\n",
       "         [0.3182],\n",
       "         [0.3186],\n",
       "         [0.3190],\n",
       "         [0.3194],\n",
       "         [0.3199],\n",
       "         [0.3203],\n",
       "         [0.3207],\n",
       "         [0.3211],\n",
       "         [0.3216],\n",
       "         [0.3220],\n",
       "         [0.3224],\n",
       "         [0.3228],\n",
       "         [0.3233],\n",
       "         [0.3237],\n",
       "         [0.3241]]),\n",
       " tensor([[0.3245],\n",
       "         [0.3250],\n",
       "         [0.3254],\n",
       "         [0.3258],\n",
       "         [0.3262],\n",
       "         [0.3267],\n",
       "         [0.3271],\n",
       "         [0.3275],\n",
       "         [0.3280],\n",
       "         [0.3284],\n",
       "         [0.3288],\n",
       "         [0.3292],\n",
       "         [0.3297],\n",
       "         [0.3301],\n",
       "         [0.3305],\n",
       "         [0.3309],\n",
       "         [0.3314],\n",
       "         [0.3318],\n",
       "         [0.3322],\n",
       "         [0.3327],\n",
       "         [0.3331],\n",
       "         [0.3335],\n",
       "         [0.3339],\n",
       "         [0.3344],\n",
       "         [0.3348],\n",
       "         [0.3352],\n",
       "         [0.3357],\n",
       "         [0.3361],\n",
       "         [0.3365],\n",
       "         [0.3370],\n",
       "         [0.3374],\n",
       "         [0.3378],\n",
       "         [0.3383],\n",
       "         [0.3387],\n",
       "         [0.3391],\n",
       "         [0.3395],\n",
       "         [0.3400],\n",
       "         [0.3404],\n",
       "         [0.3409],\n",
       "         [0.3413],\n",
       "         [0.3417],\n",
       "         [0.3422],\n",
       "         [0.3426],\n",
       "         [0.3430],\n",
       "         [0.3435],\n",
       "         [0.3439],\n",
       "         [0.3443],\n",
       "         [0.3448],\n",
       "         [0.3452],\n",
       "         [0.3456],\n",
       "         [0.3461],\n",
       "         [0.3465],\n",
       "         [0.3470],\n",
       "         [0.3474],\n",
       "         [0.3478],\n",
       "         [0.3483],\n",
       "         [0.3487],\n",
       "         [0.3492],\n",
       "         [0.3496],\n",
       "         [0.3500],\n",
       "         [0.3505],\n",
       "         [0.3509],\n",
       "         [0.3514],\n",
       "         [0.3518],\n",
       "         [0.3523],\n",
       "         [0.3527],\n",
       "         [0.3532],\n",
       "         [0.3536],\n",
       "         [0.3541],\n",
       "         [0.3545],\n",
       "         [0.3550],\n",
       "         [0.3554],\n",
       "         [0.3559],\n",
       "         [0.3563],\n",
       "         [0.3568],\n",
       "         [0.3572],\n",
       "         [0.3577],\n",
       "         [0.3581],\n",
       "         [0.3586],\n",
       "         [0.3590],\n",
       "         [0.3595],\n",
       "         [0.3599],\n",
       "         [0.3604],\n",
       "         [0.3608],\n",
       "         [0.3613],\n",
       "         [0.3618],\n",
       "         [0.3622],\n",
       "         [0.3627],\n",
       "         [0.3631],\n",
       "         [0.3636],\n",
       "         [0.3641],\n",
       "         [0.3645],\n",
       "         [0.3650],\n",
       "         [0.3655],\n",
       "         [0.3659],\n",
       "         [0.3664],\n",
       "         [0.3669],\n",
       "         [0.3673],\n",
       "         [0.3678],\n",
       "         [0.3683],\n",
       "         [0.3687],\n",
       "         [0.3692],\n",
       "         [0.3697],\n",
       "         [0.3701],\n",
       "         [0.3706],\n",
       "         [0.3711],\n",
       "         [0.3715],\n",
       "         [0.3720],\n",
       "         [0.3725],\n",
       "         [0.3730],\n",
       "         [0.3734],\n",
       "         [0.3739],\n",
       "         [0.3744],\n",
       "         [0.3749],\n",
       "         [0.3753],\n",
       "         [0.3758],\n",
       "         [0.3763],\n",
       "         [0.3768],\n",
       "         [0.3772],\n",
       "         [0.3777],\n",
       "         [0.3782],\n",
       "         [0.3787],\n",
       "         [0.3792],\n",
       "         [0.3796],\n",
       "         [0.3801],\n",
       "         [0.3806],\n",
       "         [0.3811],\n",
       "         [0.3816]]),\n",
       " tensor([[0.3821],\n",
       "         [0.3826],\n",
       "         [0.3831],\n",
       "         [0.3835],\n",
       "         [0.3840],\n",
       "         [0.3845],\n",
       "         [0.3850],\n",
       "         [0.3855],\n",
       "         [0.3860],\n",
       "         [0.3865],\n",
       "         [0.3870],\n",
       "         [0.3875],\n",
       "         [0.3880],\n",
       "         [0.3885],\n",
       "         [0.3890],\n",
       "         [0.3895],\n",
       "         [0.3900],\n",
       "         [0.3905],\n",
       "         [0.3910],\n",
       "         [0.3915],\n",
       "         [0.3920],\n",
       "         [0.3925],\n",
       "         [0.3930],\n",
       "         [0.3935],\n",
       "         [0.3940],\n",
       "         [0.3945],\n",
       "         [0.3950],\n",
       "         [0.3955],\n",
       "         [0.3960],\n",
       "         [0.3965],\n",
       "         [0.3970],\n",
       "         [0.3975],\n",
       "         [0.3980],\n",
       "         [0.3985],\n",
       "         [0.3990],\n",
       "         [0.3995],\n",
       "         [0.4000],\n",
       "         [0.4005],\n",
       "         [0.4010],\n",
       "         [0.4015],\n",
       "         [0.4020],\n",
       "         [0.4025],\n",
       "         [0.4030],\n",
       "         [0.4035],\n",
       "         [0.4040],\n",
       "         [0.4045],\n",
       "         [0.4050],\n",
       "         [0.4055],\n",
       "         [0.4060],\n",
       "         [0.4065],\n",
       "         [0.4071],\n",
       "         [0.4076],\n",
       "         [0.4081],\n",
       "         [0.4086],\n",
       "         [0.4091],\n",
       "         [0.4096],\n",
       "         [0.4101],\n",
       "         [0.4106],\n",
       "         [0.4111],\n",
       "         [0.4115],\n",
       "         [0.4120],\n",
       "         [0.4125],\n",
       "         [0.4130],\n",
       "         [0.4135],\n",
       "         [0.4140],\n",
       "         [0.4145],\n",
       "         [0.4150],\n",
       "         [0.4155],\n",
       "         [0.4160],\n",
       "         [0.4165],\n",
       "         [0.4170],\n",
       "         [0.4175],\n",
       "         [0.4180],\n",
       "         [0.4185],\n",
       "         [0.4190],\n",
       "         [0.4195],\n",
       "         [0.4200],\n",
       "         [0.4205],\n",
       "         [0.4210],\n",
       "         [0.4215],\n",
       "         [0.4220],\n",
       "         [0.4224],\n",
       "         [0.4229],\n",
       "         [0.4234],\n",
       "         [0.4239],\n",
       "         [0.4244],\n",
       "         [0.4249],\n",
       "         [0.4254],\n",
       "         [0.4258],\n",
       "         [0.4263],\n",
       "         [0.4268],\n",
       "         [0.4273],\n",
       "         [0.4278],\n",
       "         [0.4283],\n",
       "         [0.4288],\n",
       "         [0.4293],\n",
       "         [0.4297],\n",
       "         [0.4302],\n",
       "         [0.4307],\n",
       "         [0.4312],\n",
       "         [0.4317],\n",
       "         [0.4322],\n",
       "         [0.4327],\n",
       "         [0.4332],\n",
       "         [0.4337],\n",
       "         [0.4342],\n",
       "         [0.4347],\n",
       "         [0.4351],\n",
       "         [0.4356],\n",
       "         [0.4361],\n",
       "         [0.4366],\n",
       "         [0.4371],\n",
       "         [0.4376],\n",
       "         [0.4381],\n",
       "         [0.4386],\n",
       "         [0.4391],\n",
       "         [0.4396],\n",
       "         [0.4401],\n",
       "         [0.4406],\n",
       "         [0.4410],\n",
       "         [0.4415],\n",
       "         [0.4420],\n",
       "         [0.4425],\n",
       "         [0.4430],\n",
       "         [0.4435],\n",
       "         [0.4440],\n",
       "         [0.4445],\n",
       "         [0.4451]]),\n",
       " tensor([[0.4456],\n",
       "         [0.4461],\n",
       "         [0.4466],\n",
       "         [0.4471],\n",
       "         [0.4476],\n",
       "         [0.4481],\n",
       "         [0.4486],\n",
       "         [0.4491],\n",
       "         [0.4496],\n",
       "         [0.4501],\n",
       "         [0.4506],\n",
       "         [0.4511],\n",
       "         [0.4517],\n",
       "         [0.4522],\n",
       "         [0.4527],\n",
       "         [0.4532],\n",
       "         [0.4537],\n",
       "         [0.4542],\n",
       "         [0.4547],\n",
       "         [0.4552],\n",
       "         [0.4558],\n",
       "         [0.4563],\n",
       "         [0.4568],\n",
       "         [0.4573],\n",
       "         [0.4578],\n",
       "         [0.4584],\n",
       "         [0.4589],\n",
       "         [0.4594],\n",
       "         [0.4599],\n",
       "         [0.4605],\n",
       "         [0.4610],\n",
       "         [0.4615],\n",
       "         [0.4620],\n",
       "         [0.4626],\n",
       "         [0.4631],\n",
       "         [0.4636],\n",
       "         [0.4642],\n",
       "         [0.4647],\n",
       "         [0.4652],\n",
       "         [0.4658],\n",
       "         [0.4663],\n",
       "         [0.4668],\n",
       "         [0.4674],\n",
       "         [0.4679],\n",
       "         [0.4684],\n",
       "         [0.4690],\n",
       "         [0.4695],\n",
       "         [0.4701],\n",
       "         [0.4706],\n",
       "         [0.4711],\n",
       "         [0.4717],\n",
       "         [0.4722],\n",
       "         [0.4728],\n",
       "         [0.4733],\n",
       "         [0.4738],\n",
       "         [0.4744],\n",
       "         [0.4749],\n",
       "         [0.4755],\n",
       "         [0.4760],\n",
       "         [0.4765],\n",
       "         [0.4771],\n",
       "         [0.4776],\n",
       "         [0.4782],\n",
       "         [0.4787],\n",
       "         [0.4793],\n",
       "         [0.4798],\n",
       "         [0.4804],\n",
       "         [0.4809],\n",
       "         [0.4814],\n",
       "         [0.4820],\n",
       "         [0.4825],\n",
       "         [0.4831],\n",
       "         [0.4836],\n",
       "         [0.4842],\n",
       "         [0.4847],\n",
       "         [0.4852],\n",
       "         [0.4858],\n",
       "         [0.4863],\n",
       "         [0.4869],\n",
       "         [0.4874],\n",
       "         [0.4880],\n",
       "         [0.4885],\n",
       "         [0.4890],\n",
       "         [0.4896],\n",
       "         [0.4901],\n",
       "         [0.4907],\n",
       "         [0.4912],\n",
       "         [0.4918],\n",
       "         [0.4923],\n",
       "         [0.4928],\n",
       "         [0.4934],\n",
       "         [0.4939],\n",
       "         [0.4945],\n",
       "         [0.4950],\n",
       "         [0.4956],\n",
       "         [0.4961],\n",
       "         [0.4967],\n",
       "         [0.4972],\n",
       "         [0.4978],\n",
       "         [0.4983],\n",
       "         [0.4988],\n",
       "         [0.4994],\n",
       "         [0.4999],\n",
       "         [0.5005],\n",
       "         [0.5010],\n",
       "         [0.5016],\n",
       "         [0.5021],\n",
       "         [0.5027],\n",
       "         [0.5032],\n",
       "         [0.5038],\n",
       "         [0.5043],\n",
       "         [0.5049],\n",
       "         [0.5054],\n",
       "         [0.5060],\n",
       "         [0.5065],\n",
       "         [0.5071],\n",
       "         [0.5076],\n",
       "         [0.5082],\n",
       "         [0.5087],\n",
       "         [0.5093],\n",
       "         [0.5098],\n",
       "         [0.5104],\n",
       "         [0.5109],\n",
       "         [0.5115],\n",
       "         [0.5121],\n",
       "         [0.5126],\n",
       "         [0.5132],\n",
       "         [0.5137]]),\n",
       " tensor([[0.5143],\n",
       "         [0.5149],\n",
       "         [0.5154],\n",
       "         [0.5160],\n",
       "         [0.5166],\n",
       "         [0.5171],\n",
       "         [0.5177],\n",
       "         [0.5183],\n",
       "         [0.5188],\n",
       "         [0.5194],\n",
       "         [0.5200],\n",
       "         [0.5205],\n",
       "         [0.5211],\n",
       "         [0.5217],\n",
       "         [0.5222],\n",
       "         [0.5228],\n",
       "         [0.5234],\n",
       "         [0.5240],\n",
       "         [0.5245],\n",
       "         [0.5251],\n",
       "         [0.5257],\n",
       "         [0.5262],\n",
       "         [0.5268],\n",
       "         [0.5274],\n",
       "         [0.5280],\n",
       "         [0.5285],\n",
       "         [0.5291],\n",
       "         [0.5297],\n",
       "         [0.5303],\n",
       "         [0.5309],\n",
       "         [0.5314],\n",
       "         [0.5320],\n",
       "         [0.5326],\n",
       "         [0.5332],\n",
       "         [0.5338],\n",
       "         [0.5343],\n",
       "         [0.5349],\n",
       "         [0.5355],\n",
       "         [0.5361],\n",
       "         [0.5367],\n",
       "         [0.5372],\n",
       "         [0.5378],\n",
       "         [0.5384],\n",
       "         [0.5390],\n",
       "         [0.5396],\n",
       "         [0.5402],\n",
       "         [0.5407],\n",
       "         [0.5413],\n",
       "         [0.5419],\n",
       "         [0.5425],\n",
       "         [0.5431],\n",
       "         [0.5437],\n",
       "         [0.5442],\n",
       "         [0.5448],\n",
       "         [0.5454],\n",
       "         [0.5460],\n",
       "         [0.5466],\n",
       "         [0.5472],\n",
       "         [0.5477],\n",
       "         [0.5483],\n",
       "         [0.5489],\n",
       "         [0.5495],\n",
       "         [0.5501],\n",
       "         [0.5507],\n",
       "         [0.5513],\n",
       "         [0.5519],\n",
       "         [0.5525],\n",
       "         [0.5531],\n",
       "         [0.5537],\n",
       "         [0.5543],\n",
       "         [0.5549],\n",
       "         [0.5555],\n",
       "         [0.5561],\n",
       "         [0.5566],\n",
       "         [0.5572],\n",
       "         [0.5578],\n",
       "         [0.5584],\n",
       "         [0.5590],\n",
       "         [0.5596],\n",
       "         [0.5602],\n",
       "         [0.5608],\n",
       "         [0.5614],\n",
       "         [0.5620],\n",
       "         [0.5626],\n",
       "         [0.5632],\n",
       "         [0.5638],\n",
       "         [0.5644],\n",
       "         [0.5650],\n",
       "         [0.5656],\n",
       "         [0.5663],\n",
       "         [0.5669],\n",
       "         [0.5675],\n",
       "         [0.5681],\n",
       "         [0.5687],\n",
       "         [0.5693],\n",
       "         [0.5699],\n",
       "         [0.5705],\n",
       "         [0.5711],\n",
       "         [0.5717],\n",
       "         [0.5724],\n",
       "         [0.5730],\n",
       "         [0.5736],\n",
       "         [0.5742],\n",
       "         [0.5748],\n",
       "         [0.5754],\n",
       "         [0.5760],\n",
       "         [0.5767],\n",
       "         [0.5773],\n",
       "         [0.5779],\n",
       "         [0.5785],\n",
       "         [0.5791],\n",
       "         [0.5797],\n",
       "         [0.5804],\n",
       "         [0.5810],\n",
       "         [0.5816],\n",
       "         [0.5822],\n",
       "         [0.5828],\n",
       "         [0.5834],\n",
       "         [0.5841],\n",
       "         [0.5847],\n",
       "         [0.5853],\n",
       "         [0.5859],\n",
       "         [0.5865],\n",
       "         [0.5872],\n",
       "         [0.5878],\n",
       "         [0.5884],\n",
       "         [0.5890],\n",
       "         [0.5897]]),\n",
       " tensor([[0.5903],\n",
       "         [0.5909],\n",
       "         [0.5915],\n",
       "         [0.5922],\n",
       "         [0.5928],\n",
       "         [0.5934],\n",
       "         [0.5940],\n",
       "         [0.5947],\n",
       "         [0.5953],\n",
       "         [0.5959],\n",
       "         [0.5966],\n",
       "         [0.5972],\n",
       "         [0.5978],\n",
       "         [0.5984],\n",
       "         [0.5991],\n",
       "         [0.5997],\n",
       "         [0.6003],\n",
       "         [0.6009],\n",
       "         [0.6016],\n",
       "         [0.6022],\n",
       "         [0.6028],\n",
       "         [0.6034],\n",
       "         [0.6041],\n",
       "         [0.6047],\n",
       "         [0.6053],\n",
       "         [0.6060],\n",
       "         [0.6066],\n",
       "         [0.6072],\n",
       "         [0.6079],\n",
       "         [0.6085],\n",
       "         [0.6091],\n",
       "         [0.6098],\n",
       "         [0.6104],\n",
       "         [0.6110],\n",
       "         [0.6117],\n",
       "         [0.6123],\n",
       "         [0.6129],\n",
       "         [0.6136],\n",
       "         [0.6142],\n",
       "         [0.6148],\n",
       "         [0.6155],\n",
       "         [0.6161],\n",
       "         [0.6168],\n",
       "         [0.6174],\n",
       "         [0.6180],\n",
       "         [0.6187],\n",
       "         [0.6193],\n",
       "         [0.6199],\n",
       "         [0.6206],\n",
       "         [0.6212],\n",
       "         [0.6219],\n",
       "         [0.6225],\n",
       "         [0.6231],\n",
       "         [0.6238],\n",
       "         [0.6244],\n",
       "         [0.6251],\n",
       "         [0.6257],\n",
       "         [0.6263],\n",
       "         [0.6270],\n",
       "         [0.6276],\n",
       "         [0.6283],\n",
       "         [0.6289],\n",
       "         [0.6296],\n",
       "         [0.6302],\n",
       "         [0.6309],\n",
       "         [0.6315],\n",
       "         [0.6322],\n",
       "         [0.6328],\n",
       "         [0.6335],\n",
       "         [0.6341],\n",
       "         [0.6348],\n",
       "         [0.6354],\n",
       "         [0.6361],\n",
       "         [0.6367],\n",
       "         [0.6374],\n",
       "         [0.6380],\n",
       "         [0.6387],\n",
       "         [0.6393],\n",
       "         [0.6400],\n",
       "         [0.6406],\n",
       "         [0.6413],\n",
       "         [0.6419],\n",
       "         [0.6426],\n",
       "         [0.6432],\n",
       "         [0.6439],\n",
       "         [0.6445],\n",
       "         [0.6452],\n",
       "         [0.6458],\n",
       "         [0.6465],\n",
       "         [0.6471],\n",
       "         [0.6478],\n",
       "         [0.6484],\n",
       "         [0.6491],\n",
       "         [0.6497],\n",
       "         [0.6504],\n",
       "         [0.6511],\n",
       "         [0.6517],\n",
       "         [0.6524],\n",
       "         [0.6530],\n",
       "         [0.6537],\n",
       "         [0.6544],\n",
       "         [0.6550],\n",
       "         [0.6557],\n",
       "         [0.6563],\n",
       "         [0.6570],\n",
       "         [0.6577],\n",
       "         [0.6583],\n",
       "         [0.6590],\n",
       "         [0.6596],\n",
       "         [0.6603],\n",
       "         [0.6610],\n",
       "         [0.6616],\n",
       "         [0.6623],\n",
       "         [0.6629],\n",
       "         [0.6636],\n",
       "         [0.6642],\n",
       "         [0.6649],\n",
       "         [0.6656],\n",
       "         [0.6662],\n",
       "         [0.6669],\n",
       "         [0.6675],\n",
       "         [0.6682],\n",
       "         [0.6689],\n",
       "         [0.6695],\n",
       "         [0.6702],\n",
       "         [0.6708],\n",
       "         [0.6715],\n",
       "         [0.6722]]),\n",
       " tensor([[0.6728],\n",
       "         [0.6735],\n",
       "         [0.6741],\n",
       "         [0.6748],\n",
       "         [0.6755],\n",
       "         [0.6761],\n",
       "         [0.6768],\n",
       "         [0.6774],\n",
       "         [0.6781],\n",
       "         [0.6787],\n",
       "         [0.6794],\n",
       "         [0.6801],\n",
       "         [0.6807],\n",
       "         [0.6814],\n",
       "         [0.6820],\n",
       "         [0.6827],\n",
       "         [0.6833],\n",
       "         [0.6840],\n",
       "         [0.6847],\n",
       "         [0.6853],\n",
       "         [0.6860],\n",
       "         [0.6866],\n",
       "         [0.6873],\n",
       "         [0.6879],\n",
       "         [0.6886],\n",
       "         [0.6892],\n",
       "         [0.6899],\n",
       "         [0.6905],\n",
       "         [0.6912],\n",
       "         [0.6919],\n",
       "         [0.6925],\n",
       "         [0.6932],\n",
       "         [0.6938],\n",
       "         [0.6945],\n",
       "         [0.6951],\n",
       "         [0.6958],\n",
       "         [0.6964],\n",
       "         [0.6971],\n",
       "         [0.6978],\n",
       "         [0.6984],\n",
       "         [0.6991],\n",
       "         [0.6997],\n",
       "         [0.7004],\n",
       "         [0.7010],\n",
       "         [0.7017],\n",
       "         [0.7023],\n",
       "         [0.7030],\n",
       "         [0.7037],\n",
       "         [0.7043],\n",
       "         [0.7050],\n",
       "         [0.7056],\n",
       "         [0.7063],\n",
       "         [0.7069],\n",
       "         [0.7076],\n",
       "         [0.7082],\n",
       "         [0.7089],\n",
       "         [0.7096],\n",
       "         [0.7102],\n",
       "         [0.7109],\n",
       "         [0.7116],\n",
       "         [0.7122],\n",
       "         [0.7129],\n",
       "         [0.7135],\n",
       "         [0.7142],\n",
       "         [0.7149],\n",
       "         [0.7155],\n",
       "         [0.7162],\n",
       "         [0.7169],\n",
       "         [0.7176],\n",
       "         [0.7182],\n",
       "         [0.7189],\n",
       "         [0.7196],\n",
       "         [0.7202],\n",
       "         [0.7209],\n",
       "         [0.7216],\n",
       "         [0.7222],\n",
       "         [0.7229],\n",
       "         [0.7236],\n",
       "         [0.7243],\n",
       "         [0.7249],\n",
       "         [0.7256],\n",
       "         [0.7263],\n",
       "         [0.7270],\n",
       "         [0.7277],\n",
       "         [0.7283],\n",
       "         [0.7290],\n",
       "         [0.7297],\n",
       "         [0.7304],\n",
       "         [0.7311],\n",
       "         [0.7317],\n",
       "         [0.7324],\n",
       "         [0.7331],\n",
       "         [0.7338],\n",
       "         [0.7345],\n",
       "         [0.7352],\n",
       "         [0.7359],\n",
       "         [0.7365],\n",
       "         [0.7372],\n",
       "         [0.7379],\n",
       "         [0.7386],\n",
       "         [0.7393],\n",
       "         [0.7400],\n",
       "         [0.7407],\n",
       "         [0.7414],\n",
       "         [0.7421],\n",
       "         [0.7428],\n",
       "         [0.7435],\n",
       "         [0.7442],\n",
       "         [0.7448],\n",
       "         [0.7455],\n",
       "         [0.7462],\n",
       "         [0.7469],\n",
       "         [0.7476],\n",
       "         [0.7483],\n",
       "         [0.7490],\n",
       "         [0.7497],\n",
       "         [0.7504],\n",
       "         [0.7511],\n",
       "         [0.7518],\n",
       "         [0.7525],\n",
       "         [0.7532],\n",
       "         [0.7539],\n",
       "         [0.7546],\n",
       "         [0.7553],\n",
       "         [0.7560],\n",
       "         [0.7567],\n",
       "         [0.7574],\n",
       "         [0.7581]]),\n",
       " tensor([[0.7588],\n",
       "         [0.7595],\n",
       "         [0.7602],\n",
       "         [0.7610],\n",
       "         [0.7617],\n",
       "         [0.7624],\n",
       "         [0.7631],\n",
       "         [0.7638],\n",
       "         [0.7645],\n",
       "         [0.7652],\n",
       "         [0.7659],\n",
       "         [0.7666],\n",
       "         [0.7673],\n",
       "         [0.7680],\n",
       "         [0.7687],\n",
       "         [0.7694],\n",
       "         [0.7701],\n",
       "         [0.7708],\n",
       "         [0.7715],\n",
       "         [0.7722],\n",
       "         [0.7729],\n",
       "         [0.7736],\n",
       "         [0.7743],\n",
       "         [0.7750],\n",
       "         [0.7757],\n",
       "         [0.7764],\n",
       "         [0.7771],\n",
       "         [0.7778],\n",
       "         [0.7785],\n",
       "         [0.7792],\n",
       "         [0.7799],\n",
       "         [0.7806],\n",
       "         [0.7813],\n",
       "         [0.7820],\n",
       "         [0.7827],\n",
       "         [0.7834],\n",
       "         [0.7842],\n",
       "         [0.7849],\n",
       "         [0.7856],\n",
       "         [0.7863],\n",
       "         [0.7870],\n",
       "         [0.7877],\n",
       "         [0.7884],\n",
       "         [0.7891],\n",
       "         [0.7898],\n",
       "         [0.7905],\n",
       "         [0.7912],\n",
       "         [0.7919],\n",
       "         [0.7926],\n",
       "         [0.7933],\n",
       "         [0.7940],\n",
       "         [0.7947],\n",
       "         [0.7955],\n",
       "         [0.7962],\n",
       "         [0.7969],\n",
       "         [0.7976],\n",
       "         [0.7983],\n",
       "         [0.7990],\n",
       "         [0.7997],\n",
       "         [0.8004],\n",
       "         [0.8011],\n",
       "         [0.8018],\n",
       "         [0.8025],\n",
       "         [0.8032],\n",
       "         [0.8040],\n",
       "         [0.8047],\n",
       "         [0.8054],\n",
       "         [0.8061],\n",
       "         [0.8068],\n",
       "         [0.8075],\n",
       "         [0.8082],\n",
       "         [0.8089],\n",
       "         [0.8096],\n",
       "         [0.8103],\n",
       "         [0.8111],\n",
       "         [0.8118],\n",
       "         [0.8125],\n",
       "         [0.8132],\n",
       "         [0.8139],\n",
       "         [0.8146],\n",
       "         [0.8153],\n",
       "         [0.8160],\n",
       "         [0.8167],\n",
       "         [0.8175],\n",
       "         [0.8182],\n",
       "         [0.8189],\n",
       "         [0.8196],\n",
       "         [0.8203],\n",
       "         [0.8210],\n",
       "         [0.8217],\n",
       "         [0.8224],\n",
       "         [0.8231],\n",
       "         [0.8239],\n",
       "         [0.8246],\n",
       "         [0.8253],\n",
       "         [0.8260],\n",
       "         [0.8267],\n",
       "         [0.8274],\n",
       "         [0.8281],\n",
       "         [0.8288],\n",
       "         [0.8296],\n",
       "         [0.8303],\n",
       "         [0.8310],\n",
       "         [0.8317],\n",
       "         [0.8324],\n",
       "         [0.8331],\n",
       "         [0.8338],\n",
       "         [0.8345],\n",
       "         [0.8353],\n",
       "         [0.8360],\n",
       "         [0.8367],\n",
       "         [0.8374],\n",
       "         [0.8381],\n",
       "         [0.8388],\n",
       "         [0.8395],\n",
       "         [0.8403],\n",
       "         [0.8410],\n",
       "         [0.8417],\n",
       "         [0.8424],\n",
       "         [0.8431],\n",
       "         [0.8438],\n",
       "         [0.8445],\n",
       "         [0.8453],\n",
       "         [0.8460],\n",
       "         [0.8467],\n",
       "         [0.8474],\n",
       "         [0.8481],\n",
       "         [0.8488]]),\n",
       " tensor([[0.8495],\n",
       "         [0.8503],\n",
       "         [0.8510],\n",
       "         [0.8517],\n",
       "         [0.8524],\n",
       "         [0.8531],\n",
       "         [0.8538],\n",
       "         [0.8545],\n",
       "         [0.8553],\n",
       "         [0.8560],\n",
       "         [0.8567],\n",
       "         [0.8574],\n",
       "         [0.8581],\n",
       "         [0.8588],\n",
       "         [0.8595],\n",
       "         [0.8603],\n",
       "         [0.8610],\n",
       "         [0.8617],\n",
       "         [0.8624],\n",
       "         [0.8631],\n",
       "         [0.8638],\n",
       "         [0.8645],\n",
       "         [0.8653],\n",
       "         [0.8660],\n",
       "         [0.8667],\n",
       "         [0.8674],\n",
       "         [0.8681],\n",
       "         [0.8688],\n",
       "         [0.8696],\n",
       "         [0.8703],\n",
       "         [0.8710],\n",
       "         [0.8717],\n",
       "         [0.8724],\n",
       "         [0.8731],\n",
       "         [0.8738],\n",
       "         [0.8746],\n",
       "         [0.8753],\n",
       "         [0.8760],\n",
       "         [0.8767],\n",
       "         [0.8774],\n",
       "         [0.8781],\n",
       "         [0.8789],\n",
       "         [0.8796],\n",
       "         [0.8803],\n",
       "         [0.8810],\n",
       "         [0.8817],\n",
       "         [0.8824],\n",
       "         [0.8831],\n",
       "         [0.8839],\n",
       "         [0.8846],\n",
       "         [0.8853],\n",
       "         [0.8860],\n",
       "         [0.8867],\n",
       "         [0.8874],\n",
       "         [0.8882],\n",
       "         [0.8889],\n",
       "         [0.8896],\n",
       "         [0.8903],\n",
       "         [0.8910],\n",
       "         [0.8917],\n",
       "         [0.8924],\n",
       "         [0.8932],\n",
       "         [0.8939],\n",
       "         [0.8946],\n",
       "         [0.8953],\n",
       "         [0.8960],\n",
       "         [0.8967],\n",
       "         [0.8974],\n",
       "         [0.8982],\n",
       "         [0.8989],\n",
       "         [0.8996],\n",
       "         [0.9003],\n",
       "         [0.9010],\n",
       "         [0.9017],\n",
       "         [0.9024],\n",
       "         [0.9032],\n",
       "         [0.9039],\n",
       "         [0.9046],\n",
       "         [0.9053],\n",
       "         [0.9060],\n",
       "         [0.9067],\n",
       "         [0.9075],\n",
       "         [0.9082],\n",
       "         [0.9089],\n",
       "         [0.9096],\n",
       "         [0.9103],\n",
       "         [0.9110],\n",
       "         [0.9117],\n",
       "         [0.9125],\n",
       "         [0.9132],\n",
       "         [0.9139],\n",
       "         [0.9146],\n",
       "         [0.9153],\n",
       "         [0.9160],\n",
       "         [0.9168],\n",
       "         [0.9175],\n",
       "         [0.9182],\n",
       "         [0.9189],\n",
       "         [0.9196],\n",
       "         [0.9203],\n",
       "         [0.9211],\n",
       "         [0.9218],\n",
       "         [0.9225],\n",
       "         [0.9232],\n",
       "         [0.9239],\n",
       "         [0.9246],\n",
       "         [0.9253],\n",
       "         [0.9261],\n",
       "         [0.9268],\n",
       "         [0.9275],\n",
       "         [0.9282],\n",
       "         [0.9289],\n",
       "         [0.9296],\n",
       "         [0.9303],\n",
       "         [0.9310],\n",
       "         [0.9318],\n",
       "         [0.9325],\n",
       "         [0.9332],\n",
       "         [0.9339],\n",
       "         [0.9346],\n",
       "         [0.9353],\n",
       "         [0.9360],\n",
       "         [0.9367],\n",
       "         [0.9374],\n",
       "         [0.9381],\n",
       "         [0.9388],\n",
       "         [0.9396],\n",
       "         [0.9403]]),\n",
       " tensor([[0.9410],\n",
       "         [0.9417],\n",
       "         [0.9424],\n",
       "         [0.9431],\n",
       "         [0.9438],\n",
       "         [0.9445],\n",
       "         [0.9452],\n",
       "         [0.9459],\n",
       "         [0.9466],\n",
       "         [0.9473],\n",
       "         [0.9480],\n",
       "         [0.9487],\n",
       "         [0.9494],\n",
       "         [0.9501],\n",
       "         [0.9508],\n",
       "         [0.9515],\n",
       "         [0.9523],\n",
       "         [0.9530],\n",
       "         [0.9537],\n",
       "         [0.9544],\n",
       "         [0.9551],\n",
       "         [0.9558],\n",
       "         [0.9565],\n",
       "         [0.9572],\n",
       "         [0.9580],\n",
       "         [0.9587],\n",
       "         [0.9594],\n",
       "         [0.9601],\n",
       "         [0.9608],\n",
       "         [0.9615],\n",
       "         [0.9623],\n",
       "         [0.9630],\n",
       "         [0.9637],\n",
       "         [0.9644],\n",
       "         [0.9651],\n",
       "         [0.9659],\n",
       "         [0.9666],\n",
       "         [0.9673],\n",
       "         [0.9681],\n",
       "         [0.9688],\n",
       "         [0.9695],\n",
       "         [0.9702],\n",
       "         [0.9710],\n",
       "         [0.9717],\n",
       "         [0.9724],\n",
       "         [0.9731],\n",
       "         [0.9739],\n",
       "         [0.9746],\n",
       "         [0.9753],\n",
       "         [0.9760],\n",
       "         [0.9768],\n",
       "         [0.9775],\n",
       "         [0.9782],\n",
       "         [0.9789],\n",
       "         [0.9796],\n",
       "         [0.9803],\n",
       "         [0.9810],\n",
       "         [0.9816],\n",
       "         [0.9823],\n",
       "         [0.9830],\n",
       "         [0.9837],\n",
       "         [0.9843],\n",
       "         [0.9850],\n",
       "         [0.9857],\n",
       "         [0.9864],\n",
       "         [0.9871],\n",
       "         [0.9878],\n",
       "         [0.9885],\n",
       "         [0.9892],\n",
       "         [0.9899],\n",
       "         [0.9907],\n",
       "         [0.9914],\n",
       "         [0.9922],\n",
       "         [0.9929],\n",
       "         [0.9936],\n",
       "         [0.9944],\n",
       "         [0.9951],\n",
       "         [0.9959],\n",
       "         [0.9966],\n",
       "         [0.9973],\n",
       "         [0.9981],\n",
       "         [0.9988],\n",
       "         [0.9995],\n",
       "         [1.0002],\n",
       "         [1.0009],\n",
       "         [1.0016],\n",
       "         [1.0023],\n",
       "         [1.0030],\n",
       "         [1.0037],\n",
       "         [1.0043],\n",
       "         [1.0050],\n",
       "         [1.0056],\n",
       "         [1.0063],\n",
       "         [1.0070],\n",
       "         [1.0076],\n",
       "         [1.0083],\n",
       "         [1.0089],\n",
       "         [1.0096],\n",
       "         [1.0103],\n",
       "         [1.0111],\n",
       "         [1.0118],\n",
       "         [1.0125],\n",
       "         [1.0133],\n",
       "         [1.0140],\n",
       "         [1.0148],\n",
       "         [1.0155],\n",
       "         [1.0163],\n",
       "         [1.0170],\n",
       "         [1.0177],\n",
       "         [1.0185],\n",
       "         [1.0192],\n",
       "         [1.0200],\n",
       "         [1.0207],\n",
       "         [1.0214],\n",
       "         [1.0221],\n",
       "         [1.0228],\n",
       "         [1.0235],\n",
       "         [1.0242],\n",
       "         [1.0249],\n",
       "         [1.0256],\n",
       "         [1.0262],\n",
       "         [1.0269],\n",
       "         [1.0275],\n",
       "         [1.0282],\n",
       "         [1.0288],\n",
       "         [1.0294],\n",
       "         [1.0301],\n",
       "         [1.0307]]),\n",
       " tensor([[1.0314],\n",
       "         [1.0320],\n",
       "         [1.0327],\n",
       "         [1.0334],\n",
       "         [1.0341],\n",
       "         [1.0348],\n",
       "         [1.0355],\n",
       "         [1.0362],\n",
       "         [1.0370],\n",
       "         [1.0377],\n",
       "         [1.0384],\n",
       "         [1.0391],\n",
       "         [1.0398],\n",
       "         [1.0405],\n",
       "         [1.0412],\n",
       "         [1.0419],\n",
       "         [1.0426],\n",
       "         [1.0433],\n",
       "         [1.0440],\n",
       "         [1.0447],\n",
       "         [1.0454],\n",
       "         [1.0461],\n",
       "         [1.0468],\n",
       "         [1.0475],\n",
       "         [1.0482],\n",
       "         [1.0489],\n",
       "         [1.0495],\n",
       "         [1.0502],\n",
       "         [1.0509],\n",
       "         [1.0516],\n",
       "         [1.0523],\n",
       "         [1.0530],\n",
       "         [1.0536],\n",
       "         [1.0543],\n",
       "         [1.0550],\n",
       "         [1.0557],\n",
       "         [1.0564],\n",
       "         [1.0571],\n",
       "         [1.0578],\n",
       "         [1.0586],\n",
       "         [1.0593],\n",
       "         [1.0600],\n",
       "         [1.0607],\n",
       "         [1.0614],\n",
       "         [1.0621],\n",
       "         [1.0628],\n",
       "         [1.0635],\n",
       "         [1.0642],\n",
       "         [1.0649],\n",
       "         [1.0656],\n",
       "         [1.0663],\n",
       "         [1.0670],\n",
       "         [1.0677],\n",
       "         [1.0684],\n",
       "         [1.0691],\n",
       "         [1.0698],\n",
       "         [1.0705],\n",
       "         [1.0712],\n",
       "         [1.0718],\n",
       "         [1.0725],\n",
       "         [1.0732],\n",
       "         [1.0738],\n",
       "         [1.0745],\n",
       "         [1.0752],\n",
       "         [1.0759],\n",
       "         [1.0765],\n",
       "         [1.0772],\n",
       "         [1.0779],\n",
       "         [1.0787],\n",
       "         [1.0794],\n",
       "         [1.0801],\n",
       "         [1.0808],\n",
       "         [1.0816],\n",
       "         [1.0823],\n",
       "         [1.0830],\n",
       "         [1.0837],\n",
       "         [1.0845],\n",
       "         [1.0852],\n",
       "         [1.0859],\n",
       "         [1.0866],\n",
       "         [1.0873],\n",
       "         [1.0880],\n",
       "         [1.0887],\n",
       "         [1.0894],\n",
       "         [1.0901],\n",
       "         [1.0908],\n",
       "         [1.0915],\n",
       "         [1.0921],\n",
       "         [1.0928],\n",
       "         [1.0934],\n",
       "         [1.0941],\n",
       "         [1.0947],\n",
       "         [1.0953],\n",
       "         [1.0960],\n",
       "         [1.0966],\n",
       "         [1.0972],\n",
       "         [1.0979],\n",
       "         [1.0985],\n",
       "         [1.0992],\n",
       "         [1.0999],\n",
       "         [1.1006],\n",
       "         [1.1013],\n",
       "         [1.1020],\n",
       "         [1.1027],\n",
       "         [1.1034],\n",
       "         [1.1041],\n",
       "         [1.1048],\n",
       "         [1.1055],\n",
       "         [1.1062],\n",
       "         [1.1069],\n",
       "         [1.1076],\n",
       "         [1.1083],\n",
       "         [1.1090],\n",
       "         [1.1097],\n",
       "         [1.1104],\n",
       "         [1.1111],\n",
       "         [1.1118],\n",
       "         [1.1124],\n",
       "         [1.1131],\n",
       "         [1.1138],\n",
       "         [1.1144],\n",
       "         [1.1151],\n",
       "         [1.1158],\n",
       "         [1.1164],\n",
       "         [1.1171],\n",
       "         [1.1177],\n",
       "         [1.1184],\n",
       "         [1.1191]]),\n",
       " tensor([[1.1197],\n",
       "         [1.1204],\n",
       "         [1.1211],\n",
       "         [1.1218],\n",
       "         [1.1225],\n",
       "         [1.1232],\n",
       "         [1.1239],\n",
       "         [1.1246],\n",
       "         [1.1253],\n",
       "         [1.1260],\n",
       "         [1.1267],\n",
       "         [1.1274],\n",
       "         [1.1281],\n",
       "         [1.1288],\n",
       "         [1.1295],\n",
       "         [1.1302],\n",
       "         [1.1309],\n",
       "         [1.1316],\n",
       "         [1.1323],\n",
       "         [1.1329],\n",
       "         [1.1336],\n",
       "         [1.1343],\n",
       "         [1.1350],\n",
       "         [1.1356],\n",
       "         [1.1363],\n",
       "         [1.1369],\n",
       "         [1.1376],\n",
       "         [1.1382],\n",
       "         [1.1389],\n",
       "         [1.1395],\n",
       "         [1.1402],\n",
       "         [1.1408],\n",
       "         [1.1415],\n",
       "         [1.1421],\n",
       "         [1.1428],\n",
       "         [1.1435],\n",
       "         [1.1442],\n",
       "         [1.1449],\n",
       "         [1.1456],\n",
       "         [1.1463],\n",
       "         [1.1470],\n",
       "         [1.1477],\n",
       "         [1.1484],\n",
       "         [1.1491],\n",
       "         [1.1498],\n",
       "         [1.1505],\n",
       "         [1.1512],\n",
       "         [1.1519],\n",
       "         [1.1526],\n",
       "         [1.1533],\n",
       "         [1.1539],\n",
       "         [1.1546],\n",
       "         [1.1553],\n",
       "         [1.1560],\n",
       "         [1.1566],\n",
       "         [1.1573],\n",
       "         [1.1582],\n",
       "         [1.1593],\n",
       "         [1.1604],\n",
       "         [1.1615],\n",
       "         [1.1626],\n",
       "         [1.1636],\n",
       "         [1.1647],\n",
       "         [1.1658],\n",
       "         [1.1669],\n",
       "         [1.1681],\n",
       "         [1.1692],\n",
       "         [1.1703],\n",
       "         [1.1715],\n",
       "         [1.1727],\n",
       "         [1.1739],\n",
       "         [1.1750],\n",
       "         [1.1762],\n",
       "         [1.1774],\n",
       "         [1.1786],\n",
       "         [1.1798],\n",
       "         [1.1810],\n",
       "         [1.1821],\n",
       "         [1.1833],\n",
       "         [1.1845],\n",
       "         [1.1857],\n",
       "         [1.1868],\n",
       "         [1.1880],\n",
       "         [1.1891],\n",
       "         [1.1903],\n",
       "         [1.1914],\n",
       "         [1.1925],\n",
       "         [1.1936],\n",
       "         [1.1947],\n",
       "         [1.1958],\n",
       "         [1.1969],\n",
       "         [1.1979],\n",
       "         [1.1989],\n",
       "         [1.2000],\n",
       "         [1.2010],\n",
       "         [1.2021],\n",
       "         [1.2031],\n",
       "         [1.2042],\n",
       "         [1.2053],\n",
       "         [1.2064],\n",
       "         [1.2075],\n",
       "         [1.2087],\n",
       "         [1.2098],\n",
       "         [1.2110],\n",
       "         [1.2121],\n",
       "         [1.2133],\n",
       "         [1.2144],\n",
       "         [1.2156],\n",
       "         [1.2167],\n",
       "         [1.2179],\n",
       "         [1.2190],\n",
       "         [1.2202],\n",
       "         [1.2213],\n",
       "         [1.2225],\n",
       "         [1.2236],\n",
       "         [1.2247],\n",
       "         [1.2258],\n",
       "         [1.2269],\n",
       "         [1.2280],\n",
       "         [1.2290],\n",
       "         [1.2301],\n",
       "         [1.2311],\n",
       "         [1.2322],\n",
       "         [1.2332],\n",
       "         [1.2342],\n",
       "         [1.2353],\n",
       "         [1.2363],\n",
       "         [1.2374]]),\n",
       " tensor([[1.2384],\n",
       "         [1.2395],\n",
       "         [1.2406],\n",
       "         [1.2417],\n",
       "         [1.2428],\n",
       "         [1.2440],\n",
       "         [1.2451],\n",
       "         [1.2463],\n",
       "         [1.2474],\n",
       "         [1.2486],\n",
       "         [1.2497],\n",
       "         [1.2509],\n",
       "         [1.2520],\n",
       "         [1.2532],\n",
       "         [1.2543],\n",
       "         [1.2555],\n",
       "         [1.2566],\n",
       "         [1.2577],\n",
       "         [1.2589],\n",
       "         [1.2600],\n",
       "         [1.2611],\n",
       "         [1.2622],\n",
       "         [1.2632],\n",
       "         [1.2643],\n",
       "         [1.2654],\n",
       "         [1.2664],\n",
       "         [1.2674],\n",
       "         [1.2685],\n",
       "         [1.2695],\n",
       "         [1.2706],\n",
       "         [1.2716],\n",
       "         [1.2726],\n",
       "         [1.2737],\n",
       "         [1.2748],\n",
       "         [1.2758],\n",
       "         [1.2769],\n",
       "         [1.2781],\n",
       "         [1.2792],\n",
       "         [1.2803],\n",
       "         [1.2814],\n",
       "         [1.2826],\n",
       "         [1.2837],\n",
       "         [1.2848],\n",
       "         [1.2860],\n",
       "         [1.2871],\n",
       "         [1.2882],\n",
       "         [1.2893],\n",
       "         [1.2905],\n",
       "         [1.2916],\n",
       "         [1.2927],\n",
       "         [1.2938],\n",
       "         [1.2949],\n",
       "         [1.2960],\n",
       "         [1.2971],\n",
       "         [1.2982],\n",
       "         [1.2993],\n",
       "         [1.3004],\n",
       "         [1.3015],\n",
       "         [1.3026],\n",
       "         [1.3037],\n",
       "         [1.3048],\n",
       "         [1.3059],\n",
       "         [1.3070],\n",
       "         [1.3080],\n",
       "         [1.3091],\n",
       "         [1.3102],\n",
       "         [1.3114],\n",
       "         [1.3125],\n",
       "         [1.3136],\n",
       "         [1.3148],\n",
       "         [1.3159],\n",
       "         [1.3170],\n",
       "         [1.3182],\n",
       "         [1.3193],\n",
       "         [1.3205],\n",
       "         [1.3216],\n",
       "         [1.3228],\n",
       "         [1.3239],\n",
       "         [1.3250],\n",
       "         [1.3262],\n",
       "         [1.3273],\n",
       "         [1.3284],\n",
       "         [1.3296],\n",
       "         [1.3307],\n",
       "         [1.3318],\n",
       "         [1.3329],\n",
       "         [1.3340],\n",
       "         [1.3351],\n",
       "         [1.3362],\n",
       "         [1.3372],\n",
       "         [1.3383],\n",
       "         [1.3394],\n",
       "         [1.3404],\n",
       "         [1.3415],\n",
       "         [1.3425],\n",
       "         [1.3436],\n",
       "         [1.3447],\n",
       "         [1.3458],\n",
       "         [1.3469],\n",
       "         [1.3480],\n",
       "         [1.3491],\n",
       "         [1.3502],\n",
       "         [1.3513],\n",
       "         [1.3524],\n",
       "         [1.3536],\n",
       "         [1.3547],\n",
       "         [1.3558],\n",
       "         [1.3569],\n",
       "         [1.3581],\n",
       "         [1.3592],\n",
       "         [1.3603],\n",
       "         [1.3614],\n",
       "         [1.3625],\n",
       "         [1.3637],\n",
       "         [1.3648],\n",
       "         [1.3659],\n",
       "         [1.3670],\n",
       "         [1.3681],\n",
       "         [1.3693],\n",
       "         [1.3704],\n",
       "         [1.3715],\n",
       "         [1.3726],\n",
       "         [1.3737],\n",
       "         [1.3748],\n",
       "         [1.3759],\n",
       "         [1.3770],\n",
       "         [1.3781],\n",
       "         [1.3793]]),\n",
       " tensor([[1.3804],\n",
       "         [1.3815],\n",
       "         [1.3826],\n",
       "         [1.3838],\n",
       "         [1.3849],\n",
       "         [1.3861],\n",
       "         [1.3872],\n",
       "         [1.3884],\n",
       "         [1.3895],\n",
       "         [1.3907],\n",
       "         [1.3918],\n",
       "         [1.3930],\n",
       "         [1.3941],\n",
       "         [1.3953],\n",
       "         [1.3965],\n",
       "         [1.3976],\n",
       "         [1.3988],\n",
       "         [1.3999],\n",
       "         [1.4010],\n",
       "         [1.4022],\n",
       "         [1.4033],\n",
       "         [1.4044],\n",
       "         [1.4055],\n",
       "         [1.4067],\n",
       "         [1.4077],\n",
       "         [1.4088],\n",
       "         [1.4099],\n",
       "         [1.4110],\n",
       "         [1.4121],\n",
       "         [1.4132],\n",
       "         [1.4143],\n",
       "         [1.4154],\n",
       "         [1.4165],\n",
       "         [1.4176],\n",
       "         [1.4187],\n",
       "         [1.4198],\n",
       "         [1.4210],\n",
       "         [1.4222],\n",
       "         [1.4233],\n",
       "         [1.4245],\n",
       "         [1.4257],\n",
       "         [1.4269],\n",
       "         [1.4280],\n",
       "         [1.4292],\n",
       "         [1.4304],\n",
       "         [1.4316],\n",
       "         [1.4327],\n",
       "         [1.4339],\n",
       "         [1.4350],\n",
       "         [1.4362],\n",
       "         [1.4373],\n",
       "         [1.4385],\n",
       "         [1.4396],\n",
       "         [1.4407],\n",
       "         [1.4418],\n",
       "         [1.4430],\n",
       "         [1.4441],\n",
       "         [1.4451],\n",
       "         [1.4462],\n",
       "         [1.4473],\n",
       "         [1.4484],\n",
       "         [1.4495],\n",
       "         [1.4505],\n",
       "         [1.4516],\n",
       "         [1.4527],\n",
       "         [1.4538],\n",
       "         [1.4549],\n",
       "         [1.4561],\n",
       "         [1.4572],\n",
       "         [1.4583],\n",
       "         [1.4595],\n",
       "         [1.4606],\n",
       "         [1.4618],\n",
       "         [1.4629],\n",
       "         [1.4641],\n",
       "         [1.4652],\n",
       "         [1.4664],\n",
       "         [1.4675],\n",
       "         [1.4687],\n",
       "         [1.4698],\n",
       "         [1.4710],\n",
       "         [1.4721],\n",
       "         [1.4732],\n",
       "         [1.4744],\n",
       "         [1.4755],\n",
       "         [1.4767],\n",
       "         [1.4778],\n",
       "         [1.4790],\n",
       "         [1.4801],\n",
       "         [1.4813],\n",
       "         [1.4824],\n",
       "         [1.4836],\n",
       "         [1.4847],\n",
       "         [1.4859],\n",
       "         [1.4870],\n",
       "         [1.4882],\n",
       "         [1.4893],\n",
       "         [1.4905],\n",
       "         [1.4916],\n",
       "         [1.4928],\n",
       "         [1.4939],\n",
       "         [1.4951],\n",
       "         [1.4962],\n",
       "         [1.4974],\n",
       "         [1.4985],\n",
       "         [1.4997],\n",
       "         [1.5008],\n",
       "         [1.5020],\n",
       "         [1.5031],\n",
       "         [1.5043],\n",
       "         [1.5055],\n",
       "         [1.5066],\n",
       "         [1.5078],\n",
       "         [1.5089],\n",
       "         [1.5101],\n",
       "         [1.5112],\n",
       "         [1.5124],\n",
       "         [1.5136],\n",
       "         [1.5147],\n",
       "         [1.5159],\n",
       "         [1.5171],\n",
       "         [1.5182],\n",
       "         [1.5194],\n",
       "         [1.5206],\n",
       "         [1.5218],\n",
       "         [1.5230],\n",
       "         [1.5241],\n",
       "         [1.5253]]),\n",
       " tensor([[1.5265],\n",
       "         [1.5277],\n",
       "         [1.5289],\n",
       "         [1.5300],\n",
       "         [1.5312],\n",
       "         [1.5324],\n",
       "         [1.5336],\n",
       "         [1.5348],\n",
       "         [1.5360],\n",
       "         [1.5372],\n",
       "         [1.5383],\n",
       "         [1.5395],\n",
       "         [1.5407],\n",
       "         [1.5419],\n",
       "         [1.5431],\n",
       "         [1.5443],\n",
       "         [1.5455],\n",
       "         [1.5466],\n",
       "         [1.5478],\n",
       "         [1.5490],\n",
       "         [1.5502],\n",
       "         [1.5514],\n",
       "         [1.5526],\n",
       "         [1.5538],\n",
       "         [1.5550],\n",
       "         [1.5562],\n",
       "         [1.5574],\n",
       "         [1.5586],\n",
       "         [1.5598],\n",
       "         [1.5610],\n",
       "         [1.5621],\n",
       "         [1.5633],\n",
       "         [1.5645],\n",
       "         [1.5657],\n",
       "         [1.5669],\n",
       "         [1.5681],\n",
       "         [1.5693],\n",
       "         [1.5705],\n",
       "         [1.5717],\n",
       "         [1.5729],\n",
       "         [1.5741],\n",
       "         [1.5753],\n",
       "         [1.5765],\n",
       "         [1.5777],\n",
       "         [1.5789],\n",
       "         [1.5801],\n",
       "         [1.5813],\n",
       "         [1.5825],\n",
       "         [1.5837],\n",
       "         [1.5850],\n",
       "         [1.5862],\n",
       "         [1.5874],\n",
       "         [1.5886],\n",
       "         [1.5898],\n",
       "         [1.5910],\n",
       "         [1.5922],\n",
       "         [1.5934],\n",
       "         [1.5946],\n",
       "         [1.5958],\n",
       "         [1.5970],\n",
       "         [1.5982],\n",
       "         [1.5994],\n",
       "         [1.6007],\n",
       "         [1.6019],\n",
       "         [1.6031],\n",
       "         [1.6043],\n",
       "         [1.6055],\n",
       "         [1.6067],\n",
       "         [1.6079],\n",
       "         [1.6092],\n",
       "         [1.6104],\n",
       "         [1.6116],\n",
       "         [1.6128],\n",
       "         [1.6140],\n",
       "         [1.6152],\n",
       "         [1.6165],\n",
       "         [1.6177],\n",
       "         [1.6189],\n",
       "         [1.6201],\n",
       "         [1.6213],\n",
       "         [1.6226],\n",
       "         [1.6238],\n",
       "         [1.6250],\n",
       "         [1.6262],\n",
       "         [1.6274],\n",
       "         [1.6287],\n",
       "         [1.6299],\n",
       "         [1.6311],\n",
       "         [1.6323],\n",
       "         [1.6336],\n",
       "         [1.6348],\n",
       "         [1.6360],\n",
       "         [1.6372],\n",
       "         [1.6385],\n",
       "         [1.6397],\n",
       "         [1.6409],\n",
       "         [1.6422],\n",
       "         [1.6434],\n",
       "         [1.6446],\n",
       "         [1.6458],\n",
       "         [1.6471],\n",
       "         [1.6483],\n",
       "         [1.6495],\n",
       "         [1.6508],\n",
       "         [1.6520],\n",
       "         [1.6532],\n",
       "         [1.6545],\n",
       "         [1.6557],\n",
       "         [1.6570],\n",
       "         [1.6582],\n",
       "         [1.6594],\n",
       "         [1.6607],\n",
       "         [1.6619],\n",
       "         [1.6631],\n",
       "         [1.6644],\n",
       "         [1.6656],\n",
       "         [1.6669],\n",
       "         [1.6681],\n",
       "         [1.6693],\n",
       "         [1.6706],\n",
       "         [1.6718],\n",
       "         [1.6731],\n",
       "         [1.6743],\n",
       "         [1.6755],\n",
       "         [1.6768],\n",
       "         [1.6780],\n",
       "         [1.6793],\n",
       "         [1.6805]]),\n",
       " tensor([[1.6818],\n",
       "         [1.6830],\n",
       "         [1.6843],\n",
       "         [1.6855],\n",
       "         [1.6868],\n",
       "         [1.6880],\n",
       "         [1.6893],\n",
       "         [1.6905],\n",
       "         [1.6918],\n",
       "         [1.6930],\n",
       "         [1.6943],\n",
       "         [1.6955],\n",
       "         [1.6968],\n",
       "         [1.6980],\n",
       "         [1.6993],\n",
       "         [1.7005],\n",
       "         [1.7018],\n",
       "         [1.7030],\n",
       "         [1.7043],\n",
       "         [1.7055],\n",
       "         [1.7068],\n",
       "         [1.7080],\n",
       "         [1.7093],\n",
       "         [1.7106],\n",
       "         [1.7118],\n",
       "         [1.7131],\n",
       "         [1.7143],\n",
       "         [1.7156],\n",
       "         [1.7168],\n",
       "         [1.7181],\n",
       "         [1.7194],\n",
       "         [1.7206],\n",
       "         [1.7219],\n",
       "         [1.7231],\n",
       "         [1.7244],\n",
       "         [1.7257],\n",
       "         [1.7269],\n",
       "         [1.7282],\n",
       "         [1.7295],\n",
       "         [1.7307],\n",
       "         [1.7320],\n",
       "         [1.7332],\n",
       "         [1.7345],\n",
       "         [1.7358],\n",
       "         [1.7370],\n",
       "         [1.7383],\n",
       "         [1.7396],\n",
       "         [1.7408],\n",
       "         [1.7421],\n",
       "         [1.7434],\n",
       "         [1.7446],\n",
       "         [1.7459],\n",
       "         [1.7472],\n",
       "         [1.7485],\n",
       "         [1.7497],\n",
       "         [1.7510],\n",
       "         [1.7523],\n",
       "         [1.7535],\n",
       "         [1.7548],\n",
       "         [1.7561],\n",
       "         [1.7573],\n",
       "         [1.7586],\n",
       "         [1.7599],\n",
       "         [1.7612],\n",
       "         [1.7624],\n",
       "         [1.7637],\n",
       "         [1.7650],\n",
       "         [1.7662],\n",
       "         [1.7675],\n",
       "         [1.7688],\n",
       "         [1.7701],\n",
       "         [1.7713],\n",
       "         [1.7726],\n",
       "         [1.7739],\n",
       "         [1.7752],\n",
       "         [1.7765],\n",
       "         [1.7777],\n",
       "         [1.7790],\n",
       "         [1.7803],\n",
       "         [1.7816],\n",
       "         [1.7828],\n",
       "         [1.7841],\n",
       "         [1.7854],\n",
       "         [1.7867],\n",
       "         [1.7879],\n",
       "         [1.7892],\n",
       "         [1.7905],\n",
       "         [1.7918],\n",
       "         [1.7931],\n",
       "         [1.7943],\n",
       "         [1.7956],\n",
       "         [1.7969],\n",
       "         [1.7982],\n",
       "         [1.7995],\n",
       "         [1.8007],\n",
       "         [1.8020],\n",
       "         [1.8033],\n",
       "         [1.8046],\n",
       "         [1.8059],\n",
       "         [1.8071],\n",
       "         [1.8084],\n",
       "         [1.8097],\n",
       "         [1.8110],\n",
       "         [1.8123],\n",
       "         [1.8135],\n",
       "         [1.8148],\n",
       "         [1.8161],\n",
       "         [1.8174],\n",
       "         [1.8187],\n",
       "         [1.8200],\n",
       "         [1.8212],\n",
       "         [1.8225],\n",
       "         [1.8238],\n",
       "         [1.8251],\n",
       "         [1.8264],\n",
       "         [1.8276],\n",
       "         [1.8289],\n",
       "         [1.8302],\n",
       "         [1.8315],\n",
       "         [1.8328],\n",
       "         [1.8341],\n",
       "         [1.8353],\n",
       "         [1.8366],\n",
       "         [1.8379],\n",
       "         [1.8392],\n",
       "         [1.8405],\n",
       "         [1.8417],\n",
       "         [1.8430]]),\n",
       " tensor([[1.8443],\n",
       "         [1.8456],\n",
       "         [1.8469],\n",
       "         [1.8482],\n",
       "         [1.8494],\n",
       "         [1.8507],\n",
       "         [1.8520],\n",
       "         [1.8533],\n",
       "         [1.8546],\n",
       "         [1.8558],\n",
       "         [1.8571],\n",
       "         [1.8584],\n",
       "         [1.8597],\n",
       "         [1.8610],\n",
       "         [1.8622],\n",
       "         [1.8635],\n",
       "         [1.8648],\n",
       "         [1.8661],\n",
       "         [1.8674],\n",
       "         [1.8686],\n",
       "         [1.8699],\n",
       "         [1.8712],\n",
       "         [1.8725],\n",
       "         [1.8737],\n",
       "         [1.8750],\n",
       "         [1.8763],\n",
       "         [1.8776],\n",
       "         [1.8789],\n",
       "         [1.8801],\n",
       "         [1.8814],\n",
       "         [1.8827],\n",
       "         [1.8840],\n",
       "         [1.8852],\n",
       "         [1.8865],\n",
       "         [1.8878],\n",
       "         [1.8891],\n",
       "         [1.8903],\n",
       "         [1.8916],\n",
       "         [1.8929],\n",
       "         [1.8941],\n",
       "         [1.8954],\n",
       "         [1.8967],\n",
       "         [1.8980],\n",
       "         [1.8992],\n",
       "         [1.9005],\n",
       "         [1.9018],\n",
       "         [1.9030],\n",
       "         [1.9043],\n",
       "         [1.9056],\n",
       "         [1.9069],\n",
       "         [1.9081],\n",
       "         [1.9094],\n",
       "         [1.9107],\n",
       "         [1.9119],\n",
       "         [1.9132],\n",
       "         [1.9144],\n",
       "         [1.9157],\n",
       "         [1.9170],\n",
       "         [1.9182],\n",
       "         [1.9195],\n",
       "         [1.9208],\n",
       "         [1.9220],\n",
       "         [1.9233],\n",
       "         [1.9245],\n",
       "         [1.9258],\n",
       "         [1.9271],\n",
       "         [1.9283],\n",
       "         [1.9296],\n",
       "         [1.9308],\n",
       "         [1.9321],\n",
       "         [1.9333],\n",
       "         [1.9346],\n",
       "         [1.9358],\n",
       "         [1.9371],\n",
       "         [1.9384],\n",
       "         [1.9396],\n",
       "         [1.9409],\n",
       "         [1.9422],\n",
       "         [1.9434],\n",
       "         [1.9447],\n",
       "         [1.9459],\n",
       "         [1.9472],\n",
       "         [1.9484],\n",
       "         [1.9496],\n",
       "         [1.9508],\n",
       "         [1.9519],\n",
       "         [1.9531],\n",
       "         [1.9543],\n",
       "         [1.9555],\n",
       "         [1.9567],\n",
       "         [1.9580],\n",
       "         [1.9594],\n",
       "         [1.9608],\n",
       "         [1.9621],\n",
       "         [1.9635],\n",
       "         [1.9648],\n",
       "         [1.9661],\n",
       "         [1.9675],\n",
       "         [1.9688],\n",
       "         [1.9702],\n",
       "         [1.9715],\n",
       "         [1.9729],\n",
       "         [1.9743],\n",
       "         [1.9756],\n",
       "         [1.9771],\n",
       "         [1.9785],\n",
       "         [1.9799],\n",
       "         [1.9814],\n",
       "         [1.9829],\n",
       "         [1.9844],\n",
       "         [1.9859],\n",
       "         [1.9874],\n",
       "         [1.9890],\n",
       "         [1.9906],\n",
       "         [1.9922],\n",
       "         [1.9938],\n",
       "         [1.9954],\n",
       "         [1.9971],\n",
       "         [1.9988],\n",
       "         [2.0005],\n",
       "         [2.0023],\n",
       "         [2.0041],\n",
       "         [2.0059],\n",
       "         [2.0078],\n",
       "         [2.0097],\n",
       "         [2.0116],\n",
       "         [2.0135],\n",
       "         [2.0154]]),\n",
       " tensor([[2.0173],\n",
       "         [2.0191],\n",
       "         [2.0210],\n",
       "         [2.0229],\n",
       "         [2.0247],\n",
       "         [2.0265],\n",
       "         [2.0283],\n",
       "         [2.0302],\n",
       "         [2.0319],\n",
       "         [2.0337],\n",
       "         [2.0355],\n",
       "         [2.0373],\n",
       "         [2.0390],\n",
       "         [2.0407],\n",
       "         [2.0424],\n",
       "         [2.0441],\n",
       "         [2.0458],\n",
       "         [2.0475],\n",
       "         [2.0491],\n",
       "         [2.0508],\n",
       "         [2.0524],\n",
       "         [2.0540],\n",
       "         [2.0555],\n",
       "         [2.0571],\n",
       "         [2.0587],\n",
       "         [2.0602],\n",
       "         [2.0618],\n",
       "         [2.0634],\n",
       "         [2.0650],\n",
       "         [2.0665],\n",
       "         [2.0681],\n",
       "         [2.0696],\n",
       "         [2.0711],\n",
       "         [2.0725],\n",
       "         [2.0740],\n",
       "         [2.0754],\n",
       "         [2.0768],\n",
       "         [2.0782],\n",
       "         [2.0796],\n",
       "         [2.0810],\n",
       "         [2.0824],\n",
       "         [2.0838],\n",
       "         [2.0852],\n",
       "         [2.0865],\n",
       "         [2.0879],\n",
       "         [2.0892],\n",
       "         [2.0905],\n",
       "         [2.0918],\n",
       "         [2.0931],\n",
       "         [2.0944],\n",
       "         [2.0956],\n",
       "         [2.0968],\n",
       "         [2.0980],\n",
       "         [2.0991],\n",
       "         [2.1003],\n",
       "         [2.1014],\n",
       "         [2.1025],\n",
       "         [2.1035],\n",
       "         [2.1046],\n",
       "         [2.1058],\n",
       "         [2.1069],\n",
       "         [2.1080],\n",
       "         [2.1091],\n",
       "         [2.1102],\n",
       "         [2.1114],\n",
       "         [2.1125],\n",
       "         [2.1137],\n",
       "         [2.1149],\n",
       "         [2.1161],\n",
       "         [2.1174],\n",
       "         [2.1186],\n",
       "         [2.1199],\n",
       "         [2.1212],\n",
       "         [2.1226],\n",
       "         [2.1239],\n",
       "         [2.1253],\n",
       "         [2.1268],\n",
       "         [2.1282],\n",
       "         [2.1297],\n",
       "         [2.1312],\n",
       "         [2.1328],\n",
       "         [2.1344],\n",
       "         [2.1360],\n",
       "         [2.1377],\n",
       "         [2.1394],\n",
       "         [2.1411],\n",
       "         [2.1427],\n",
       "         [2.1443],\n",
       "         [2.1460],\n",
       "         [2.1477],\n",
       "         [2.1494],\n",
       "         [2.1512],\n",
       "         [2.1531],\n",
       "         [2.1549],\n",
       "         [2.1567],\n",
       "         [2.1585],\n",
       "         [2.1604],\n",
       "         [2.1622],\n",
       "         [2.1640],\n",
       "         [2.1658],\n",
       "         [2.1677],\n",
       "         [2.1695],\n",
       "         [2.1713],\n",
       "         [2.1731],\n",
       "         [2.1748],\n",
       "         [2.1766],\n",
       "         [2.1784],\n",
       "         [2.1801],\n",
       "         [2.1818],\n",
       "         [2.1835],\n",
       "         [2.1852],\n",
       "         [2.1870],\n",
       "         [2.1887],\n",
       "         [2.1904],\n",
       "         [2.1921],\n",
       "         [2.1938],\n",
       "         [2.1955],\n",
       "         [2.1974],\n",
       "         [2.1995],\n",
       "         [2.2016],\n",
       "         [2.2036],\n",
       "         [2.2057],\n",
       "         [2.2077],\n",
       "         [2.2097],\n",
       "         [2.2117],\n",
       "         [2.2137],\n",
       "         [2.2156],\n",
       "         [2.2175]]),\n",
       " tensor([[2.2194],\n",
       "         [2.2213],\n",
       "         [2.2231],\n",
       "         [2.2249],\n",
       "         [2.2266],\n",
       "         [2.2284],\n",
       "         [2.2301],\n",
       "         [2.2318],\n",
       "         [2.2334],\n",
       "         [2.2351],\n",
       "         [2.2367],\n",
       "         [2.2383],\n",
       "         [2.2398],\n",
       "         [2.2414],\n",
       "         [2.2429],\n",
       "         [2.2444],\n",
       "         [2.2459],\n",
       "         [2.2473],\n",
       "         [2.2487],\n",
       "         [2.2501],\n",
       "         [2.2514],\n",
       "         [2.2527],\n",
       "         [2.2540],\n",
       "         [2.2553],\n",
       "         [2.2566],\n",
       "         [2.2579],\n",
       "         [2.2592],\n",
       "         [2.2606],\n",
       "         [2.2619],\n",
       "         [2.2632],\n",
       "         [2.2646],\n",
       "         [2.2659],\n",
       "         [2.2672],\n",
       "         [2.2685],\n",
       "         [2.2698],\n",
       "         [2.2713],\n",
       "         [2.2728],\n",
       "         [2.2743],\n",
       "         [2.2758],\n",
       "         [2.2773],\n",
       "         [2.2788],\n",
       "         [2.2804],\n",
       "         [2.2819],\n",
       "         [2.2835],\n",
       "         [2.2851],\n",
       "         [2.2867],\n",
       "         [2.2883],\n",
       "         [2.2899],\n",
       "         [2.2916],\n",
       "         [2.2932],\n",
       "         [2.2948],\n",
       "         [2.2965],\n",
       "         [2.2982],\n",
       "         [2.2998],\n",
       "         [2.3015],\n",
       "         [2.3032],\n",
       "         [2.3049],\n",
       "         [2.3066],\n",
       "         [2.3084],\n",
       "         [2.3102],\n",
       "         [2.3120],\n",
       "         [2.3138],\n",
       "         [2.3156],\n",
       "         [2.3175],\n",
       "         [2.3193],\n",
       "         [2.3210],\n",
       "         [2.3228],\n",
       "         [2.3246],\n",
       "         [2.3263],\n",
       "         [2.3281],\n",
       "         [2.3298],\n",
       "         [2.3315],\n",
       "         [2.3332],\n",
       "         [2.3348],\n",
       "         [2.3365],\n",
       "         [2.3381],\n",
       "         [2.3398],\n",
       "         [2.3414],\n",
       "         [2.3430],\n",
       "         [2.3446],\n",
       "         [2.3462],\n",
       "         [2.3477],\n",
       "         [2.3493],\n",
       "         [2.3508],\n",
       "         [2.3523],\n",
       "         [2.3538],\n",
       "         [2.3553],\n",
       "         [2.3568],\n",
       "         [2.3582],\n",
       "         [2.3597],\n",
       "         [2.3611],\n",
       "         [2.3625],\n",
       "         [2.3640],\n",
       "         [2.3654],\n",
       "         [2.3668],\n",
       "         [2.3681],\n",
       "         [2.3695],\n",
       "         [2.3709],\n",
       "         [2.3722],\n",
       "         [2.3735],\n",
       "         [2.3749],\n",
       "         [2.3762],\n",
       "         [2.3775],\n",
       "         [2.3788],\n",
       "         [2.3801],\n",
       "         [2.3814],\n",
       "         [2.3828],\n",
       "         [2.3841],\n",
       "         [2.3854],\n",
       "         [2.3868],\n",
       "         [2.3881],\n",
       "         [2.3894],\n",
       "         [2.3908],\n",
       "         [2.3922],\n",
       "         [2.3935],\n",
       "         [2.3949],\n",
       "         [2.3963],\n",
       "         [2.3977],\n",
       "         [2.3991],\n",
       "         [2.4005],\n",
       "         [2.4020],\n",
       "         [2.4034],\n",
       "         [2.4049],\n",
       "         [2.4064],\n",
       "         [2.4079],\n",
       "         [2.4094],\n",
       "         [2.4109],\n",
       "         [2.4125]]),\n",
       " tensor([[2.4140],\n",
       "         [2.4155],\n",
       "         [2.4171],\n",
       "         [2.4187],\n",
       "         [2.4202],\n",
       "         [2.4218],\n",
       "         [2.4234],\n",
       "         [2.4251],\n",
       "         [2.4267],\n",
       "         [2.4284],\n",
       "         [2.4301],\n",
       "         [2.4318],\n",
       "         [2.4335],\n",
       "         [2.4353],\n",
       "         [2.4371],\n",
       "         [2.4389],\n",
       "         [2.4407],\n",
       "         [2.4426],\n",
       "         [2.4444],\n",
       "         [2.4463],\n",
       "         [2.4483],\n",
       "         [2.4504],\n",
       "         [2.4525],\n",
       "         [2.4546],\n",
       "         [2.4568],\n",
       "         [2.4590],\n",
       "         [2.4612],\n",
       "         [2.4634],\n",
       "         [2.4657],\n",
       "         [2.4679],\n",
       "         [2.4702],\n",
       "         [2.4725],\n",
       "         [2.4748],\n",
       "         [2.4772],\n",
       "         [2.4795],\n",
       "         [2.4819],\n",
       "         [2.4843],\n",
       "         [2.4868],\n",
       "         [2.4893],\n",
       "         [2.4918],\n",
       "         [2.4943],\n",
       "         [2.4969],\n",
       "         [2.4995],\n",
       "         [2.5021],\n",
       "         [2.5048],\n",
       "         [2.5074],\n",
       "         [2.5101],\n",
       "         [2.5128],\n",
       "         [2.5155],\n",
       "         [2.5182],\n",
       "         [2.5209],\n",
       "         [2.5235],\n",
       "         [2.5261],\n",
       "         [2.5287],\n",
       "         [2.5312],\n",
       "         [2.5337],\n",
       "         [2.5362],\n",
       "         [2.5388],\n",
       "         [2.5413],\n",
       "         [2.5438],\n",
       "         [2.5464],\n",
       "         [2.5490],\n",
       "         [2.5515],\n",
       "         [2.5542],\n",
       "         [2.5568],\n",
       "         [2.5595],\n",
       "         [2.5622],\n",
       "         [2.5650],\n",
       "         [2.5678],\n",
       "         [2.5707],\n",
       "         [2.5737],\n",
       "         [2.5767],\n",
       "         [2.5798],\n",
       "         [2.5830],\n",
       "         [2.5863],\n",
       "         [2.5896],\n",
       "         [2.5931],\n",
       "         [2.5966],\n",
       "         [2.6001],\n",
       "         [2.6037],\n",
       "         [2.6074],\n",
       "         [2.6111],\n",
       "         [2.6148],\n",
       "         [2.6185],\n",
       "         [2.6222],\n",
       "         [2.6259],\n",
       "         [2.6296],\n",
       "         [2.6334],\n",
       "         [2.6373],\n",
       "         [2.6412],\n",
       "         [2.6451],\n",
       "         [2.6492],\n",
       "         [2.6533],\n",
       "         [2.6572],\n",
       "         [2.6605],\n",
       "         [2.6638],\n",
       "         [2.6671],\n",
       "         [2.6705],\n",
       "         [2.6739],\n",
       "         [2.6774],\n",
       "         [2.6809],\n",
       "         [2.6845],\n",
       "         [2.6882],\n",
       "         [2.6919],\n",
       "         [2.6957],\n",
       "         [2.6995],\n",
       "         [2.7035],\n",
       "         [2.7075],\n",
       "         [2.7115],\n",
       "         [2.7156],\n",
       "         [2.7197],\n",
       "         [2.7237],\n",
       "         [2.7277],\n",
       "         [2.7316],\n",
       "         [2.7355],\n",
       "         [2.7393],\n",
       "         [2.7429],\n",
       "         [2.7464],\n",
       "         [2.7498],\n",
       "         [2.7531],\n",
       "         [2.7565],\n",
       "         [2.7597],\n",
       "         [2.7635],\n",
       "         [2.7679],\n",
       "         [2.7723],\n",
       "         [2.7767],\n",
       "         [2.7811],\n",
       "         [2.7855]]),\n",
       " tensor([[2.7899],\n",
       "         [2.7944],\n",
       "         [2.7989],\n",
       "         [2.8035],\n",
       "         [2.8081],\n",
       "         [2.8128],\n",
       "         [2.8176],\n",
       "         [2.8224],\n",
       "         [2.8273],\n",
       "         [2.8323],\n",
       "         [2.8374],\n",
       "         [2.8425],\n",
       "         [2.8477],\n",
       "         [2.8527],\n",
       "         [2.8573],\n",
       "         [2.8618],\n",
       "         [2.8663],\n",
       "         [2.8707],\n",
       "         [2.8750],\n",
       "         [2.8791],\n",
       "         [2.8832],\n",
       "         [2.8871],\n",
       "         [2.8910],\n",
       "         [2.8947],\n",
       "         [2.8984],\n",
       "         [2.9020],\n",
       "         [2.9055],\n",
       "         [2.9090],\n",
       "         [2.9124],\n",
       "         [2.9159],\n",
       "         [2.9195],\n",
       "         [2.9231],\n",
       "         [2.9267],\n",
       "         [2.9303],\n",
       "         [2.9341],\n",
       "         [2.9378],\n",
       "         [2.9417],\n",
       "         [2.9455],\n",
       "         [2.9495],\n",
       "         [2.9535],\n",
       "         [2.9576],\n",
       "         [2.9617],\n",
       "         [2.9659],\n",
       "         [2.9701],\n",
       "         [2.9743],\n",
       "         [2.9785],\n",
       "         [2.9827],\n",
       "         [2.9869],\n",
       "         [2.9911],\n",
       "         [2.9952],\n",
       "         [2.9992],\n",
       "         [3.0032],\n",
       "         [3.0072],\n",
       "         [3.0111],\n",
       "         [3.0150],\n",
       "         [3.0188],\n",
       "         [3.0225],\n",
       "         [3.0262],\n",
       "         [3.0299],\n",
       "         [3.0335],\n",
       "         [3.0369],\n",
       "         [3.0403],\n",
       "         [3.0437],\n",
       "         [3.0469],\n",
       "         [3.0501],\n",
       "         [3.0532],\n",
       "         [3.0563],\n",
       "         [3.0592],\n",
       "         [3.0621],\n",
       "         [3.0649],\n",
       "         [3.0677],\n",
       "         [3.0703],\n",
       "         [3.0729],\n",
       "         [3.0754],\n",
       "         [3.0778],\n",
       "         [3.0801],\n",
       "         [3.0823],\n",
       "         [3.0844],\n",
       "         [3.0864],\n",
       "         [3.0884],\n",
       "         [3.0902],\n",
       "         [3.0920],\n",
       "         [3.0937],\n",
       "         [3.0954],\n",
       "         [3.0970],\n",
       "         [3.0985],\n",
       "         [3.0999],\n",
       "         [3.1013],\n",
       "         [3.1027],\n",
       "         [3.1039],\n",
       "         [3.1050],\n",
       "         [3.1061],\n",
       "         [3.1072],\n",
       "         [3.1082],\n",
       "         [3.1092],\n",
       "         [3.1101],\n",
       "         [3.1110],\n",
       "         [3.1118],\n",
       "         [3.1127],\n",
       "         [3.1134],\n",
       "         [3.1141],\n",
       "         [3.1148],\n",
       "         [3.1155],\n",
       "         [3.1161],\n",
       "         [3.1167],\n",
       "         [3.1173],\n",
       "         [3.1178],\n",
       "         [3.1183],\n",
       "         [3.1187],\n",
       "         [3.1192],\n",
       "         [3.1196],\n",
       "         [3.1199],\n",
       "         [3.1203],\n",
       "         [3.1204],\n",
       "         [3.1204],\n",
       "         [3.1205],\n",
       "         [3.1205],\n",
       "         [3.1205],\n",
       "         [3.1205],\n",
       "         [3.1205],\n",
       "         [3.1205],\n",
       "         [3.1205],\n",
       "         [3.1204],\n",
       "         [3.1203],\n",
       "         [3.1200],\n",
       "         [3.1197],\n",
       "         [3.1194],\n",
       "         [3.1190]]),\n",
       " tensor([[3.1186],\n",
       "         [3.1181],\n",
       "         [3.1176],\n",
       "         [3.1171],\n",
       "         [3.1165],\n",
       "         [3.1158],\n",
       "         [3.1151],\n",
       "         [3.1143],\n",
       "         [3.1135],\n",
       "         [3.1126],\n",
       "         [3.1116],\n",
       "         [3.1105],\n",
       "         [3.1094],\n",
       "         [3.1081],\n",
       "         [3.1068],\n",
       "         [3.1053],\n",
       "         [3.1038],\n",
       "         [3.1021],\n",
       "         [3.1003],\n",
       "         [3.0983],\n",
       "         [3.0962],\n",
       "         [3.0939],\n",
       "         [3.0915],\n",
       "         [3.0888],\n",
       "         [3.0859],\n",
       "         [3.0828],\n",
       "         [3.0795],\n",
       "         [3.0759],\n",
       "         [3.0721],\n",
       "         [3.0680],\n",
       "         [3.0636],\n",
       "         [3.0590],\n",
       "         [3.0539],\n",
       "         [3.0486],\n",
       "         [3.0428],\n",
       "         [3.0367],\n",
       "         [3.0301],\n",
       "         [3.0232],\n",
       "         [3.0158],\n",
       "         [3.0079],\n",
       "         [2.9996],\n",
       "         [2.9908],\n",
       "         [2.9815],\n",
       "         [2.9718],\n",
       "         [2.9619],\n",
       "         [2.9553],\n",
       "         [2.9482],\n",
       "         [2.9409],\n",
       "         [2.9334],\n",
       "         [2.9258],\n",
       "         [2.9180],\n",
       "         [2.9100],\n",
       "         [2.9019],\n",
       "         [2.8935],\n",
       "         [2.8849],\n",
       "         [2.8762],\n",
       "         [2.8674],\n",
       "         [2.8584],\n",
       "         [2.8493],\n",
       "         [2.8400],\n",
       "         [2.8306],\n",
       "         [2.8211],\n",
       "         [2.8114],\n",
       "         [2.8016],\n",
       "         [2.7916],\n",
       "         [2.7815],\n",
       "         [2.7713],\n",
       "         [2.7609],\n",
       "         [2.7505],\n",
       "         [2.7400],\n",
       "         [2.7294],\n",
       "         [2.7186],\n",
       "         [2.7077],\n",
       "         [2.6967],\n",
       "         [2.6855],\n",
       "         [2.6743],\n",
       "         [2.6629],\n",
       "         [2.6514],\n",
       "         [2.6398],\n",
       "         [2.6279],\n",
       "         [2.6158],\n",
       "         [2.6036],\n",
       "         [2.5916],\n",
       "         [2.5795],\n",
       "         [2.5673],\n",
       "         [2.5549],\n",
       "         [2.5421],\n",
       "         [2.5290],\n",
       "         [2.5157],\n",
       "         [2.5026],\n",
       "         [2.4896],\n",
       "         [2.4766],\n",
       "         [2.4634],\n",
       "         [2.4497],\n",
       "         [2.4354],\n",
       "         [2.4207],\n",
       "         [2.4061],\n",
       "         [2.3917],\n",
       "         [2.3774],\n",
       "         [2.3634],\n",
       "         [2.3495],\n",
       "         [2.3358],\n",
       "         [2.3220],\n",
       "         [2.3081],\n",
       "         [2.2941],\n",
       "         [2.2799],\n",
       "         [2.2655],\n",
       "         [2.2509],\n",
       "         [2.2361],\n",
       "         [2.2203],\n",
       "         [2.2042],\n",
       "         [2.1883],\n",
       "         [2.1727],\n",
       "         [2.1568],\n",
       "         [2.1405],\n",
       "         [2.1237],\n",
       "         [2.1069],\n",
       "         [2.0907],\n",
       "         [2.0752],\n",
       "         [2.0603],\n",
       "         [2.0449],\n",
       "         [2.0282],\n",
       "         [2.0108],\n",
       "         [1.9929],\n",
       "         [1.9755],\n",
       "         [1.9592],\n",
       "         [1.9442],\n",
       "         [1.9297]]),\n",
       " tensor([[1.9149],\n",
       "         [1.8992],\n",
       "         [1.8826],\n",
       "         [1.8651],\n",
       "         [1.8469],\n",
       "         [1.8278],\n",
       "         [1.8085],\n",
       "         [1.7894],\n",
       "         [1.7705],\n",
       "         [1.7520],\n",
       "         [1.7338],\n",
       "         [1.7159],\n",
       "         [1.6982],\n",
       "         [1.6809],\n",
       "         [1.6639],\n",
       "         [1.6475],\n",
       "         [1.6314],\n",
       "         [1.6153],\n",
       "         [1.5990],\n",
       "         [1.5824],\n",
       "         [1.5657],\n",
       "         [1.5493],\n",
       "         [1.5332],\n",
       "         [1.5173],\n",
       "         [1.5014],\n",
       "         [1.4852],\n",
       "         [1.4685],\n",
       "         [1.4518],\n",
       "         [1.4355],\n",
       "         [1.4200],\n",
       "         [1.4053],\n",
       "         [1.3910],\n",
       "         [1.3766],\n",
       "         [1.3617],\n",
       "         [1.3465],\n",
       "         [1.3309],\n",
       "         [1.3149],\n",
       "         [1.2985],\n",
       "         [1.2820],\n",
       "         [1.2657],\n",
       "         [1.2495],\n",
       "         [1.2335],\n",
       "         [1.2177],\n",
       "         [1.2021],\n",
       "         [1.1866],\n",
       "         [1.1713],\n",
       "         [1.1563],\n",
       "         [1.1416],\n",
       "         [1.1272],\n",
       "         [1.1127],\n",
       "         [1.0981],\n",
       "         [1.0833],\n",
       "         [1.0685],\n",
       "         [1.0539],\n",
       "         [1.0397],\n",
       "         [1.0256],\n",
       "         [1.0116],\n",
       "         [0.9973],\n",
       "         [0.9828],\n",
       "         [0.9683],\n",
       "         [0.9540],\n",
       "         [0.9402],\n",
       "         [0.9269],\n",
       "         [0.9138],\n",
       "         [0.9007],\n",
       "         [0.8872],\n",
       "         [0.8735],\n",
       "         [0.8594],\n",
       "         [0.8451],\n",
       "         [0.8306],\n",
       "         [0.8160],\n",
       "         [0.8021],\n",
       "         [0.7903],\n",
       "         [0.7786],\n",
       "         [0.7670],\n",
       "         [0.7554],\n",
       "         [0.7438],\n",
       "         [0.7324],\n",
       "         [0.7212],\n",
       "         [0.7104],\n",
       "         [0.6999],\n",
       "         [0.6892],\n",
       "         [0.6782],\n",
       "         [0.6669],\n",
       "         [0.6556],\n",
       "         [0.6448],\n",
       "         [0.6345],\n",
       "         [0.6247],\n",
       "         [0.6149],\n",
       "         [0.6047],\n",
       "         [0.5940],\n",
       "         [0.5830],\n",
       "         [0.5725],\n",
       "         [0.5629],\n",
       "         [0.5541],\n",
       "         [0.5459],\n",
       "         [0.5373],\n",
       "         [0.5282],\n",
       "         [0.5185],\n",
       "         [0.5082],\n",
       "         [0.4972],\n",
       "         [0.4878],\n",
       "         [0.4784],\n",
       "         [0.4691],\n",
       "         [0.4600],\n",
       "         [0.4510],\n",
       "         [0.4422],\n",
       "         [0.4336],\n",
       "         [0.4251],\n",
       "         [0.4168],\n",
       "         [0.4088],\n",
       "         [0.4010],\n",
       "         [0.3933],\n",
       "         [0.3857],\n",
       "         [0.3779],\n",
       "         [0.3700],\n",
       "         [0.3621],\n",
       "         [0.3544],\n",
       "         [0.3468],\n",
       "         [0.3395],\n",
       "         [0.3322],\n",
       "         [0.3247],\n",
       "         [0.3170],\n",
       "         [0.3092],\n",
       "         [0.3017],\n",
       "         [0.2945],\n",
       "         [0.2878],\n",
       "         [0.2813]]),\n",
       " tensor([[ 0.2747],\n",
       "         [ 0.2678],\n",
       "         [ 0.2608],\n",
       "         [ 0.2538],\n",
       "         [ 0.2469],\n",
       "         [ 0.2399],\n",
       "         [ 0.2328],\n",
       "         [ 0.2258],\n",
       "         [ 0.2189],\n",
       "         [ 0.2120],\n",
       "         [ 0.2053],\n",
       "         [ 0.1986],\n",
       "         [ 0.1919],\n",
       "         [ 0.1854],\n",
       "         [ 0.1790],\n",
       "         [ 0.1728],\n",
       "         [ 0.1668],\n",
       "         [ 0.1607],\n",
       "         [ 0.1545],\n",
       "         [ 0.1482],\n",
       "         [ 0.1419],\n",
       "         [ 0.1357],\n",
       "         [ 0.1298],\n",
       "         [ 0.1241],\n",
       "         [ 0.1183],\n",
       "         [ 0.1125],\n",
       "         [ 0.1064],\n",
       "         [ 0.1002],\n",
       "         [ 0.0943],\n",
       "         [ 0.0887],\n",
       "         [ 0.0836],\n",
       "         [ 0.0787],\n",
       "         [ 0.0737],\n",
       "         [ 0.0685],\n",
       "         [ 0.0631],\n",
       "         [ 0.0574],\n",
       "         [ 0.0516],\n",
       "         [ 0.0455],\n",
       "         [ 0.0394],\n",
       "         [ 0.0334],\n",
       "         [ 0.0275],\n",
       "         [ 0.0217],\n",
       "         [ 0.0160],\n",
       "         [ 0.0104],\n",
       "         [ 0.0049],\n",
       "         [-0.0005],\n",
       "         [-0.0058],\n",
       "         [-0.0109],\n",
       "         [-0.0158],\n",
       "         [-0.0208],\n",
       "         [-0.0258],\n",
       "         [-0.0308],\n",
       "         [-0.0359],\n",
       "         [-0.0408],\n",
       "         [-0.0458],\n",
       "         [-0.0506],\n",
       "         [-0.0554],\n",
       "         [-0.0603],\n",
       "         [-0.0653],\n",
       "         [-0.0702],\n",
       "         [-0.0749],\n",
       "         [-0.0794],\n",
       "         [-0.0836],\n",
       "         [-0.0877],\n",
       "         [-0.0918],\n",
       "         [-0.0960],\n",
       "         [-0.1003],\n",
       "         [-0.1046],\n",
       "         [-0.1091],\n",
       "         [-0.1135],\n",
       "         [-0.1180],\n",
       "         [-0.1225],\n",
       "         [-0.1268],\n",
       "         [-0.1311],\n",
       "         [-0.1353],\n",
       "         [-0.1393],\n",
       "         [-0.1434],\n",
       "         [-0.1473],\n",
       "         [-0.1511],\n",
       "         [-0.1547],\n",
       "         [-0.1580],\n",
       "         [-0.1614],\n",
       "         [-0.1648],\n",
       "         [-0.1684],\n",
       "         [-0.1721],\n",
       "         [-0.1757],\n",
       "         [-0.1793],\n",
       "         [-0.1827],\n",
       "         [-0.1862],\n",
       "         [-0.1900],\n",
       "         [-0.1938],\n",
       "         [-0.1976],\n",
       "         [-0.2012],\n",
       "         [-0.2044],\n",
       "         [-0.2072],\n",
       "         [-0.2098],\n",
       "         [-0.2125],\n",
       "         [-0.2153],\n",
       "         [-0.2184],\n",
       "         [-0.2216],\n",
       "         [-0.2250],\n",
       "         [-0.2285],\n",
       "         [-0.2321],\n",
       "         [-0.2355],\n",
       "         [-0.2389],\n",
       "         [-0.2422],\n",
       "         [-0.2454],\n",
       "         [-0.2485],\n",
       "         [-0.2515],\n",
       "         [-0.2544],\n",
       "         [-0.2572],\n",
       "         [-0.2600],\n",
       "         [-0.2626],\n",
       "         [-0.2652],\n",
       "         [-0.2678],\n",
       "         [-0.2705],\n",
       "         [-0.2732],\n",
       "         [-0.2759],\n",
       "         [-0.2788],\n",
       "         [-0.2818],\n",
       "         [-0.2848],\n",
       "         [-0.2879],\n",
       "         [-0.2909],\n",
       "         [-0.2938],\n",
       "         [-0.2966],\n",
       "         [-0.2994],\n",
       "         [-0.3021],\n",
       "         [-0.3048]]),\n",
       " tensor([[-0.3075],\n",
       "         [-0.3102],\n",
       "         [-0.3129],\n",
       "         [-0.3156],\n",
       "         [-0.3182],\n",
       "         [-0.3208],\n",
       "         [-0.3234],\n",
       "         [-0.3260],\n",
       "         [-0.3285],\n",
       "         [-0.3311],\n",
       "         [-0.3337],\n",
       "         [-0.3363],\n",
       "         [-0.3388],\n",
       "         [-0.3413],\n",
       "         [-0.3439],\n",
       "         [-0.3465],\n",
       "         [-0.3491],\n",
       "         [-0.3516],\n",
       "         [-0.3541],\n",
       "         [-0.3566],\n",
       "         [-0.3590],\n",
       "         [-0.3616],\n",
       "         [-0.3643],\n",
       "         [-0.3671],\n",
       "         [-0.3699],\n",
       "         [-0.3727],\n",
       "         [-0.3754],\n",
       "         [-0.3781],\n",
       "         [-0.3808],\n",
       "         [-0.3836],\n",
       "         [-0.3866],\n",
       "         [-0.3897],\n",
       "         [-0.3927],\n",
       "         [-0.3957],\n",
       "         [-0.3987],\n",
       "         [-0.4017],\n",
       "         [-0.4045],\n",
       "         [-0.4074],\n",
       "         [-0.4102],\n",
       "         [-0.4131],\n",
       "         [-0.4160],\n",
       "         [-0.4189],\n",
       "         [-0.4219],\n",
       "         [-0.4249],\n",
       "         [-0.4280],\n",
       "         [-0.4311],\n",
       "         [-0.4341],\n",
       "         [-0.4369],\n",
       "         [-0.4396],\n",
       "         [-0.4423],\n",
       "         [-0.4454],\n",
       "         [-0.4488],\n",
       "         [-0.4523],\n",
       "         [-0.4556],\n",
       "         [-0.4586],\n",
       "         [-0.4615],\n",
       "         [-0.4644],\n",
       "         [-0.4678],\n",
       "         [-0.4716],\n",
       "         [-0.4756],\n",
       "         [-0.4792],\n",
       "         [-0.4822],\n",
       "         [-0.4845],\n",
       "         [-0.4864],\n",
       "         [-0.4887],\n",
       "         [-0.4913],\n",
       "         [-0.4945],\n",
       "         [-0.4981],\n",
       "         [-0.5022],\n",
       "         [-0.5067],\n",
       "         [-0.5113],\n",
       "         [-0.5157],\n",
       "         [-0.5201],\n",
       "         [-0.5242],\n",
       "         [-0.5282],\n",
       "         [-0.5320],\n",
       "         [-0.5357],\n",
       "         [-0.5392],\n",
       "         [-0.5425],\n",
       "         [-0.5457],\n",
       "         [-0.5488],\n",
       "         [-0.5519],\n",
       "         [-0.5549],\n",
       "         [-0.5580],\n",
       "         [-0.5610],\n",
       "         [-0.5639],\n",
       "         [-0.5669],\n",
       "         [-0.5698],\n",
       "         [-0.5726],\n",
       "         [-0.5755],\n",
       "         [-0.5783],\n",
       "         [-0.5811],\n",
       "         [-0.5838],\n",
       "         [-0.5864],\n",
       "         [-0.5890],\n",
       "         [-0.5915],\n",
       "         [-0.5940],\n",
       "         [-0.5964],\n",
       "         [-0.5988],\n",
       "         [-0.6011],\n",
       "         [-0.6033],\n",
       "         [-0.6055],\n",
       "         [-0.6077],\n",
       "         [-0.6098],\n",
       "         [-0.6120],\n",
       "         [-0.6141],\n",
       "         [-0.6161],\n",
       "         [-0.6182],\n",
       "         [-0.6202],\n",
       "         [-0.6222],\n",
       "         [-0.6241],\n",
       "         [-0.6261],\n",
       "         [-0.6280],\n",
       "         [-0.6299],\n",
       "         [-0.6318],\n",
       "         [-0.6336],\n",
       "         [-0.6354],\n",
       "         [-0.6372],\n",
       "         [-0.6390],\n",
       "         [-0.6408],\n",
       "         [-0.6425],\n",
       "         [-0.6442],\n",
       "         [-0.6459],\n",
       "         [-0.6476],\n",
       "         [-0.6492],\n",
       "         [-0.6508],\n",
       "         [-0.6524],\n",
       "         [-0.6539]]),\n",
       " tensor([[-0.6554],\n",
       "         [-0.6569],\n",
       "         [-0.6583],\n",
       "         [-0.6598],\n",
       "         [-0.6612],\n",
       "         [-0.6626],\n",
       "         [-0.6639],\n",
       "         [-0.6653],\n",
       "         [-0.6666],\n",
       "         [-0.6679],\n",
       "         [-0.6691],\n",
       "         [-0.6703],\n",
       "         [-0.6715],\n",
       "         [-0.6727],\n",
       "         [-0.6738],\n",
       "         [-0.6749],\n",
       "         [-0.6760],\n",
       "         [-0.6770],\n",
       "         [-0.6780],\n",
       "         [-0.6789],\n",
       "         [-0.6798],\n",
       "         [-0.6807],\n",
       "         [-0.6815],\n",
       "         [-0.6823],\n",
       "         [-0.6830],\n",
       "         [-0.6837],\n",
       "         [-0.6844],\n",
       "         [-0.6851],\n",
       "         [-0.6857],\n",
       "         [-0.6862],\n",
       "         [-0.6868],\n",
       "         [-0.6873],\n",
       "         [-0.6879],\n",
       "         [-0.6884],\n",
       "         [-0.6889],\n",
       "         [-0.6894],\n",
       "         [-0.6899],\n",
       "         [-0.6904],\n",
       "         [-0.6909],\n",
       "         [-0.6914],\n",
       "         [-0.6919],\n",
       "         [-0.6924],\n",
       "         [-0.6929],\n",
       "         [-0.6934],\n",
       "         [-0.6938],\n",
       "         [-0.6943],\n",
       "         [-0.6948],\n",
       "         [-0.6953],\n",
       "         [-0.6957],\n",
       "         [-0.6962],\n",
       "         [-0.6967],\n",
       "         [-0.6972],\n",
       "         [-0.6977],\n",
       "         [-0.6983],\n",
       "         [-0.6988],\n",
       "         [-0.6994],\n",
       "         [-0.6999],\n",
       "         [-0.7005],\n",
       "         [-0.7011],\n",
       "         [-0.7017],\n",
       "         [-0.7023],\n",
       "         [-0.7029],\n",
       "         [-0.7035],\n",
       "         [-0.7042],\n",
       "         [-0.7048],\n",
       "         [-0.7055],\n",
       "         [-0.7062],\n",
       "         [-0.7068],\n",
       "         [-0.7075],\n",
       "         [-0.7082],\n",
       "         [-0.7090],\n",
       "         [-0.7097],\n",
       "         [-0.7104],\n",
       "         [-0.7111],\n",
       "         [-0.7118],\n",
       "         [-0.7126],\n",
       "         [-0.7133],\n",
       "         [-0.7141],\n",
       "         [-0.7148],\n",
       "         [-0.7155],\n",
       "         [-0.7163],\n",
       "         [-0.7171],\n",
       "         [-0.7178],\n",
       "         [-0.7186],\n",
       "         [-0.7193],\n",
       "         [-0.7201],\n",
       "         [-0.7209],\n",
       "         [-0.7217],\n",
       "         [-0.7224],\n",
       "         [-0.7232],\n",
       "         [-0.7240],\n",
       "         [-0.7247],\n",
       "         [-0.7255],\n",
       "         [-0.7263],\n",
       "         [-0.7270],\n",
       "         [-0.7278],\n",
       "         [-0.7286],\n",
       "         [-0.7293],\n",
       "         [-0.7301],\n",
       "         [-0.7308],\n",
       "         [-0.7316],\n",
       "         [-0.7323],\n",
       "         [-0.7331],\n",
       "         [-0.7338],\n",
       "         [-0.7345],\n",
       "         [-0.7353],\n",
       "         [-0.7360],\n",
       "         [-0.7367],\n",
       "         [-0.7375],\n",
       "         [-0.7382],\n",
       "         [-0.7389],\n",
       "         [-0.7396],\n",
       "         [-0.7403],\n",
       "         [-0.7411],\n",
       "         [-0.7418],\n",
       "         [-0.7425],\n",
       "         [-0.7432],\n",
       "         [-0.7439],\n",
       "         [-0.7447],\n",
       "         [-0.7454],\n",
       "         [-0.7461],\n",
       "         [-0.7468],\n",
       "         [-0.7476],\n",
       "         [-0.7483],\n",
       "         [-0.7490],\n",
       "         [-0.7498],\n",
       "         [-0.7505],\n",
       "         [-0.7512]]),\n",
       " tensor([[-0.7520],\n",
       "         [-0.7527],\n",
       "         [-0.7534],\n",
       "         [-0.7542],\n",
       "         [-0.7549],\n",
       "         [-0.7556],\n",
       "         [-0.7564],\n",
       "         [-0.7571],\n",
       "         [-0.7579],\n",
       "         [-0.7586],\n",
       "         [-0.7594],\n",
       "         [-0.7601],\n",
       "         [-0.7609],\n",
       "         [-0.7616],\n",
       "         [-0.7624],\n",
       "         [-0.7631],\n",
       "         [-0.7639],\n",
       "         [-0.7647],\n",
       "         [-0.7654],\n",
       "         [-0.7662],\n",
       "         [-0.7670],\n",
       "         [-0.7678],\n",
       "         [-0.7685],\n",
       "         [-0.7693],\n",
       "         [-0.7701],\n",
       "         [-0.7709],\n",
       "         [-0.7717],\n",
       "         [-0.7725],\n",
       "         [-0.7733],\n",
       "         [-0.7741],\n",
       "         [-0.7749],\n",
       "         [-0.7757],\n",
       "         [-0.7765],\n",
       "         [-0.7773],\n",
       "         [-0.7782],\n",
       "         [-0.7790],\n",
       "         [-0.7798],\n",
       "         [-0.7806],\n",
       "         [-0.7815],\n",
       "         [-0.7823],\n",
       "         [-0.7832],\n",
       "         [-0.7840],\n",
       "         [-0.7849],\n",
       "         [-0.7857],\n",
       "         [-0.7866],\n",
       "         [-0.7874],\n",
       "         [-0.7883],\n",
       "         [-0.7891],\n",
       "         [-0.7900],\n",
       "         [-0.7909],\n",
       "         [-0.7918],\n",
       "         [-0.7926],\n",
       "         [-0.7935],\n",
       "         [-0.7944],\n",
       "         [-0.7953],\n",
       "         [-0.7962],\n",
       "         [-0.7971],\n",
       "         [-0.7980],\n",
       "         [-0.7989],\n",
       "         [-0.7998],\n",
       "         [-0.8007],\n",
       "         [-0.8016],\n",
       "         [-0.8026],\n",
       "         [-0.8035],\n",
       "         [-0.8044],\n",
       "         [-0.8053],\n",
       "         [-0.8063],\n",
       "         [-0.8072],\n",
       "         [-0.8082],\n",
       "         [-0.8091],\n",
       "         [-0.8101],\n",
       "         [-0.8110],\n",
       "         [-0.8120],\n",
       "         [-0.8129],\n",
       "         [-0.8139],\n",
       "         [-0.8149],\n",
       "         [-0.8158],\n",
       "         [-0.8168],\n",
       "         [-0.8178],\n",
       "         [-0.8187],\n",
       "         [-0.8197],\n",
       "         [-0.8207],\n",
       "         [-0.8217],\n",
       "         [-0.8227],\n",
       "         [-0.8237],\n",
       "         [-0.8247],\n",
       "         [-0.8257],\n",
       "         [-0.8266],\n",
       "         [-0.8276],\n",
       "         [-0.8286],\n",
       "         [-0.8296],\n",
       "         [-0.8307],\n",
       "         [-0.8317],\n",
       "         [-0.8327],\n",
       "         [-0.8337],\n",
       "         [-0.8347],\n",
       "         [-0.8357],\n",
       "         [-0.8367],\n",
       "         [-0.8377],\n",
       "         [-0.8387],\n",
       "         [-0.8397],\n",
       "         [-0.8408],\n",
       "         [-0.8418],\n",
       "         [-0.8428],\n",
       "         [-0.8438],\n",
       "         [-0.8448],\n",
       "         [-0.8458],\n",
       "         [-0.8469],\n",
       "         [-0.8479],\n",
       "         [-0.8489],\n",
       "         [-0.8499],\n",
       "         [-0.8509],\n",
       "         [-0.8519],\n",
       "         [-0.8530],\n",
       "         [-0.8540],\n",
       "         [-0.8550],\n",
       "         [-0.8560],\n",
       "         [-0.8570],\n",
       "         [-0.8580],\n",
       "         [-0.8591],\n",
       "         [-0.8601],\n",
       "         [-0.8611],\n",
       "         [-0.8621],\n",
       "         [-0.8631],\n",
       "         [-0.8641],\n",
       "         [-0.8651],\n",
       "         [-0.8661],\n",
       "         [-0.8671]]),\n",
       " tensor([[-0.8681],\n",
       "         [-0.8692],\n",
       "         [-0.8702],\n",
       "         [-0.8712],\n",
       "         [-0.8722],\n",
       "         [-0.8732],\n",
       "         [-0.8742],\n",
       "         [-0.8752],\n",
       "         [-0.8761],\n",
       "         [-0.8771],\n",
       "         [-0.8781],\n",
       "         [-0.8791],\n",
       "         [-0.8801],\n",
       "         [-0.8811],\n",
       "         [-0.8821],\n",
       "         [-0.8831],\n",
       "         [-0.8841],\n",
       "         [-0.8850],\n",
       "         [-0.8860],\n",
       "         [-0.8870],\n",
       "         [-0.8880],\n",
       "         [-0.8889],\n",
       "         [-0.8899],\n",
       "         [-0.8909],\n",
       "         [-0.8919],\n",
       "         [-0.8928],\n",
       "         [-0.8938],\n",
       "         [-0.8948],\n",
       "         [-0.8957],\n",
       "         [-0.8967],\n",
       "         [-0.8976],\n",
       "         [-0.8986],\n",
       "         [-0.8996],\n",
       "         [-0.9005],\n",
       "         [-0.9015],\n",
       "         [-0.9024],\n",
       "         [-0.9034],\n",
       "         [-0.9043],\n",
       "         [-0.9053],\n",
       "         [-0.9062],\n",
       "         [-0.9072],\n",
       "         [-0.9081],\n",
       "         [-0.9091],\n",
       "         [-0.9100],\n",
       "         [-0.9109],\n",
       "         [-0.9119],\n",
       "         [-0.9128],\n",
       "         [-0.9137],\n",
       "         [-0.9147],\n",
       "         [-0.9156],\n",
       "         [-0.9165],\n",
       "         [-0.9174],\n",
       "         [-0.9184],\n",
       "         [-0.9193],\n",
       "         [-0.9202],\n",
       "         [-0.9211],\n",
       "         [-0.9221],\n",
       "         [-0.9230],\n",
       "         [-0.9239],\n",
       "         [-0.9248],\n",
       "         [-0.9257],\n",
       "         [-0.9266],\n",
       "         [-0.9275],\n",
       "         [-0.9284],\n",
       "         [-0.9294],\n",
       "         [-0.9303],\n",
       "         [-0.9312],\n",
       "         [-0.9321],\n",
       "         [-0.9330],\n",
       "         [-0.9339],\n",
       "         [-0.9348],\n",
       "         [-0.9357],\n",
       "         [-0.9366],\n",
       "         [-0.9375],\n",
       "         [-0.9384],\n",
       "         [-0.9392],\n",
       "         [-0.9401],\n",
       "         [-0.9410],\n",
       "         [-0.9419],\n",
       "         [-0.9428],\n",
       "         [-0.9437],\n",
       "         [-0.9446],\n",
       "         [-0.9455],\n",
       "         [-0.9463],\n",
       "         [-0.9472],\n",
       "         [-0.9481],\n",
       "         [-0.9490],\n",
       "         [-0.9498],\n",
       "         [-0.9507],\n",
       "         [-0.9516],\n",
       "         [-0.9525],\n",
       "         [-0.9533],\n",
       "         [-0.9542],\n",
       "         [-0.9551],\n",
       "         [-0.9559],\n",
       "         [-0.9568],\n",
       "         [-0.9576],\n",
       "         [-0.9585],\n",
       "         [-0.9593],\n",
       "         [-0.9602],\n",
       "         [-0.9610],\n",
       "         [-0.9619],\n",
       "         [-0.9627],\n",
       "         [-0.9636],\n",
       "         [-0.9644],\n",
       "         [-0.9653],\n",
       "         [-0.9661],\n",
       "         [-0.9669],\n",
       "         [-0.9678],\n",
       "         [-0.9686],\n",
       "         [-0.9694],\n",
       "         [-0.9702],\n",
       "         [-0.9711],\n",
       "         [-0.9719],\n",
       "         [-0.9727],\n",
       "         [-0.9735],\n",
       "         [-0.9743],\n",
       "         [-0.9751],\n",
       "         [-0.9759]])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_pred = []\n",
    "predictions_actual = []\n",
    "trainer.test()\n",
    "predictions_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8c4f506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Regression(\n",
       "  (fc1): Linear(in_features=85, out_features=30, bias=True)\n",
       "  (fc2): Linear(in_features=30, out_features=10, bias=True)\n",
       "  (fc3): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), f'{path}/model.pt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1ec1f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of pred_actual 74 \n",
      "size of tenzors inside pred_actual torch.Size([128, 1])\n"
     ]
    }
   ],
   "source": [
    "print('length of pred_actual',len(predictions_actual),'\\nsize of tenzors inside pred_actual',predictions_actual[3].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e7fe25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert my predicted values back to actual numbers\n",
    "data_scaling=pd.read_csv(f'{path}/data_scaling.csv', header=0, index_col=0)\n",
    "mean = data_scaling['Qimpact'][0]\n",
    "std = data_scaling['Qimpact'][1]\n",
    "\n",
    "# Get predicted points (scaled back to their original size)\n",
    "if (threePoint):\n",
    "    Qcomponent = 1\n",
    "else:\n",
    "    Qcomponent = 0\n",
    "plot_pred = []\n",
    "for i in range(len(predictions_pred)):\n",
    "    plot_pred.extend(predictions_pred[i].T.numpy()[Qcomponent] * std + mean)\n",
    "# Save the results to the text file\n",
    "np.savetxt('Qimpact-NN.txt', np.transpose([scaled_Qdata.index, plot_pred]))\n",
    "\n",
    "# Get actual points (scaled back to their original size)\n",
    "plot_actual = []\n",
    "for i in range(len(predictions_actual)):\n",
    "    plot_actual.extend(predictions_actual[i].T.numpy()[Qcomponent] * std + mean) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c5e86f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fdb12e74c70>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And finally we can see that our network has done a decent job of estimating!\n",
    "fig1, ax1 = plt.subplots(figsize=(10,4))\n",
    "ax1.plot(scaled_Qdata.index,plot_actual, 'r', label='Data')\n",
    "ax1.plot(scaled_Qdata.index,plot_pred, 'k--', label='Prediction')\n",
    "ax1.set_xlabel('cm')\n",
    "ax1.set_ylabel('W/cm$^2$')\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bc5480c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradQpred=np.gradient(plot_pred, scaled_Qdata.index)\n",
    "gradQact=np.gradient(plot_actual, scaled_Qdata.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7b0e054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'W/cm$^3$')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig2, ax2 = plt.subplots(figsize=(10,4))\n",
    "ax2.plot(scaled_Qdata.index,gradQpred, label='Prediction grad')\n",
    "ax2.plot(scaled_Qdata.index,gradQact, label='Data grad', color='orange')\n",
    "ax2.legend()\n",
    "ax2.set_xlabel('cm')\n",
    "ax2.set_ylabel('W/cm$^3$')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ptl_env]",
   "language": "python",
   "name": "conda-env-ptl_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
